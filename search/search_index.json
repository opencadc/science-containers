{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CANFAR Science Platform","text":"<p>A scalable, cloud-native workspace with interactive computing and shared storage for astronomy research.</p> <p>Whether you're an observational astronomer, a data scientist, or an enthusiastic student, CANFAR offers everything you need to explore, analyze, and share your discoveries \u2014 without worrying about hardware or software installations.</p>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":"<p>New to CANFAR? Get up and running within 10 minutes with our,</p> <p>\ud83d\udcd6 Getting Started Guide</p> <p>Already have an account? Manage your workspace with,</p> <ul> <li>\ud83c\udf10 CANFAR Portal - Launch sessions</li> <li>\ud83d\udcc1 File Manager - Access and manage storage  </li> <li>\ud83d\udc65 Group Management - Manage teams and permissions</li> </ul>"},{"location":"#user-guides","title":"\ud83d\udcd6 User Guides","text":"<p>Comprehensive documentation organized by topic:</p> <ul> <li>Platform Concepts - Architecture and key concepts</li> <li>Accounts &amp; Permissions - Access control and collaboration</li> <li>Storage Systems - Data management and file operations</li> <li>Container Usage - Working with software containers</li> <li>Interactive Sessions - Jupyter, CARTA, Firefly, Desktop, and more</li> <li>Batch Jobs - Automated processing and workflows</li> <li>Radio Astronomy - CASA, CARTA, and interferometry workflows</li> </ul>"},{"location":"#need-help","title":"\u2753Need Help?","text":"<p>Check out our FAQ and Help &amp; Support pages.</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":"<p>This section answers common questions about using the CANFAR Science Platform, from basic usage to advanced troubleshooting.</p>"},{"location":"faq/#getting-started","title":"Getting Started","text":""},{"location":"faq/#how-do-i-get-access-to-canfar","title":"How do I get access to CANFAR?","text":"<ol> <li>Request an account: Visit canfar.net and click \"Request Account\"</li> <li>Provide justification: Explain your research needs and institutional affiliation</li> <li>Wait for approval: Account approval typically takes 1-2 business days</li> <li>Join a group: Contact your project PI to be added to relevant research groups</li> </ol>"},{"location":"faq/#whats-the-difference-between-the-session-types","title":"What's the difference between the session types?","text":"Session Type Best For Resources GUI Notebook Interactive analysis, prototyping Low-Medium Jupyter Lab Desktop GUI applications, multi-app workflows Medium-High Full Linux desktop CARTA Image/cube visualization Medium Specialized viewer Headless Batch processing, automation Variable None (API only)"},{"location":"faq/#how-much-does-it-cost-to-use-canfar","title":"How much does it cost to use CANFAR?","text":"<p>CANFAR is free for academic research. The platform is funded by the Canadian government and partner institutions to support astronomical research. Commercial users may have different arrangements.</p>"},{"location":"faq/#account-and-access","title":"Account and Access","text":""},{"location":"faq/#i-forgot-my-password-how-do-i-reset-it","title":"I forgot my password. How do I reset it?","text":"<p>CANFAR uses certificate-based authentication, not passwords. If you're having login issues:</p> <ol> <li>Check that your browser certificate is properly installed</li> <li>Try a different browser</li> <li>Contact support@canfar.net for certificate reissue</li> </ol>"},{"location":"faq/#how-do-i-join-a-research-group","title":"How do I join a research group?","text":"<p>Groups control access to shared storage and resources:</p> <ol> <li>Contact the group PI: Ask to be added to the relevant project group</li> <li>Provide your CANFAR username: Usually your email address</li> <li>Wait for approval: PIs can add members through the Science Portal</li> </ol>"},{"location":"faq/#can-i-access-canfar-from-anywhere-in-the-world","title":"Can I access CANFAR from anywhere in the world?","text":"<p>Yes, CANFAR is accessible from anywhere with internet access. However, large data transfers may be faster from Canadian institutions due to network proximity.</p>"},{"location":"faq/#storage-and-data","title":"Storage and Data","text":""},{"location":"faq/#how-much-storage-do-i-get","title":"How much storage do I get?","text":"<p>Storage allocation depends on your groups:</p> <ul> <li>Personal space: 10GB in <code>/arc/home/[username]/</code></li> <li>Group storage: Varies by project, typically 100GB to several TB</li> <li>Temporary storage: Unlimited in <code>/tmp/</code> (cleared when session ends)</li> </ul>"},{"location":"faq/#where-should-i-put-my-data","title":"Where should I put my data?","text":"<p>Follow this storage strategy:</p> <ul> <li>Raw data: <code>/arc/projects/[group]/raw/</code> - Original, unmodified observations</li> <li>Working data: <code>/arc/projects/[group]/data/</code> - Data being actively processed</li> <li>Results: <code>/arc/projects/[group]/results/</code> - Final analysis outputs</li> <li>Scripts: <code>/arc/projects/[group]/scripts/</code> - Analysis code and pipelines</li> <li>Personal work: <code>/arc/home/[username]/</code> - Individual analysis and notes</li> </ul>"},{"location":"faq/#how-do-i-transfer-large-datasets","title":"How do I transfer large datasets?","text":"<p>For datasets larger than a few GB:</p> <p>From external sources: <pre><code># Use rsync for resumable transfers\nrsync -avz --progress source/ username@canfar.net:/arc/projects/mygroup/\n\n# For very large files, use VOSpace\ncadc-data put largefile.fits vos:myproject/data/\n</code></pre></p> <p>To/from CANFAR: - Use the Science Portal file manager for files &lt;1GB - Use command-line tools (<code>rsync</code>, <code>scp</code>) for larger transfers - Use VOSpace for files &gt;10GB</p>"},{"location":"faq/#what-file-formats-are-supported","title":"What file formats are supported?","text":"<p>CANFAR supports all standard astronomical formats:</p> <ul> <li>FITS: Standard astronomical images and tables</li> <li>HDF5: Large datasets and modern archives</li> <li>CASA formats: Measurement sets and images</li> <li>Text formats: CSV, ASCII tables, JSON</li> <li>Images: PNG, JPEG, PDF for plots and figures</li> </ul>"},{"location":"faq/#sessions-and-computing","title":"Sessions and Computing","text":""},{"location":"faq/#how-long-can-my-session-run","title":"How long can my session run?","text":"<p>Interactive sessions: - Maximum 7 days of continuous runtime - Automatic shutdown after 24 hours of inactivity - Can be resumed if not explicitly deleted</p> <p>Batch jobs: - No strict time limits - Queue priority depends on resource usage - Long jobs (&gt;24 hours) may have lower priority</p>"},{"location":"faq/#my-session-wont-start-what-should-i-do","title":"My session won't start. What should I do?","text":"<p>Common causes and solutions:</p> <p>Resource constraints: - Try reducing memory or CPU requirements - Check resource availability in the Science Portal - Consider running during off-peak hours (evenings, weekends)</p> <p>Container issues: - Verify the container name is correct - Try a different container version - Check if the container is deprecated</p> <p>Account problems: - Verify you're in the correct groups - Check that your account is active - Contact support if needed</p>"},{"location":"faq/#can-i-run-gpu-accelerated-applications","title":"Can I run GPU-accelerated applications?","text":"<p>Yes, CANFAR provides GPU resources for supported workloads:</p> <p>Available GPUs: - NVIDIA Tesla V100: Machine learning, deep learning - NVIDIA RTX series: General GPU computing - Limited availability - request in session configuration</p> <p>Common GPU applications: - TensorFlow and PyTorch for machine learning - CUDA-accelerated astronomy codes - Image processing and computer vision</p> <p>Requesting GPU access: 1. Select \"GPU\" in session configuration 2. Choose appropriate GPU type 3. Ensure your container supports GPU computing</p>"},{"location":"faq/#how-do-i-monitor-my-resource-usage","title":"How do I monitor my resource usage?","text":"<p>In interactive sessions: <pre><code># Check memory usage\nfree -h\n\n# Monitor CPU usage\nhtop\n\n# Check disk usage\ndf -h\n\n# Monitor GPU usage (if applicable)\nnvidia-smi\n</code></pre></p> <p>Through the Science Portal: - View active sessions and their resource consumption - Monitor group storage usage - Track session history and runtime</p>"},{"location":"faq/#software-and-containers","title":"Software and Containers","text":""},{"location":"faq/#what-software-is-available","title":"What software is available?","text":"<p>CANFAR provides containers with pre-installed software:</p> <p>General astronomy: - astroml: Modern Python astronomy stack (AstroPy, NumPy, SciPy, Matplotlib) - General purpose: Basic Python data science tools</p> <p>Specialized tools: - CASA: Radio astronomy data reduction - CARTA: Image and data cube visualization - DS9: FITS image viewer - TOPCAT: Table analysis and visualization</p> <p>Development environments: - Jupyter: Interactive notebooks - Linux desktop: Full graphical environment - Custom containers: Build your own software stacks</p>"},{"location":"faq/#can-i-install-additional-software","title":"Can I install additional software?","text":"<p>In existing containers: <pre><code># Install Python packages (temporary)\npip install --user package_name\n\n# Install system packages (if you have sudo access)\nsudo apt-get install package_name\n</code></pre></p> <p>Permanent installations: - Build custom containers with your software stack - See the Container Guide for details</p>"},{"location":"faq/#how-do-i-update-to-newer-software-versions","title":"How do I update to newer software versions?","text":"<p>Container updates: - CANFAR regularly updates container images - New versions appear in the session creation menu - Older versions remain available for compatibility</p> <p>Manual updates: <pre><code># Update Python packages\npip install --upgrade --user package_name\n\n# Update conda environments (if applicable)\nconda update --all\n</code></pre></p>"},{"location":"faq/#collaboration-and-sharing","title":"Collaboration and Sharing","text":""},{"location":"faq/#how-do-i-share-my-work-with-collaborators","title":"How do I share my work with collaborators?","text":"<p>Session sharing: 1. In your active session, access the sharing menu 2. Add collaborator usernames 3. Set permissions (view-only or full access) 4. Collaborators can join your session in real-time</p> <p>Data sharing: - Add collaborators to your project group - Use shared group storage in <code>/arc/projects/[group]/</code> - Set appropriate file permissions</p> <p>Code sharing: - Use Git repositories for version control - Share Jupyter notebooks through group storage - Document your analysis workflows</p>"},{"location":"faq/#can-multiple-people-use-the-same-session","title":"Can multiple people use the same session?","text":"<p>Yes, interactive sessions support real-time collaboration:</p> <ul> <li>Shared desktop: Multiple users can see and control the same desktop</li> <li>Jupyter sharing: Collaborative notebook editing</li> <li>CARTA sharing: Synchronized image viewing and analysis</li> </ul>"},{"location":"faq/#how-do-i-cite-canfar-in-my-publications","title":"How do I cite CANFAR in my publications?","text":"<p>Include this acknowledgment in your papers:</p> <p>\"This research made use of the CANFAR computing facility, which is managed by the National Research Council of Canada and funded by the Canadian Space Agency.\"</p> <p>For more detailed citation information, see canfar.net/citation.</p>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#my-analysis-is-running-slowly-how-can-i-speed-it-up","title":"My analysis is running slowly. How can I speed it up?","text":"<p>Check resource usage: <pre><code># Monitor system resources\nhtop\niotop  # Disk I/O\n</code></pre></p> <p>Optimization strategies:</p> <ol> <li>Use scratch storage: Process data in <code>/tmp/</code> for faster I/O</li> <li>Increase resources: Request more memory or CPU cores</li> <li>Optimize code: Use vectorized operations, efficient algorithms</li> <li>Parallel processing: Utilize multiple cores when possible</li> <li>Data locality: Keep frequently accessed data in fast storage</li> </ol>"},{"location":"faq/#im-getting-out-of-memory-errors-what-should-i-do","title":"I'm getting \"out of memory\" errors. What should I do?","text":"<p>Immediate solutions: - Close unnecessary applications - Clear Python/CASA cache - Process data in smaller chunks</p> <p>Long-term solutions: - Request more memory for your session - Optimize your analysis to use less memory - Use memory-mapped file access for large datasets</p>"},{"location":"faq/#my-container-wont-start-or-crashes-immediately-help","title":"My container won't start or crashes immediately. Help!","text":"<p>Diagnostic steps:</p> <ol> <li>Check container logs: Look for error messages in session logs</li> <li>Try different container: Test with a basic container (e.g., astroml)</li> <li>Reduce resources: Start with minimal memory/CPU requirements</li> <li>Check group permissions: Ensure you have access to required storage</li> </ol> <p>Common fixes: - Update browser to latest version - Clear browser cache and cookies - Try incognito/private browsing mode - Check network connectivity</p>"},{"location":"faq/#i-cant-access-my-files-where-did-they-go","title":"I can't access my files. Where did they go?","text":"<p>Check common locations: <pre><code># Personal storage\nls /arc/home/$(whoami)/\n\n# Group storage\nls /arc/projects/\n\n# Temporary files (session-specific)\nls /tmp/\nls ~/\n</code></pre></p> <p>File recovery: - Files in <code>/tmp/</code> are deleted when sessions end - Files in <code>/arc/</code> storage are persistent - Contact support for backup restoration if needed</p>"},{"location":"faq/#browser-issues-and-compatibility","title":"Browser issues and compatibility","text":"<p>Supported browsers: - Chrome/Chromium: Best compatibility and performance - Firefox: Good compatibility - Safari: Limited support, some features may not work - Edge: Basic support</p> <p>Common browser fixes: - Enable cookies and JavaScript - Disable ad blockers for canfar.net - Clear browser cache and cookies - Update browser to latest version</p>"},{"location":"faq/#advanced-usage","title":"Advanced Usage","text":""},{"location":"faq/#can-i-run-my-own-docker-containers","title":"Can I run my own Docker containers?","text":"<p>Yes, you can build and use custom containers:</p> <ol> <li>Build locally: Create your Dockerfile with required software</li> <li>Push to Harbor: Upload to CANFAR's container registry</li> <li>Use in sessions: Select your custom container in session creation</li> </ol> <p>See the Container Development Guide for detailed instructions.</p>"},{"location":"faq/#how-do-i-automate-workflows-with-the-api","title":"How do I automate workflows with the API?","text":"<p>CANFAR provides REST APIs for programmatic access:</p> <pre><code>import requests\n\n# Submit a batch job\nresponse = requests.post(\n    \"https://ws-uv.canfar.net/skaha/v0/session\",\n    headers={\"Authorization\": f\"Bearer {token}\"},\n    data={\n        \"name\": \"automated-analysis\",\n        \"image\": \"images.canfar.net/skaha/astroml:latest\",\n        \"cores\": 4,\n        \"ram\": 16,\n        \"kind\": \"headless\",\n        \"cmd\": \"python /arc/projects/myproject/analyze.py\",\n    },\n)\n</code></pre>"},{"location":"faq/#can-i-connect-external-tools-to-canfar","title":"Can I connect external tools to CANFAR?","text":"<p>SSHFS mounting: <pre><code># Mount CANFAR storage locally\nsshfs username@canfar.net:/arc/projects/mygroup/ ~/canfar_mount/\n</code></pre></p> <p>VOSpace access: <pre><code># Access VOSpace programmatically\nfrom cadcdata import CadcDataClient\n\nclient = CadcDataClient()\nclient.put_file(\"local_file.fits\", \"vos:myproject/data/file.fits\")\n</code></pre></p>"},{"location":"faq/#performance-tips","title":"Performance Tips","text":""},{"location":"faq/#general-optimization","title":"General optimization","text":"<ol> <li>Choose appropriate resources: Don't over-request CPU/memory</li> <li>Use scratch storage: Process data in <code>/tmp/</code> for speed</li> <li>Monitor usage: Keep an eye on resource consumption</li> <li>Clean up: Remove temporary files regularly</li> <li>Work during off-peak: Better performance evenings/weekends</li> </ol>"},{"location":"faq/#for-large-datasets","title":"For large datasets","text":"<ol> <li>Stream processing: Process data in chunks rather than loading entirely</li> <li>Parallel processing: Use multiple cores effectively</li> <li>Memory mapping: Use memory-mapped file access</li> <li>Compression: Compress intermediate results to save I/O</li> <li>Batch operations: Group similar operations together</li> </ol>"},{"location":"faq/#for-collaborative-work","title":"For collaborative work","text":"<ol> <li>Coordinate resource usage: Avoid competing for resources</li> <li>Share efficiently: Use read-only sharing when possible</li> <li>Document workflows: Clear documentation helps collaboration</li> <li>Version control: Use Git for shared code development</li> </ol>"},{"location":"faq/#getting-help","title":"Getting Help","text":""},{"location":"faq/#self-help-resources","title":"Self-help resources","text":"<ul> <li>Documentation: Browse the User Guide</li> <li>Radio Astronomy: Check radio astronomy guide for specialized workflows</li> <li>Community: Join our Discord for peer support</li> <li>Examples: Look at example notebooks and scripts</li> </ul>"},{"location":"faq/#contacting-support","title":"Contacting support","text":"<p>Email: support@canfar.net</p> <p>Include in your support request: - Your CANFAR username - Description of the problem - Steps to reproduce the issue - Error messages (copy/paste exact text) - Session type and container used</p> <p>Response time: Support typically responds within 1-2 business days.</p>"},{"location":"faq/#community-support","title":"Community support","text":"<p>Discord community: Join our Discord server for: - Quick questions and answers - Tips and tricks sharing - Collaboration opportunities - Announcements of new features</p> <p>Office hours: Weekly virtual office hours for real-time help (check Discord for schedule).</p>"},{"location":"faq/#feature-requests-and-feedback","title":"Feature Requests and Feedback","text":""},{"location":"faq/#suggesting-improvements","title":"Suggesting improvements","text":"<p>We welcome feedback and suggestions:</p> <ul> <li>Feature requests: Email specific ideas to support</li> <li>Bug reports: Include detailed reproduction steps</li> <li>Documentation: Suggest improvements or missing topics</li> <li>Software requests: Request additional containers or software</li> </ul>"},{"location":"faq/#contributing-to-canfar","title":"Contributing to CANFAR","text":"<ul> <li>Documentation: Help improve these docs (see Contributing Guide)</li> <li>Containers: Share useful container recipes</li> <li>Tutorials: Create tutorials for your research area</li> <li>Testing: Help test new features in beta</li> </ul> <p>Your feedback helps make CANFAR better for the entire astronomy community!</p>"},{"location":"general/ALMA_Desktop/casa_containers/","title":"General notes on CASA containers","text":"<p>This page contains a compilation of useful notes, etc, on various CASA containers.</p>"},{"location":"general/ALMA_Desktop/casa_containers/#astroquery-astropy","title":"Astroquery / astropy","text":"<p>The astroquery tool is presently only installed on newer CASA containers (6.4.4-6.6.3).  To use astroquery from an appropriate CASA container, type the following to initiate an astroquery-compatible version of python: <code>/opt/casa/bin/python3</code> As per the astroquery documentation, the tool can then be used on the command line within the python environment.  For example, the following sequence of commands</p> <p><code>from astroquery.simbad import Simbad</code></p> <p><code>result_table = Simbad.query_object(\"m1\")</code></p> <p><code>result_table.pprint()</code></p> <p>yield a one-line table listing some basic information about M1.</p>"},{"location":"general/ALMA_Desktop/casa_containers/#analysis-utilities","title":"Analysis Utilities","text":"<p>The analysisUtils package package is pre-installed on every CASA container, and is ready to use.  You may need to type <code>import analysisUtils as au</code> to load it.</p>"},{"location":"general/ALMA_Desktop/casa_containers/#admit","title":"ADMIT","text":"<p>ADMIT (ALMA Data Mining Tool) is pre-installed on CASA containers where possible (CASA versions 4.5 and higher) and should be ready to use, although it has not been tested.  Note that the newest CASA containers (6.6.1-pipeline and regular versions 6.6.4 and higher) exclude ADMIT because it does not properly compile.</p>"},{"location":"general/ALMA_Desktop/casa_containers/#firefox","title":"Firefox","text":"<p>The Firefox web-browser, needed for CASA commands where you are interacting with the weblogs, should available for CASA versions 6.1.0 to 6.4.3.  Error messages will pop up in your terminal window, but minimal testing suggests that it is sufficiently functional.</p>"},{"location":"general/ALMA_Desktop/casa_containers/#uvmultifit","title":"UVMultiFit","text":"<p>The UVMultiFit package is presently installed and working for all CASA 5.X versions except 5.8.  To load the UVMultiFit package, initiate casa and then type</p> <p><code>from NordicARC import uvmultifit as uvm</code></p>"},{"location":"general/ALMA_Desktop/casa_containers/#known-container-bugs","title":"Known Container Bugs","text":"<p>1) CASA versions 6.5.0 to 6.5.2 initially launch with some display errors in the logger window.  Exiting casa (but not the container) and re-starting casa fixes the issue, i.e.,</p> <p><code>casa</code></p> <p><code>exit</code></p> <p><code>casa</code></p> <p>2) Running multi-thread pipeline scripts (MPI CASA) may generate error messages, as described here under the 'Running pipeline in non-interactive mode' section.  A CANFAR ALMA user reports success initiating MPI CASA in a Desktop container as follows:</p> <p><code>xvfb-run -a mpicasa casa \u2014nologger \u2014nogui -agg -c casa_script.py</code></p>"},{"location":"general/ALMA_Desktop/casa_containers/#almacasa-adjacent-containers-galario","title":"ALMA/CASA Adjacent Containers : Galario","text":"<p>The UV data analysis package galario is available under the radio-submm menu.  Note that this container has had minimal testing, and the uvplot package commands in the quickstart.py script are not presently working, although all preceeding commands in the quickstart.py script do work.</p>"},{"location":"general/ALMA_Desktop/casa_containers/#almacasa-adjacent-containers-starlink","title":"ALMA/CASA Adjacent Containers : Starlink","text":"<p>The JCMT's Starlink package is available under the radio-submm menu, including image analysis tools and the gaia image viewer.  Note that the starlink-pywrapper add-on package is presently not working.  Minimal testing has been done on the Starlink container.</p>"},{"location":"get-started/","title":"Getting Started with CANFAR","text":"<p>Quick start guide to get you up and running with CANFAR Science Platform in minutes</p>"},{"location":"get-started/#quick-setup","title":"\ud83d\ude80 Quick Setup","text":"<p>This guide will walk you through the complete process of getting started with CANFAR, from account setup to your first analysis session.</p>"},{"location":"get-started/#step-1-get-your-cadc-account","title":"Step 1: Get Your CADC Account","text":"<p>First time user? You need a Canadian Astronomy Data Centre (CADC) account:</p> <p>\ud83d\udd17 Request CADC Account</p> <p>Account Processing Time</p> <p>CADC accounts are typically approved within 1-2 business days.</p>"},{"location":"get-started/#step-2-join-or-create-your-research-group","title":"Step 2: Join or Create Your Research Group","text":"<p>Once you have a CADC account:</p> Joining Existing GroupNew Collaboration <p>Ask your collaboration administrator to add you via the CADC Group Management Interface</p> <p>Email support@canfar.net with:</p> <ul> <li>Your research project description</li> <li>Expected team size</li> <li>Storage requirements</li> <li>Timeline</li> </ul>"},{"location":"get-started/#step-3-first-login-and-setup","title":"Step 3: First Login and Setup","text":"<ol> <li>Login to CANFAR - Visit canfar.net with your CADC credentials</li> <li>Accept Terms of Service - Complete the initial setup</li> <li>Access Image Registry - Login to images.canfar.net (required for private containers)</li> </ol> <p>Pro Tip</p> <p>Ask your group administrator to grant you read access to private container images if your collaboration uses custom software.</p>"},{"location":"get-started/#step-4-launch-your-first-session","title":"Step 4: Launch Your First Session","text":"<p>Try launching a Jupyter notebook to start analyzing data:</p> <ol> <li>Click Science Portal from the main menu</li> <li>Use the default settings as is</li> <li>Click Launch</li> <li>Wait ~30s and click to open your session</li> </ol> <p>\ud83c\udf89 You're ready to go! Your session includes Python, common astronomy packages, and access to shared storage.</p> <p>Recommended Starting Point</p> <p>Start with the default <code>astroml</code> container - it includes most common astronomy packages and is regularly updated with the latest software.</p>"},{"location":"get-started/#understanding-your-workspace","title":"\ud83d\udcc1 Understanding Your Workspace","text":"<p>Now that you're logged in, here's how CANFAR organizes your data:</p> Location Purpose Persistence Best For <code>/arc/projects/yourgroup/</code> Shared research data \u2705 Permanent, backed up Datasets, results, shared code <code>/arc/home/yourusername/</code> Personal files \u2705 Permanent, backed up Personal configs, small files <code>/scratch/</code> Fast temporary space \u274c Wiped at session end Large computations, temporary files"},{"location":"get-started/#collaboration-features","title":"\ud83e\udd1d Collaboration Features","text":""},{"location":"get-started/#session-sharing","title":"Session Sharing","text":"<p>Share running sessions with collaborators:</p> <ol> <li>In your session, copy the session URL</li> <li>Share with team members (must be in same group)</li> <li>They can view and interact with your work in real-time</li> </ol>"},{"location":"get-started/#storage-sharing","title":"Storage Sharing","text":"<p>All group members have access to <code>/arc/projects/yourgroup/</code> - perfect for:</p> <ul> <li>Sharing datasets and results</li> <li>Collaborative analysis scripts</li> <li>Common software environments</li> <li>Project documentation</li> </ul>"},{"location":"get-started/#whats-next","title":"\ud83d\udd17 What's Next?","text":"<p>Ready to dive deeper? </p> <ul> <li>User Guide \u2192 - Comprehensive documentation</li> <li>Storage Guide \u2192 - Detailed storage management</li> <li>Container Guide \u2192 - Using and building containers</li> <li>Radio Astronomy \u2192 - CASA, ALMA workflows</li> </ul>"},{"location":"get-started/#need-help","title":"\ud83d\udcac Need Help?","text":"<ul> <li>\ud83d\udcac Discord Community - Chat with other users</li> <li>\ud83d\udce7 Email Support - Direct technical support</li> <li>\u2753 FAQ - Common questions and solutions</li> </ul>"},{"location":"help/","title":"Getting Help and Support","text":"<p>The CANFAR Science Platform provides multiple channels for getting help, from self-service documentation to direct support. This section guides you to the right resources for your needs.</p>"},{"location":"help/#quick-help","title":"Quick Help","text":""},{"location":"help/#new-to-canfar","title":"New to CANFAR?","text":"<ul> <li>Get Started Guide: 10-minute quick start</li> <li>First Login: Account setup and access</li> <li>Choose Your Interface: Pick the right session type</li> </ul>"},{"location":"help/#having-problems","title":"Having Problems?","text":"<ul> <li>FAQ: Common questions and solutions</li> <li>Troubleshooting: Diagnostic steps for common issues</li> <li>Contact Support: Direct help from CANFAR staff</li> </ul>"},{"location":"help/#want-to-learn-more","title":"Want to Learn More?","text":"<ul> <li>User Guide: Comprehensive platform documentation</li> <li>Radio Astronomy Guide: Specialized astronomy workflows</li> <li>Community: Connect with other users</li> </ul>"},{"location":"help/#self-help-resources","title":"Self-Help Resources","text":""},{"location":"help/#documentation","title":"Documentation","text":"<p>User Guide Sections:</p> <ul> <li>Concepts: Understanding the platform architecture</li> <li>Storage: Managing your data effectively</li> <li>Containers: Using and building software environments</li> <li>Interactive Sessions: Jupyter, Desktop, CARTA</li> <li>Batch Jobs: Automated and large-scale processing</li> <li>Radio Astronomy: CASA and radio-specific workflows</li> </ul> <p>Tutorials:</p> <ul> <li>Data Analysis Examples: Common astronomy workflows</li> <li>Radio Astronomy Guide: CASA and interferometry</li> <li>Container Building: Create custom environments</li> </ul>"},{"location":"help/#video-resources","title":"Video Resources","text":"<p>Getting Started Videos (coming soon):</p> <ul> <li>Platform overview and navigation</li> <li>Creating your first session</li> <li>Data management basics</li> <li>Collaboration features</li> </ul> <p>Workflow Demonstrations:</p> <ul> <li>Optical photometry pipeline</li> <li>Radio interferometry reduction</li> <li>Multi-wavelength analysis</li> </ul>"},{"location":"help/#troubleshooting","title":"Troubleshooting","text":""},{"location":"help/#quick-diagnostic-steps","title":"Quick Diagnostic Steps","text":"<p>When you encounter issues, try these steps first:</p> <ol> <li>Check System status: Look for maintenance announcements</li> <li>Try a different browser: Chrome and Firefox work best</li> <li>Clear browser cache: Remove cookies and cached data</li> <li>Try incognito mode: Eliminates browser extension conflicts</li> <li>Check your network: Ensure stable internet connection</li> </ol>"},{"location":"help/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"help/#session-wont-start","title":"Session Won't Start","text":"<p>Symptoms: Session creation fails or hangs</p> <p>Solutions: - Reduce resource requirements (memory/CPU) - Try during off-peak hours (evenings, weekends) - Select a different container image - Check group permissions</p>"},{"location":"help/#cant-access-files","title":"Can't Access Files","text":"<p>Symptoms: Files missing or permission denied</p> <p>Solutions: <pre><code># Check file locations\nls /arc/home/$(whoami)/     # Personal storage\nls /arc/projects/           # Group storage\n\n# Check permissions\nls -la /arc/projects/mygroup/\n</code></pre></p> <ul> <li>Verify you're in the correct group</li> <li>Check file paths are correct</li> <li>Contact group administrator</li> </ul>"},{"location":"help/#performance-issues","title":"Performance Issues","text":"<p>Symptoms: Slow processing or unresponsive interface</p> <p>Solutions: - Monitor resource usage with <code>htop</code> - Close unnecessary applications - Use scratch storage (<code>/tmp/</code>) for temporary files - Consider requesting more resources</p>"},{"location":"help/#browser-compatibility","title":"Browser Compatibility","text":"<p>Symptoms: Interface doesn't load or behaves incorrectly</p> <p>Solutions: - Use Chrome or Firefox (recommended) - Enable JavaScript and cookies - Disable ad blockers for canfar.net - Update browser to latest version</p>"},{"location":"help/#diagnostic-commands","title":"Diagnostic Commands","text":"<p>Use these commands to gather information for support requests:</p> <pre><code># System information\nuname -a\ncat /proc/cpuinfo | grep \"model name\" | head -1\nfree -h\ndf -h\n\n# Session information\necho $USER\ngroups\nenv | grep -E \"(CANFAR|SESSION)\"\n\n# Network connectivity\nping -c 3 canfar.net\ncurl -I https://canfar.net\n</code></pre>"},{"location":"help/#contact-support","title":"Contact Support","text":""},{"location":"help/#when-to-contact-support","title":"When to Contact Support","text":"<p>Contact support@canfar.net for:</p> <ul> <li>Account issues: Access problems, group membership</li> <li>Technical problems: Persistent errors, system failures</li> <li>Data recovery: Lost or corrupted files</li> <li>Resource requests: Increased storage or compute allocations</li> <li>Software installation: Help with complex software setups</li> </ul>"},{"location":"help/#how-to-write-effective-support-requests","title":"How to Write Effective Support Requests","text":"<p>Include these details in your support email:</p> <p>Essential information: <pre><code>Subject: [Brief description of problem]\n\nCANFAR Username: your.email@domain.com\nDate/Time of issue: 2024-01-15 14:30 PST\nSession type: Desktop/Notebook/CARTA/Batch\nContainer used: astroml:latest\nBrowser: Chrome 120.0.6099\n\nProblem description:\n[Detailed description of what you were trying to do]\n\nError messages:\n[Copy/paste exact error text]\n\nSteps to reproduce:\n1. Login to Science Portal\n2. Create desktop session\n3. [etc.]\n\nWhat you've already tried:\n- Cleared browser cache\n- Tried different browser\n- [etc.]\n</code></pre></p> <p>Additional helpful information: - Screenshots of error messages - Session IDs for failed jobs - File paths for missing data - Group names for permission issues</p>"},{"location":"help/#response-times","title":"Response Times","text":"<ul> <li>Standard support: 1-2 business days</li> <li>Urgent issues: Same day during business hours</li> <li>Emergency outages: Immediate response during business hours</li> </ul> <p>Business hours: Monday-Friday, 9 AM - 5 PM Pacific Time</p>"},{"location":"help/#support-escalation","title":"Support Escalation","text":"<p>For urgent research deadlines or critical system issues:</p> <ol> <li>Mark email as urgent: Use \"URGENT\" in subject line</li> <li>Explain deadline: Include your research timeline</li> <li>Provide context: Explain impact of the issue</li> <li>Follow up: Call if no response within expected timeframe</li> </ol>"},{"location":"help/#community-support","title":"Community Support","text":""},{"location":"help/#discord-community","title":"Discord Community","text":"<p>Join our Discord server for peer support and community interaction:</p> <ul> <li>Quick questions: Get fast answers from other users</li> <li>Tips and tricks: Share and learn best practices</li> <li>Collaboration: Find research partners and collaborators</li> <li>Announcements: Stay updated on new features and maintenance</li> </ul> <p>Discord invite: Join CANFAR Discord</p> <p>Community guidelines: - Search previous messages before asking - Use appropriate channels and threads - Be respectful and helpful to other users - Don't share sensitive data or credentials</p>"},{"location":"help/#github-issues","title":"GitHub Issues","text":"<p>For bug reports and feature requests, use our GitHub repositories:</p> <ul> <li>Platform issues: Report technical problems</li> <li>Documentation: Suggest improvements</li> <li>Feature requests: Propose new capabilities</li> <li>Community contributions: Submit code and examples</li> </ul>"},{"location":"help/#office-hours","title":"Office Hours","text":"<p>Virtual office hours: Thursdays 2-3 PM Pacific Time</p> <ul> <li>Format: Video conference with screen sharing</li> <li>Topics: Any CANFAR-related questions</li> <li>Registration: Not required, drop-in welcome</li> <li>Recording: Sessions recorded for later viewing</li> </ul> <p>What to bring: - Specific questions or problems - Example code or workflows - Error messages or screenshots</p>"},{"location":"help/#peer-mentoring","title":"Peer Mentoring","text":"<p>Experienced user program: Connect new users with experienced mentors</p> <ul> <li>Mentors: Volunteer researchers who use CANFAR regularly</li> <li>Support areas: Platform basics, specific software, research workflows</li> <li>Matching: Based on research area and experience level</li> <li>Contact: Email support to request mentor connection</li> </ul>"},{"location":"help/#community-contributions","title":"Community Contributions","text":"<p>Ways to help other users:</p> <ul> <li>Answer questions: Respond to Discord and community discussions</li> <li>Share tutorials: Create workflow examples</li> <li>Report bugs: Help improve platform stability</li> <li>Suggest features: Propose improvements</li> </ul>"},{"location":"help/#contributing-to-documentation","title":"Contributing to Documentation","text":"<p>The CANFAR Science Platform documentation is community-driven, and we welcome contributions from users who want to help improve the platform for everyone.</p>"},{"location":"help/#how-to-contribute","title":"\ud83d\udcdd How to Contribute","text":"<p>Quick Edits: - Use the \"Edit this page\" link (pencil icon) on any documentation page - Makes suggestions directly on GitHub - Perfect for typos, clarifications, and small updates</p> <p>Larger Contributions: - Set up local development environment - Create comprehensive new sections - Major restructuring or new guides</p>"},{"location":"help/#local-development-setup","title":"\ud83d\ude80 Local Development Setup","text":"<p>Prerequisites: - Python 3.x and pip - Git for version control</p> <p>Setup Steps:</p> <ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/opencadc/science-containers.git\ncd science-containers\n</code></pre></p> </li> <li> <p>Install dependencies (using Poetry):    <pre><code># Install Poetry if you don't have it\n# See: https://python-poetry.org/docs/#installation\n\npoetry install\n</code></pre></p> </li> <li> <p>Start development server:    <pre><code>poetry shell\nmkdocs serve\n</code></pre></p> </li> <li> <p>View documentation: Open <code>http://127.0.0.1:8000</code> in your browser</p> </li> </ol> <p>Changes to documentation files will automatically reload in your browser for real-time preview.</p>"},{"location":"help/#documentation-structure","title":"\ud83d\udcc1 Documentation Structure","text":"<p>Our documentation follows a clear structure designed for different user needs:</p> <ul> <li><code>get-started/</code>: Quick setup for new users</li> <li><code>user-guide/</code>: Comprehensive platform documentation</li> <li><code>concepts/</code>: Platform architecture and core concepts</li> <li><code>accounts-permissions/</code>: User management and access control  </li> <li><code>storage/</code>: Data management and storage systems</li> <li><code>containers/</code>: Container usage and building</li> <li><code>interactive-sessions/</code>: Jupyter, desktop, and application sessions</li> <li><code>batch-jobs/</code>: Automated and large-scale processing</li> <li><code>radio-astronomy/</code>: CASA and radio-specific workflows</li> <li><code>faq/</code>: Frequently asked questions and troubleshooting</li> <li><code>help/</code>: Support resources and community information</li> </ul>"},{"location":"help/#writing-guidelines","title":"\u270d\ufe0f Writing Guidelines","text":"<p>Markdown Style: - Use <code>#</code> for page titles, <code>##</code> for main sections, <code>###</code> for subsections - Code blocks with language specification: <code>```python</code> or <code>```bash</code> - Inline code with single backticks: <code>variable_name</code> or <code>command --option</code></p> <p>Admonitions for Important Information: <pre><code>!!! note\n    General information note\n\n!!! tip \"Pro Tip\"\n    Helpful advice for users\n\n!!! warning\n    Important cautions\n\n!!! danger \"Critical\"\n    Critical warnings\n\n!!! example\n    Code examples and demonstrations\n</code></pre></p> <p>Writing for Different Audiences:</p> <p>New Users: - Avoid jargon or explain technical terms clearly - Provide step-by-step instructions - Focus on common tasks and getting started - Include plenty of examples</p> <p>Advanced Users: - Provide technical details and configuration options - Include information on automation, APIs, and advanced workflows - Assume familiarity with relevant technologies - Link to detailed reference materials</p>"},{"location":"help/#contribution-process","title":"\ud83d\udd04 Contribution Process","text":"<ol> <li>Make your changes in the appropriate documentation files</li> <li>Test locally using <code>mkdocs serve</code> to verify formatting</li> <li>Commit with clear messages: <code>git commit -m \"docs: Describe your change\"</code></li> <li>Submit a pull request to the main repository</li> <li>Collaborate with reviewers to refine your contribution</li> </ol>"},{"location":"help/#documentation-philosophy","title":"\ud83d\udcda Documentation Philosophy","text":"<p>We aim for documentation that is: - Accurate: Technically correct and current - Clear: Easy to understand without unnecessary jargon - Complete: Covering essential aspects comprehensively - User-Friendly: Well-structured and accessible</p>"},{"location":"help/#questions-about-contributing","title":"\u2753 Questions About Contributing?","text":"<ul> <li>Open an issue on GitHub</li> <li>Ask on Discord in the community channels</li> <li>Email the CANFAR team at support@canfar.net</li> </ul> <p>Your contributions help make CANFAR better for the entire astronomy community!</p>"},{"location":"help/#additional-resources","title":"Additional Resources","text":""},{"location":"help/#external-documentation","title":"External Documentation","text":"<p>Related platforms: - CADC Archive: cadc-ccda.hia-iha.nrc-cnrc.gc.ca - VOSpace: vospace.canfar.net - Science Portal: science.canfar.net</p> <p>Software documentation: - CASA: casa.nrao.edu - AstroPy: astropy.org - Jupyter: jupyter.org - Docker: docs.docker.com</p>"},{"location":"help/#research-collaboration","title":"Research Collaboration","text":"<p>Finding collaborators: - Discord community channels - Conference networking - Shared project spaces - Research group connections</p> <p>Collaboration tools: - Real-time session sharing - Shared storage spaces - Version control with Git - Communication through Discord</p>"},{"location":"help/#staying-updated","title":"Staying Updated","text":"<p>Announcements: - Email notifications for maintenance - Discord #announcements channel - Science Portal news section - Twitter @CANFAR_ACFC</p> <p>Feature updates: - Monthly platform updates - New container releases - Beta feature testing - User feedback integration</p>"},{"location":"help/#emergency-contacts","title":"Emergency Contacts","text":""},{"location":"help/#system-outages","title":"System Outages","text":"<p>Planned maintenance: Announced 48+ hours in advance via email and Discord</p> <p>Unplanned outages:  - Check status.canfar.net for current status (when available) - Follow @CANFAR_ACFC for real-time updates - Email support@canfar.net if status unclear</p>"},{"location":"help/#critical-data-issues","title":"Critical Data Issues","text":"<p>Data loss or corruption: 1. Stop all activity: Prevent further damage 2. Document the issue: Note exactly what happened 3. Contact support immediately: Mark email as URGENT 4. Preserve evidence: Don't delete or modify files</p> <p>Backup and recovery: - Daily snapshots of <code>/arc/</code> storage - 30-day retention period - Point-in-time recovery available - Contact support for restoration requests</p>"},{"location":"help/#security-incidents","title":"Security Incidents","text":"<p>Suspected security breach: 1. Change credentials: Update certificates immediately 2. Report incident: Email security@canfar.net 3. Document details: What you observed and when 4. Follow instructions: Wait for security team guidance</p> <p>Prevention: - Never share your certificates - Use secure networks - Keep software updated - Report suspicious activity</p>"},{"location":"help/#contributing-to-documentation_1","title":"Contributing to Documentation","text":"<p>The CANFAR Science Platform documentation is community-driven, and we welcome contributions from users who want to help improve the platform for everyone.</p>"},{"location":"help/#how-to-contribute_1","title":"\ud83d\udcdd How to Contribute","text":"<p>Quick Edits:</p> <ul> <li>Use the \"Edit this page\" link (pencil icon) on any documentation page</li> <li>Makes suggestions directly on GitHub</li> <li>Perfect for typos, clarifications, and small updates</li> </ul> <p>Larger Contributions:</p> <ul> <li>Set up local development environment</li> <li>Create comprehensive new sections</li> <li>Major restructuring or new guides</li> </ul>"},{"location":"help/#local-development-setup_1","title":"\ud83d\ude80 Local Development Setup","text":"<p>Prerequisites:</p> <ul> <li>Python 3.x and pip</li> <li>Git for version control</li> </ul> <p>Setup Steps:</p> <ol> <li>Clone the repository:</li> </ol> <pre><code>git clone https://github.com/opencadc/science-containers.git\ncd science-containers\n</code></pre> <ol> <li>Install dependencies (using Poetry):</li> </ol> <pre><code># Install Poetry if you don't have it\n# See: https://python-poetry.org/docs/#installation\n\npoetry install\n</code></pre> <ol> <li>Start development server:</li> </ol> <pre><code>poetry shell\nmkdocs serve\n</code></pre> <ol> <li>View documentation: Open <code>http://127.0.0.1:8000</code> in your browser</li> </ol> <p>Changes to documentation files will automatically reload in your browser for real-time preview.</p>"},{"location":"help/#documentation-structure_1","title":"\ud83d\udcc1 Documentation Structure","text":"<p>Our documentation follows a clear structure designed for different user needs:</p> <ul> <li><code>get-started/</code>: Quick setup for new users</li> <li><code>user-guide/</code>: Comprehensive platform documentation</li> <li><code>concepts/</code>: Platform architecture and core concepts</li> <li><code>accounts-permissions/</code>: User management and access control</li> <li><code>storage/</code>: Data management and storage systems</li> <li><code>containers/</code>: Container usage and building</li> <li><code>interactive-sessions/</code>: Jupyter, desktop, and application sessions</li> <li><code>batch-jobs/</code>: Automated and large-scale processing</li> <li><code>radio-astronomy/</code>: CASA and radio-specific workflows</li> <li><code>faq/</code>: Frequently asked questions and troubleshooting</li> <li><code>help/</code>: Support resources and community information</li> </ul>"},{"location":"help/#writing-guidelines_1","title":"\u270d\ufe0f Writing Guidelines","text":"<p>Markdown Style:</p> <ul> <li>Use <code>#</code> for page titles, <code>##</code> for main sections, <code>###</code> for subsections</li> <li>Code blocks with language specification: <code>```python</code> or <code>```bash</code></li> <li>Inline code with single backticks: <code>variable_name</code> or <code>command --option</code></li> </ul> <p>Admonitions for Important Information:</p> <pre><code>!!! note\n    General information note\n\n!!! tip \"Pro Tip\"\n    Helpful advice for users\n\n!!! warning\n    Important cautions\n\n!!! danger \"Critical\"\n    Critical warnings\n\n!!! example\n    Code examples and demonstrations\n</code></pre> <p>Writing for Different Audiences:</p> <p>New Users:</p> <ul> <li>Avoid jargon or explain technical terms clearly</li> <li>Provide step-by-step instructions</li> <li>Focus on common tasks and getting started</li> <li>Include plenty of examples</li> </ul> <p>Advanced Users:</p> <ul> <li>Provide technical details and configuration options</li> <li>Include information on automation, APIs, and advanced workflows</li> <li>Assume familiarity with relevant technologies</li> <li>Link to detailed reference materials</li> </ul>"},{"location":"help/#contribution-process_1","title":"\ud83d\udd04 Contribution Process","text":"<ol> <li>Make your changes in the appropriate documentation files</li> <li>Test locally using <code>mkdocs serve</code> to verify formatting</li> <li>Commit with clear messages: <code>git commit -m \"docs: Describe your change\"</code></li> <li>Submit a pull request to the main repository</li> <li>Collaborate with reviewers to refine your contribution</li> </ol>"},{"location":"help/#documentation-philosophy_1","title":"\ud83d\udcda Documentation Philosophy","text":"<p>We aim for documentation that is:</p> <ul> <li>Accurate: Technically correct and current</li> <li>Clear: Easy to understand without unnecessary jargon</li> <li>Complete: Covering essential aspects comprehensively</li> <li>User-Friendly: Well-structured and accessible</li> </ul>"},{"location":"help/#questions-about-contributing_1","title":"\u2753 Questions About Contributing?","text":"<ul> <li>Open an issue on GitHub</li> <li>Ask on Discord in the community channels</li> <li>Email the CANFAR team at support@canfar.net</li> </ul> <p>Your contributions help make CANFAR better for the entire astronomy community!</p>"},{"location":"help/#contact-information-summary","title":"Contact Information Summary","text":"Need Contact Response Time General support support@canfar.net 1-2 business days Quick questions Discord Community Minutes to hours Security issues security@canfar.net Same day Documentation support@canfar.net 1-2 business days Office hours Video conference Thursdays 2-3 PM PT <p>Remember: The CANFAR team is here to help you succeed in your research. Don't hesitate to reach out with questions, no matter how basic they might seem!</p>"},{"location":"user-guide/","title":"User Guide","text":"<p>Comprehensive documentation for the CANFAR Science Platform</p> <p>This guide provides detailed information for astronomers, grad students, and project managers using CANFAR for research. Whether you're analyzing radio astronomy data, building custom software environments, or managing large collaborative projects, this guide has you covered.</p>"},{"location":"user-guide/#what-is-canfar","title":"What is CANFAR?","text":"<p>CANFAR provides cloud-based astronomy computing with:</p> <ul> <li>\ud83d\udda5\ufe0f Interactive sessions (Jupyter Lab, CARTA, Firefly, Desktop environments)</li> <li>\ud83d\udcbe Shared storage for collaborative datasets (shared file system, VOSpace long term, scratch)</li> <li>\ud83d\udc33 Pre-built software containers with astronomy tools</li> <li>\ud83d\udd27 User container support for specialized workflows</li> <li>\u26a1 Batch processing for automated analysis</li> <li>\ud83d\udc65 Collaboration tools with group-based permissions</li> </ul>"},{"location":"user-guide/#guide-structure","title":"\ud83d\udcd6 Guide Structure","text":""},{"location":"user-guide/#concepts","title":"\ud83e\udde0 Concepts","text":"<p>Understand the fundamentals: platform architecture, containers, Kubernetes, REST services, and VOSpace.</p>"},{"location":"user-guide/#accounts-permissions","title":"\ud83d\udc65 Accounts &amp; Permissions","text":"<p>Manage users, groups, Harbor permissions, ACLs, and API access.</p>"},{"location":"user-guide/#storage","title":"\ud83d\udcbe Storage","text":"<p>Master <code>/arc</code>, VOSpace <code>vault</code>, and scratch storage systems. Learn data transfers, <code>sshfs</code>, and the full VOSpace API.</p>"},{"location":"user-guide/#containers","title":"\ud83d\udc33 Containers","text":"<p>Work with astronomy software containers, build custom environments, and upload to CANFAR Science Platform.</p>"},{"location":"user-guide/#interactive-sessions","title":"\ud83d\udda5\ufe0f Interactive Sessions","text":"<p>Launch Jupyter notebooks, CARTA, Firefly, desktop environments, and contributed applications.</p>"},{"location":"user-guide/#batch-jobs","title":"\u26a1 Batch Jobs","text":"<p>Run \"headless\" containers, understand batch systems, manage logs, and use APIs for automation.</p>"},{"location":"user-guide/#radio-astronomy","title":"\ud83d\udce1 Radio Astronomy","text":"<p>Specialized workflows for CASA, ALMA data reduction, CARTA visualization, and other radio astronomy tools.</p>"},{"location":"user-guide/#choose-your-path","title":"\ud83c\udfaf Choose Your Path","text":""},{"location":"user-guide/#new-users","title":"\ud83c\udf31 New Users","text":"<p>First time using CANFAR?</p> <p>Start with our Getting Started Guide for a structured learning path, then:</p> <ol> <li>Concepts - Understand the platform</li> <li>Storage - Manage your data</li> <li>Interactive Sessions - Start analyzing</li> </ol>"},{"location":"user-guide/#scientists-researchers","title":"\ud83d\udd2c Scientists &amp; Researchers","text":"<p>Ready to analyze data? Jump to your workflow:</p> <ul> <li>\ud83d\udd2d Radio Astronomy - CASA, CARTA workflows and interferometry</li> <li>\ud83d\udcca Interactive Analysis - Jupyter notebooks, Python analysis</li> <li>\ud83d\udda5\ufe0f Desktop Applications - GUI tools, CASA, DS9</li> <li>\ud83d\udcc1 Data Management - Advanced transfer and organization</li> </ul>"},{"location":"user-guide/#advanced-users","title":"\u26a1 Advanced Users","text":"<p>Looking for development and automation?</p> <ul> <li>\ud83d\udc33 Container Usage - Work with and build custom containers</li> <li>\u2699\ufe0f Batch Processing - Automated workflows and APIs</li> <li>\ud83d\udd10 Access Control - Groups and permissions management</li> </ul>"},{"location":"user-guide/#quick-references","title":"\ud83d\udd17 Quick References","text":""},{"location":"user-guide/#platform-access","title":"Platform Access","text":"<ul> <li>CANFAR Portal - Main interface</li> <li>File Manager - Browse storage on <code>/arc</code> and <code>vault</code></li> <li>Group Management - Manage teams and their permissions</li> </ul>"},{"location":"user-guide/#apis-tools","title":"APIs &amp; Tools","text":"<ul> <li>REST API Docs - Programmatic access for <code>skaha</code></li> <li>VOSpace Tools - Advanced data management</li> <li>Container Registry - Container registry for teams (Harbor)</li> </ul>"},{"location":"user-guide/#support","title":"Support","text":"<ul> <li>\ud83d\udcac Discord Community - Community support</li> <li>\ud83d\udce7 Email - Technical support</li> <li>FAQ - Common solutions</li> </ul> <p>Documentation Structure</p> <p>This user guide is organized by workflow rather than by interface. Each section builds on previous concepts, so we recommend reading the Concepts section first if you're new to CANFAR.</p>"},{"location":"user-guide/#citation","title":"Citation","text":"<p>If you use CANFAR Science Platform for your research, please acknowledge CANFAR in publications:</p> <p>Citation</p> <p>The authors acknowledge the use of the Canadian Advanced Network for Astronomy Research (CANFAR) Science Platform. Our work used the facilities of the Canadian Astronomy Data Center, operated by the National Research Council of Canada with the support of the Canadian Space Agency, and CANFAR, a consortium that serves the data-intensive storage, access, and processing needs of university groups and centers engaged in astronomy research. </p> <p>If you need to refer to a paper, you can use this  (SPIE 2024 citation).</p> <p></p>"},{"location":"user-guide/accounts-permissions/","title":"Accounts &amp; Permissions","text":"<p>Managing users, groups, and access control on CANFAR</p> <p>This section covers everything you need to know about user management, group permissions, and access control on the CANFAR platform. Whether you're setting up a new collaboration or managing an existing team, this guide will help you understand and configure permissions effectively.</p> <p>\ud83c\udfaf What You'll Learn</p> <p>By the end of this guide, you'll understand: - How CANFAR's permission system works - How to create and manage research groups - How to control access to files and containers - How to use APIs for programmatic access</p>"},{"location":"user-guide/accounts-permissions/#permissions-system","title":"\ud83d\udd13 Permissions System","text":"<p>CANFAR's permission system is built on several layers that work together to provide secure, flexible access control:</p> <p>Permission Layers</p> <ul> <li>CADC Accounts - Your base identity for accessing Canadian astronomy services</li> <li>Groups - Collections of users for collaborative access </li> <li>Harbor Permissions - Container registry access control</li> <li>ACL (Access Control Lists) - File-level permissions on <code>/arc</code> shared file system</li> <li>API Authentication - Programmatic access control</li> </ul>"},{"location":"user-guide/accounts-permissions/#group-management","title":"\ud83d\udc65 Group Management","text":"<p>Groups are the foundation of collaboration on CANFAR. A group defines who can access shared resources, what projects and storage they can use, and how they can interact.</p>"},{"location":"user-guide/accounts-permissions/#group-hierarchy","title":"Group Hierarchy","text":"<pre><code>graph TD\n    Admin[\"\ud83d\udc51 Group Administrator\"]\n    Members[\"\ud83d\udc64 Group Members\"]\n    Resources[\"\ud83d\udcbe Shared Resources\"]\n\n    Admin --&gt; |\"Manages\"| Members\n    Admin --&gt; |\"Controls access to\"| Resources\n    Members --&gt; |\"Access\"| Resources\n\n    Resources --&gt; Projects[\"\ud83d\udcc1 /arc/projects/groupname/\"]\n    Resources --&gt; Storage[\"\ud83d\udcbe Storage Quotas\"]\n    Resources --&gt; Containers[\"\ud83d\udc33 Container Access\"]</code></pre> <p>Key Concept</p> <p>Groups enable collaborative research by providing shared access to storage, computing resources, and container images while maintaining security boundaries.</p>"},{"location":"user-guide/accounts-permissions/#creating-and-managing-groups","title":"Creating and Managing Groups","text":"<p>Access the Group Management Interface:</p> <p>\ud83d\udd17 CADC Group Management</p>"},{"location":"user-guide/accounts-permissions/#step-1-create-a-new-group","title":"Step 1: Create a New Group","text":"<ol> <li>Click \"New Group\"</li> <li>Provide a meaningful group name (e.g., <code>myproject-team</code>)</li> <li>Add a brief description of the project or collaboration</li> <li>Click \"Create\"</li> </ol>"},{"location":"user-guide/accounts-permissions/#step-2-add-members","title":"Step 2: Add Members","text":"<ol> <li>Find your group in the list</li> <li>Click \"Edit\" in the Membership column</li> <li>Type the name (not username) of your collaborator</li> <li>Select from the search results</li> <li>Click \"Add member\"</li> </ol> <p>Finding Users</p> <p>The search function uses real names, not CADC usernames. Search for \"John Smith\" rather than \"jsmith\".</p>"},{"location":"user-guide/accounts-permissions/#step-3-assign-administrators","title":"Step 3: Assign Administrators","text":"<ol> <li>Click \"Edit\" in the Administrators column  </li> <li>Add users who should be able to manage the group</li> <li>Administrators can add/remove members and modify permissions</li> </ol>"},{"location":"user-guide/accounts-permissions/#member-roles","title":"Member Roles","text":"Role Permissions Best For Administrator Full group management, resource allocation Project PIs, senior team members Member Access shared resources, collaborate Researchers, grad students"},{"location":"user-guide/accounts-permissions/#harbor-permissions","title":"\ud83d\udd10 Harbor Permissions","text":"<p>Harbor is CANFAR's container registry where container images are stored and managed.</p> <p>Registry Access</p> <p>Registry URL: https://images.canfar.net</p>"},{"location":"user-guide/accounts-permissions/#access-levels","title":"Access Levels","text":"Permission Level Can Do Cannot Do Guest Pull public images Push images, see private repos Developer Pull all group images, push to group repos Delete images, manage projects Master Full project management System administration"},{"location":"user-guide/accounts-permissions/#managing-harbor-access","title":"Managing Harbor Access","text":"<p>Harbor permissions are typically managed by CANFAR administrators. Contact support@canfar.net to:</p> <ul> <li>Request access to a project repository</li> <li>Set up a new project for your container images</li> <li>Modify permissions for team members</li> </ul>"},{"location":"user-guide/accounts-permissions/#using-harbor","title":"Using Harbor","text":"<pre><code># Login to Harbor\ndocker login images.canfar.net\n\n# Pull a container\ndocker pull images.canfar.net/skaha/astroml:latest\n\n# Push your container (if you have permissions)\ndocker push images.canfar.net/myproject/custom-container:v1.0\n</code></pre>"},{"location":"user-guide/accounts-permissions/#acl-access-control-lists","title":"\ud83d\udee1\ufe0f Access Control Lists","text":""},{"location":"user-guide/accounts-permissions/#what-are-acls","title":"What are ACLs?","text":"<p>Access Control Lists (ACLs) provide fine-grained file and directory permissions beyond traditional POSIX permissions. While POSIX permissions only support owner/group/other with read/write/execute, ACLs allow you to grant specific permissions to individual users and groups.</p> <p>Important Distinction</p> <p>ACLs extend traditional POSIX permissions, allowing multiple users and groups to have different permissions on the same file or directory.</p>"},{"location":"user-guide/accounts-permissions/#why-acls-matter-in-astronomy","title":"Why ACLs Matter in Astronomy","text":"<p>Traditional POSIX Limitations: - Only one group can own a file - No granular control over multiple collaborators - Difficult to share data across research groups</p> <p>ACL Advantages: - Multiple users and groups can have different permissions on the same file - Grant specific researchers read access to your dataset - Allow collaborators to write to specific directories - Maintain security while enabling flexible collaboration</p> <p>Research Collaboration</p> <p>ACLs enable flexible data sharing across research groups while maintaining security boundaries - perfect for multi-institutional astronomy projects.</p>"},{"location":"user-guide/accounts-permissions/#acl-vs-posix-comparison","title":"ACL vs POSIX Comparison","text":"Scenario POSIX Permissions ACL Permissions Single collaboration <code>rwxrwx---</code> (group access) Same as POSIX Multi-group project Must choose one group Grant specific access to multiple groups Guest researcher access Add to group or world-readable Grant individual read access Selective write access All group members can write Grant write access only to specific users"},{"location":"user-guide/accounts-permissions/#viewing-acls","title":"Viewing ACLs","text":"<pre><code># View ACL permissions\ngetfacl /arc/projects/myproject/sensitive_data/\n\n# Output example:\n# file: sensitive_data/\n# owner: alice\n# group: myproject-team\n# user::rwx\n# user:bob:r--           # Bob has read-only access\n# user:carol:rw-         # Carol can read and write\n# group::r--             # Group has read-only\n# group:external-team:r-- # External group has read access\n# mask::rwx\n# other::---             # No access for others\n</code></pre>"},{"location":"user-guide/accounts-permissions/#setting-acls","title":"Setting ACLs","text":"<pre><code># Grant user 'bob' read access to a directory\nsetfacl -m u:bob:r /arc/projects/myproject/shared_data/\n\n# Grant group 'external-collab' read access\nsetfacl -m g:external-collab:r /arc/projects/myproject/public_results/\n\n# Grant user 'alice' full access to a file\nsetfacl -m u:alice:rw /arc/projects/myproject/scripts/analysis.py\n\n# Remove ACL entry\nsetfacl -x u:bob /arc/projects/myproject/sensitive_data/\n\n# Remove all ACLs\nsetfacl -b /arc/projects/myproject/temp_data/\n</code></pre>"},{"location":"user-guide/accounts-permissions/#acl-best-practices","title":"ACL Best Practices","text":"<p>\ud83d\udcc1 Directory Structure with ACLs:</p> <pre><code>/arc/projects/myproject/\n\u251c\u2500\u2500 public/          # World-readable results\n\u2502   \u2514\u2500\u2500 (ACL: group:world:r)\n\u251c\u2500\u2500 team/           # Full team access\n\u2502   \u2514\u2500\u2500 (ACL: group:myproject-team:rw)\n\u251c\u2500\u2500 admin/          # Admin-only access\n\u2502   \u2514\u2500\u2500 (ACL: user:pi:rw, group:admins:rw)\n\u2514\u2500\u2500 external/       # Controlled external access\n    \u2514\u2500\u2500 (ACL: user:collaborator:r, group:external-team:r)\n</code></pre> <p>ACL Best Practices</p> <ul> <li>Principle of least privilege - Grant minimum necessary access</li> <li>Regular audits - Review ACLs periodically with <code>getfacl</code></li> <li>Document permissions - Keep notes on why specific ACLs were set</li> <li>Use groups when possible - Easier to manage than individual user ACLs</li> </ul>"},{"location":"user-guide/accounts-permissions/#api-authentication","title":"\ud83d\udd0c API Authentication","text":""},{"location":"user-guide/accounts-permissions/#overview","title":"Overview","text":"<p>CANFAR provides REST APIs for programmatic access to platform features. All API calls require proper authentication.</p> <p>API Access</p> <p>APIs enable automation and integration with external tools and workflows.</p>"},{"location":"user-guide/accounts-permissions/#authentication-methods","title":"Authentication Methods","text":""},{"location":"user-guide/accounts-permissions/#method-1-bearer-tokens-recommended","title":"Method 1: Bearer Tokens (Recommended)","text":"<p>Best for: Short-term automation, development, interactive use</p> <pre><code># Get a 48-hour token\ncurl https://ws-cadc.canfar.net/ac/login \\\n  -d \"username=your_username\" \\\n  -d \"password=your_password\"\n\n# Use token in API calls\ncurl -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  https://ws-uv.canfar.net/skaha/v0/session\n</code></pre>"},{"location":"user-guide/accounts-permissions/#method-2-proxy-certificates","title":"Method 2: Proxy Certificates","text":"<p>Best for: Long-term automation, file transfers, production scripts</p> <pre><code># Install CADC utilities\npip install cadcutils\n\n# Generate proxy certificate\ncadc-get-cert -u your_username\n\n# Certificate stored in ~/.ssl/cadcproxy.pem\n# Valid for 10 days, automatically used by CADC tools\n</code></pre>"},{"location":"user-guide/accounts-permissions/#api-examples","title":"API Examples","text":""},{"location":"user-guide/accounts-permissions/#session-management","title":"Session Management","text":"<pre><code># List active sessions\ncurl -H \"Authorization: Bearer TOKEN\" \\\n  https://ws-uv.canfar.net/skaha/v0/session\n\n# Launch new session  \ncurl -H \"Authorization: Bearer TOKEN\" \\\n  -d \"name=my-analysis\" \\\n  -d \"image=images.canfar.net/skaha/astroml:latest\" \\\n  https://ws-uv.canfar.net/skaha/v0/session\n\n# Delete session\ncurl -X DELETE \\\n  -H \"Authorization: Bearer TOKEN\" \\\n  https://ws-uv.canfar.net/skaha/v0/session/SESSION_ID\n</code></pre>"},{"location":"user-guide/accounts-permissions/#file-operations-vospace","title":"File Operations (VOSpace)","text":"<pre><code># List files\ncurl -H \"Authorization: Bearer TOKEN\" \\\n  https://ws-cadc.canfar.net/vospace/nodes/myproject\n\n# Upload file\ncurl -X PUT \\\n  -H \"Authorization: Bearer TOKEN\" \\\n  -H \"Content-Type: application/octet-stream\" \\\n  --data-binary @local_file.fits \\\n  https://ws-cadc.canfar.net/vospace/data/myproject/remote_file.fits\n</code></pre>"},{"location":"user-guide/accounts-permissions/#api-resources","title":"API Resources","text":"Service Documentation Purpose Skaha ws-uv.canfar.net Session management VOSpace CADC VOSpace File operations CADC Auth CADC Services Authentication"},{"location":"user-guide/accounts-permissions/#common-issues","title":"\ud83d\udea8 Common Issues","text":"<p>Troubleshooting Guide</p> <p>These are the most common permission issues and their solutions.</p>"},{"location":"user-guide/accounts-permissions/#problem-permission-denied-accessing-arcprojects","title":"Problem: \"Permission Denied\" accessing <code>/arc/projects/</code>","text":"<p>Cause: Not a member of the project group</p> <p>Solution: 1. Contact project administrator of your team to add you to the group 2. Verify group membership at CADC Group Management</p>"},{"location":"user-guide/accounts-permissions/#problem-cannot-push-to-harbor-container-registry","title":"Problem: Cannot push to Harbor container registry","text":"<p>Cause: Insufficient Harbor permissions</p> <p>Solution: 1. Contact support@canfar.net to request developer access 2. Verify you're logged into Harbor: <code>docker login images.canfar.net</code></p>"},{"location":"user-guide/accounts-permissions/#problem-api-calls-return-401-unauthorized","title":"Problem: API calls return 401 Unauthorized","text":"<p>Cause: Invalid or expired authentication token</p> <p>Solution: 1. Generate new token: <code>curl https://ws-cadc.canfar.net/ac/login -d \"username=...\" -d \"password=...\"</code> 2. Check token format in Authorization header: <code>Bearer YOUR_TOKEN</code></p>"},{"location":"user-guide/accounts-permissions/#problem-acl-changes-not-taking-effect","title":"Problem: ACL changes not taking effect","text":"<p>Cause: ACL mask or inheritance issues</p> <p>Solution: 1. Check effective permissions: <code>getfacl filename</code> 2. Update ACL mask: <code>setfacl -m m::rwx filename</code> 3. Set default ACLs for directories: <code>setfacl -d -m g:groupname:rw directory/</code></p>"},{"location":"user-guide/accounts-permissions/#whats-next","title":"\ud83d\udd17 What's Next?","text":"<p>Now that you understand permissions and access control:</p> <ul> <li>Storage Guide \u2192 - Apply permissions to manage data</li> <li>Container Guide \u2192 - Access and build container images  </li> <li>API Guide \u2192 - Use programmatic access</li> <li>Help &amp; Support \u2192 - Get assistance with user management</li> </ul> <p>Security Reminder</p> <p>Never share your CADC password or authentication tokens. Use group-based permissions for collaboration, and regularly review access permissions for sensitive data.</p>"},{"location":"user-guide/batch-jobs/","title":"Batch Jobs and Headless Processing","text":"<p>Batch jobs enable automated, non-interactive processing of astronomical data at scale. This section covers headless execution, API access, job scheduling, and workflow automation on the CANFAR Science Platform.</p> <p>\ud83c\udfaf What You'll Learn</p> <ul> <li>The difference between headless and interactive containers</li> <li>How to submit jobs via API and Python client</li> <li>Resource planning, queue behavior, and monitoring</li> <li>Best practices for automation, logging, and data management</li> </ul>"},{"location":"user-guide/batch-jobs/#what-is-batch-processing","title":"What is Batch Processing?","text":"<p>Batch processing refers to the execution of computational tasks without user interaction, typically running in the background to process large datasets or perform repetitive analysis tasks. In the context of the CANFAR Science Platform, batch jobs run as headless containers - containerized environments that execute your code without graphical interfaces or interactive terminals.</p>"},{"location":"user-guide/batch-jobs/#headless-vs-interactive-containers","title":"Headless vs Interactive Containers","text":"<p>The key difference between headless and interactive containers lies not in the container images themselves, but in how they are executed. The same container image can be launched in either mode depending on your needs.</p> <p>Headless containers execute a user-specified command or script directly. When you submit a headless job, you specify exactly what command should run - whether it's a Python script, a shell command, or any executable available in the container. The container starts, runs your specified command, and terminates when the command completes. For example, submitting a headless job with the <code>astroml</code> container might execute <code>python /arc/projects/myproject/analysis.py</code> directly.</p> <p>Interactive containers launch predefined interactive services that you can access through your web browser. The same <code>astroml</code> container, when launched interactively, would start Jupyter Lab, providing you with a notebook interface for development and exploration. These containers run indefinitely until you manually stop them, allowing for real-time interaction and iterative development.</p> <p>This distinction makes headless containers ideal for production workflows and automated processing, while interactive containers excel for development, prototyping, and exploratory data analysis.</p>"},{"location":"user-guide/batch-jobs/#overview","title":"Overview","text":"<p>Batch processing is essential for:</p> <ul> <li>Large dataset processing: Handle terabytes of astronomical data</li> <li>Automated pipelines: Run standardized reduction workflows</li> <li>Parameter studies: Execute multiple analysis runs with different parameters</li> <li>Resource optimization: Run during off-peak hours for better performance</li> <li>Reproducible science: Documented, automated workflows</li> </ul> <p>When to Use Batch Jobs</p> <ul> <li>Use interactive sessions to develop and test</li> <li>Switch to headless jobs for production-scale runs</li> <li>Schedule jobs during off-peak hours for faster starts</li> </ul>"},{"location":"user-guide/batch-jobs/#batch-processing-methods","title":"Batch Processing Methods","text":""},{"location":"user-guide/batch-jobs/#1-api-based-execution","title":"1. API-Based Execution","text":"<p>Execute containers programmatically using the CANFAR API:</p> <pre><code># Submit a job via API\ncurl -X POST \"https://ws-uv.canfar.net/skaha/v0/session\" \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"name=data-reduction-job\" \\\n  -d \"image=images.canfar.net/skaha/astroml:latest\" \\\n  -d \"cores=4\" \\\n  -d \"ram=16\" \\\n  -d \"kind=headless\" \\\n  -d \"cmd=python /arc/projects/myproject/scripts/reduce_data.py\"\n</code></pre>"},{"location":"user-guide/batch-jobs/#2-job-submission-scripts","title":"2. Job Submission Scripts","text":"<p>Create shell scripts for common workflows using the API or Python client:</p> <pre><code>#!/bin/bash\n# submit_reduction.sh - API-based job submission\n\n# Set job parameters\nJOB_NAME=\"nightly-reduction-$(date +%Y%m%d)\"\nIMAGE=\"images.canfar.net/skaha/casa:6.5\"\nCMD=\"python /arc/projects/survey/pipelines/reduce_night.py /arc/projects/survey/data/$(date +%Y%m%d)\"\n\n# Submit job via API\ncurl -X POST \"https://ws-uv.canfar.net/skaha/v0/session\" \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"name=$JOB_NAME\" \\\n  -d \"image=$IMAGE\" \\\n  -d \"cores=8\" \\\n  -d \"ram=32\" \\\n  -d \"kind=headless\" \\\n  -d \"cmd=$CMD\"\n</code></pre> <p>Or using the Python skaha client:</p> <pre><code>#!/usr/bin/env python3\n# submit_reduction.py - Python client-based submission\n\nfrom skaha.session import Session\nfrom datetime import datetime\n\n# Initialize session manager\nsession = Session()\n\n# Set job parameters\njob_name = f\"nightly-reduction-{datetime.now().strftime('%Y%m%d')}\"\nimage = \"images.canfar.net/skaha/casa:6.5\"\ndata_path = f\"/arc/projects/survey/data/{datetime.now().strftime('%Y%m%d')}\"\n\n# Submit job\njob_id = session.create(\n    name=job_name,\n    image=image,\n    kind=\"headless\",\n    cores=8,\n    ram=32,\n    cmd=\"python\",\n    args=[\"/arc/projects/survey/pipelines/reduce_night.py\", data_path]\n)\n\nprint(f\"Submitted job: {job_id}\")\n</code></pre>"},{"location":"user-guide/batch-jobs/#3-workflow-automation","title":"3. Workflow Automation","text":"<p>Use workflow managers like Prefect or Snakemake:</p> <pre><code># Snakemake example: workflow.smk\nrule all:\n    input:\n        \"results/final_catalog.fits\"\n\nrule calibrate:\n    input:\n        \"data/raw/{observation}.fits\"\n    output:\n        \"data/calibrated/{observation}.fits\"\n    shell:\n        \"python scripts/calibrate.py {input} {output}\"\n\nrule source_extract:\n    input:\n        \"data/calibrated/{observation}.fits\"\n    output:\n        \"catalogs/{observation}_sources.fits\"\n    shell:\n        \"python scripts/extract_sources.py {input} {output}\"\n</code></pre>"},{"location":"user-guide/batch-jobs/#job-types-and-use-cases","title":"Job Types and Use Cases","text":""},{"location":"user-guide/batch-jobs/#data-reduction-pipelines","title":"Data Reduction Pipelines","text":"<p>Optical/IR Surveys: - Bias, dark, and flat field correction - Astrometric calibration - Photometric calibration - Source extraction and cataloging</p> <p>Radio Astronomy: - Flagging and calibration - Imaging and deconvolution - Spectral line analysis - Polarization processing</p>"},{"location":"user-guide/batch-jobs/#scientific-analysis","title":"Scientific Analysis","text":"<p>Large-scale Surveys: - Cross-matching catalogs - Statistical analysis - Machine learning training - Population studies</p> <p>Time-domain Astronomy: - Light curve analysis - Period finding - Variability classification - Transient detection</p>"},{"location":"user-guide/batch-jobs/#simulation-and-modeling","title":"Simulation and Modeling","text":"<p>N-body Simulations: - Galaxy formation models - Stellar dynamics - Dark matter simulations</p> <p>Synthetic Observations: - Mock catalog generation - Instrument simulation - Survey planning</p>"},{"location":"user-guide/batch-jobs/#resource-planning","title":"Resource Planning","text":""},{"location":"user-guide/batch-jobs/#job-sizing","title":"Job Sizing","text":"<p>Choose appropriate resources based on your workload:</p> Job Type Cores Memory Storage Duration Single image reduction 1-2 4-8GB 10GB 5-30 min Survey night processing 4-8 16-32GB 100GB 1-4 hours Catalog cross-matching 2-4 8-16GB 50GB 30min-2hr ML model training 8-16 32-64GB 200GB 4-24 hours Large simulations 16-32 64-128GB 1TB Days-weeks <p>Queue Behavior</p> <p>Small jobs (\u22644 cores, \u226416GB) start faster. Large jobs (\u226516 cores, \u226564GB) may queue longer. Off-peak hours often improve start times.</p>"},{"location":"user-guide/batch-jobs/#queue-management","title":"Queue Management","text":"<p>Understand job priorities and scheduling:</p> <ul> <li>Small jobs (&lt;4 cores, &lt;16GB): Higher priority, faster start</li> <li>Large jobs (16+ cores, 64GB+): Lower priority, may queue longer</li> <li>Off-peak hours: Better resource availability (evenings, weekends)</li> <li>Resource limits: Per-user and per-group limits apply</li> </ul>"},{"location":"user-guide/batch-jobs/#api-access","title":"API Reference","text":""},{"location":"user-guide/batch-jobs/#method-1-direct-curl-commands","title":"Method 1: Direct curl Commands","text":""},{"location":"user-guide/batch-jobs/#submit-job","title":"Submit Job","text":"<pre><code>curl -X POST \"https://ws-uv.canfar.net/skaha/v0/session\" \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"name=my-analysis-job\" \\\n  -d \"image=images.canfar.net/skaha/astroml:latest\" \\\n  -d \"cores=4\" \\\n  -d \"ram=16\" \\\n  -d \"kind=headless\" \\\n  -d \"cmd=python /arc/projects/myproject/analysis.py\"\n</code></pre>"},{"location":"user-guide/batch-jobs/#list-jobs","title":"List Jobs","text":"<pre><code>curl -X GET \"https://ws-uv.canfar.net/skaha/v0/session\" \\\n  -H \"Authorization: Bearer $TOKEN\"\n</code></pre>"},{"location":"user-guide/batch-jobs/#get-job-status","title":"Get Job Status","text":"<pre><code>curl -X GET \"https://ws-uv.canfar.net/skaha/v0/session/{session-id}\" \\\n  -H \"Authorization: Bearer $TOKEN\"\n</code></pre>"},{"location":"user-guide/batch-jobs/#cancel-job","title":"Cancel Job","text":"<pre><code>curl -X DELETE \"https://ws-uv.canfar.net/skaha/v0/session/{session-id}\" \\\n  -H \"Authorization: Bearer $TOKEN\"\n</code></pre>"},{"location":"user-guide/batch-jobs/#get-job-logs","title":"Get Job Logs","text":"<pre><code>curl -X GET \"https://ws-uv.canfar.net/skaha/v0/session/{session-id}/logs\" \\\n  -H \"Authorization: Bearer $TOKEN\"\n</code></pre>"},{"location":"user-guide/batch-jobs/#get-resource-usage","title":"Get Resource Usage","text":"<pre><code>curl -X GET \"https://ws-uv.canfar.net/skaha/v0/session/{session-id}/stats\" \\\n  -H \"Authorization: Bearer $TOKEN\" | jq .\n</code></pre>"},{"location":"user-guide/batch-jobs/#method-2-python-skaha-client","title":"Method 2: Python skaha Client","text":"<p>The skaha Python client provides a more convenient interface for batch job management and automation.</p>"},{"location":"user-guide/batch-jobs/#installation","title":"Installation","text":"<pre><code>mamba activate base\npip install skaha\n</code></pre>"},{"location":"user-guide/batch-jobs/#basic-python-client-usage","title":"Basic Python Client Usage","text":"<pre><code>from skaha.session import Session\nfrom skaha.image import Image\nimport time\n\n# Initialize session manager\nsession = Session()\n\n# Simple job submission\njob_id = session.create(\n    name=\"python-analysis\",\n    image=\"images.canfar.net/skaha/astroml:latest\",\n    kind=\"headless\",\n    cmd=\"python\",\n    args=[\"/arc/projects/myproject/analysis.py\"]\n)\n\nprint(f\"Submitted job: {job_id}\")\n</code></pre>"},{"location":"user-guide/batch-jobs/#advanced-job-submission","title":"Advanced Job Submission","text":"<pre><code># Job with custom resources and environment\njob_id = session.create(\n    name=\"heavy-computation\",\n    image=\"images.canfar.net/myproject/processor:latest\", \n    kind=\"headless\",\n    cores=8,\n    ram=32,\n    cmd=\"/opt/scripts/heavy_process.sh\",\n    args=[\"/arc/projects/data/large_dataset.h5\", \"/arc/projects/results/\"],\n    env={\n        \"PROCESSING_THREADS\": \"8\",\n        \"OUTPUT_FORMAT\": \"hdf5\",\n        \"VERBOSE\": \"true\"\n    }\n)\n</code></pre>"},{"location":"user-guide/batch-jobs/#private-image-authentication","title":"Private Image Authentication","text":"<pre><code># For private images, set registry authentication\nimport base64\n\nusername = \"your_username\"\ncli_secret = \"your_cli_secret\"\nauth_string = base64.b64encode(f\"{username}:{cli_secret}\".encode()).decode()\n\njob_id = session.create(\n    name=\"private-image-job\",\n    image=\"images.canfar.net/myproject/private:latest\",\n    kind=\"headless\",\n    cmd=\"python /opt/analysis.py\",\n    registry_auth=auth_string\n)\n</code></pre> <p>Private Images</p> <p>For private Harbor projects, ensure your CLI credentials are valid and your account has access to the project repository.</p>"},{"location":"user-guide/batch-jobs/#job-monitoring-and-management","title":"Job Monitoring and Management","text":"<pre><code># List all your sessions\nsessions = session.fetch()\nprint(f\"Active sessions: {len(sessions)}\")\n\n# Get session details\nsession_info = session.fetch(job_id)\nprint(f\"Status: {session_info['status']}\")\nprint(f\"Start time: {session_info['startTime']}\")\n\n# Wait for completion\nwhile True:\n    status = session.fetch(job_id)['status']\n    if status in ['Succeeded', 'Failed', 'Terminated']:\n        print(f\"Job completed with status: {status}\")\n        break\n    time.sleep(30)\n\n# Get logs\nlogs = session.logs(job_id)\nprint(\"Job output:\")\nprint(logs)\n\n# Clean up\nsession.delete(job_id)\n</code></pre>"},{"location":"user-guide/batch-jobs/#bulk-job-management","title":"Bulk Job Management","text":"<pre><code># Submit multiple related jobs\njob_ids = []\nfor i in range(10):\n    job_id = session.create(\n        name=f\"parameter-study-{i}\",\n        image=\"images.canfar.net/skaha/astroml:latest\",\n        kind=\"headless\",\n        cmd=\"python\",\n        args=[\"/arc/projects/study/analyze.py\", f\"--param={i}\"]\n    )\n    job_ids.append(job_id)\n    print(f\"Submitted job {i}: {job_id}\")\n\n# Monitor all jobs\ncompleted = 0\nwhile completed &lt; len(job_ids):\n    completed = 0\n    for job_id in job_ids:\n        status = session.fetch(job_id)['status']\n        if status in ['Succeeded', 'Failed', 'Terminated']:\n            completed += 1\n\n    print(f\"Completed: {completed}/{len(job_ids)}\")\n    if completed &lt; len(job_ids):\n        time.sleep(60)\n\nprint(\"All jobs completed!\")\n</code></pre>"},{"location":"user-guide/batch-jobs/#method-3-higher-level-python-api","title":"Method 3: Higher-Level Python API","text":"<pre><code># Example: Higher-level API for common tasks\nfrom skaha import Session\n\n# Create a session object\nsession = Session()\n\n# Submit a data reduction job\njob_id = session.submit(\n    name=\"data-reduction\",\n    image=\"images.canfar.net/skaha/astroml:latest\",\n    cmd=\"python /arc/projects/myproject/scripts/reduce_data.py\",\n    cores=4,\n    ram=16\n)\n\n# Monitor the job\nsession.monitor(job_id)\n\n# Fetch and print logs\nlogs = session.logs(job_id)\nprint(logs)\n\n# Delete the job after completion\nsession.delete(job_id)\n</code></pre>"},{"location":"user-guide/batch-jobs/#monitoring-and-debugging","title":"Monitoring and Debugging","text":""},{"location":"user-guide/batch-jobs/#log-analysis","title":"Log Analysis","text":"<p>Monitor job progress through logs:</p> <pre><code># Real-time log monitoring\ncurl -s \"https://ws-uv.canfar.net/skaha/v0/session/$SESSION_ID/logs\" \\\n  -H \"Authorization: Bearer $TOKEN\" | tail -f\n\n# Search for errors\ncurl -s \"https://ws-uv.canfar.net/skaha/v0/session/$SESSION_ID/logs\" \\\n  -H \"Authorization: Bearer $TOKEN\" | grep -i error\n</code></pre>"},{"location":"user-guide/batch-jobs/#resource-monitoring","title":"Resource Monitoring","text":"<p>Track resource usage:</p> <pre><code># Get session statistics\ncurl -s \"https://ws-uv.canfar.net/skaha/v0/session/$SESSION_ID/stats\" \\\n  -H \"Authorization: Bearer $TOKEN\" | jq .\n</code></pre>"},{"location":"user-guide/batch-jobs/#common-issues","title":"Common Issues","text":"<p>Job fails to start: - Check resource availability - Verify container image exists - Check command syntax</p> <p>Job crashes: - Review logs for error messages - Check memory usage patterns - Verify input file accessibility</p> <p>Job hangs: - Monitor CPU usage - Check for infinite loops - Verify network connectivity</p>"},{"location":"user-guide/batch-jobs/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/batch-jobs/#script-design","title":"Script Design","text":"<ul> <li>Error handling: Use try-catch blocks and meaningful error messages</li> <li>Logging: Include progress indicators and debugging information</li> <li>Checkpointing: Save intermediate results for long-running jobs</li> <li>Resource monitoring: Track memory and CPU usage</li> </ul>"},{"location":"user-guide/batch-jobs/#data-management","title":"Data Management","text":"<ul> <li>Input validation: Check file existence and format before processing</li> <li>Output organization: Use consistent naming and directory structures</li> <li>Cleanup: Remove temporary files to save storage</li> <li>Metadata: Include processing parameters in output headers</li> </ul> <p>Persistence Reminder</p> <p>Headless containers do not persist changes to the container filesystem. Always write outputs to <code>/arc/projects/</code> or <code>/arc/home/</code>.</p>"},{"location":"user-guide/batch-jobs/#security-and-efficiency","title":"Security and Efficiency","text":"<ul> <li>Token management: Use secure token storage and rotation</li> <li>Resource limits: Don't request more resources than needed</li> <li>Parallel processing: Use appropriate parallelization strategies</li> <li>Cost optimization: Run large jobs during off-peak hours</li> </ul>"},{"location":"user-guide/batch-jobs/#getting-help","title":"Getting Help","text":"<ul> <li>API Documentation: CANFAR API Reference</li> <li>Support: Email support@canfar.net</li> <li>Community: Join our Discord for batch processing discussions</li> <li>Examples: Check the CANFAR GitHub for more examples</li> </ul>"},{"location":"user-guide/batch-jobs/#next-steps","title":"Next Steps","text":"<ul> <li>Container Development: Build custom containers for your workflows</li> <li>Storage Optimization: Efficient data management strategies</li> <li>Interactive Sessions: Develop and test scripts interactively</li> <li>Radio Astronomy Workflows: Specialized batch processing for radio data</li> </ul>"},{"location":"user-guide/concepts/","title":"CANFAR Platform Concepts","text":"<p>Understanding the architecture and core concepts behind the CANFAR Science Platform</p> <p>This section covers the fundamental concepts you need to understand to effectively use CANFAR. Whether you are a student starting your first analysis or a project manager setting up a team workspace, these concepts will help you understand how the platform works.</p> <p>\ud83c\udfaf What You'll Learn</p> <p>By the end of this guide, you'll understand:</p> <ul> <li>How CANFAR's cloud architecture works</li> <li>The role of containers in your research workflow</li> <li>How sessions and storage systems interact</li> <li>When to use different platform features</li> </ul>"},{"location":"user-guide/concepts/#what-is-canfar","title":"\ud83d\ude80 What is CANFAR?","text":"<p>The Canadian Advanced Network for Astronomy Research (CANFAR) Science Platform is a cloud-based computing environment designed specifically for astronomical research. It provides:</p> <ul> <li>On-demand computing resources without needing your own servers</li> <li>Pre-built software environments with astronomy packages ready to use</li> <li>Shared storage systems for collaborative research</li> <li>Scalable infrastructure that grows with your project needs</li> </ul> <p>Key Benefit</p> <p>CANFAR eliminates the traditional barriers of software installation, hardware management, and infrastructure setup, letting you focus entirely on your research.</p>"},{"location":"user-guide/concepts/#who-benefits-from-canfar","title":"Who Benefits from CANFAR?","text":"Individual ResearchersResearch TeamsLarge Projects <ul> <li>No software installation headaches - pre-configured containers ready to use</li> <li>Access powerful computing resources without owning hardware</li> <li>Work from anywhere with just a web browser</li> <li>Automatic backups and data protection</li> </ul> <ul> <li>Share data and analysis environments seamlessly</li> <li>Standardized software stacks across the team</li> <li>Collaborative workspaces and session sharing</li> <li>Centralized project management</li> </ul> <ul> <li>Scale computing resources up or down as needed</li> <li>Batch processing for large datasets</li> <li>Custom software environments for specialized workflows</li> <li>Integration with astronomy data archives</li> </ul>"},{"location":"user-guide/concepts/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<p>CANFAR is built on modern cloud-native technologies designed for scalability and reliability. Here's how the components work together:</p> <pre><code>%%{init: {'flowchart': {'curve': 'linear'}}}%%\ngraph LR\n    %% User Entry Point\n    User[\"\ud83d\udc64 You\"]:::user\n\n    %% Portal Layer\n    Portal[\"\ud83c\udf10 Science Portal&lt;br/&gt;canfar.net\"]:::portal\n    Auth[\"\ud83d\udd10 CADC Authentication\"]:::auth\n    Sessions[\"\ud83d\udda5\ufe0f Session Manager&lt;br/&gt;Skaha\"]:::sessions\n\n    %% Infrastructure Layer\n    K8s[\"\u2638\ufe0f Kubernetes Cluster\"]:::k8s\n    Containers[\"\ud83d\udc33 Container Images&lt;br/&gt;Harbor Registry\"]:::containers\n    Storage[\"\ud83d\udcbe Storage Systems\"]:::storage\n\n    %% Storage Systems\n    arc[\"\ud83d\udcc1 arc Posix Storage&lt;br/&gt;Shared Filesystem\"]:::arc\n    VOSpace[\"\u2601\ufe0f VOSpace Object Store&lt;br/&gt;Long-term Storage\"]:::vospace\n    Scratch[\"\u26a1 Scratch&lt;br/&gt;Temporary SSDs\"]:::scratch\n\n    %% Session Types\n    Types[\"Session Types\"]:::types\n    Notebook[\"\ud83d\udcd3 Jupyter Notebooks\"]:::notebooks\n    Desktop[\"\ud83d\udda5\ufe0f Desktop Environment\"]:::desktop\n    CARTA[\"\ud83d\udcca CARTA Viewer\"]:::carta\n    Firefly[\"\ud83d\udd25 Firefly Viewer\"]:::firefly\n    Contrib[\"\u2699\ufe0f Contributed Apps\"]:::contrib\n    Batch[\"\ud83c\udfed Batch Jobs\"]:::batch\n\n    %% Connections\n    User --&gt; Portal\n    Portal --&gt; Auth\n    Portal --&gt; Sessions\n\n    Auth --&gt; K8s\n    Sessions --&gt; K8s\n\n    K8s --&gt; Containers\n    K8s --&gt; Storage\n\n    Storage --&gt; arc\n    Storage --&gt; VOSpace\n    Storage --&gt; Scratch\n\n    Sessions --&gt; Types\n    Types --&gt; Notebook\n    Types --&gt; Desktop\n    Types --&gt; CARTA\n    Types --&gt; Firefly\n    Types --&gt; Contrib\n    Types --&gt; Batch\n\n    %% Styling\n    classDef user fill:#e3f2fd,stroke:#1976d2,stroke-width:3px,color:#000\n    classDef portal fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000\n    classDef auth fill:#ffebee,stroke:#c62828,stroke-width:2px,color:#000\n    classDef sessions fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px,color:#000\n    classDef k8s fill:#fff3e0,stroke:#ef6c00,stroke-width:3px,color:#000\n    classDef containers fill:#f1f8e9,stroke:#558b2f,stroke-width:2px,color:#000\n    classDef storage fill:#e0f2f1,stroke:#00695c,stroke-width:2px,color:#000\n    classDef arc fill:#fce4ec,stroke:#ad1457,stroke-width:2px,color:#000\n    classDef vospace fill:#f3e5f5,stroke:#6a1b9a,stroke-width:2px,color:#000\n    classDef scratch fill:#fff8e1,stroke:#f57f17,stroke-width:2px,color:#000\n    classDef types fill:#e1f5fe,stroke:#0277bd,stroke-width:2px,color:#000\n    classDef notebooks fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000\n    classDef desktop fill:#e8f5e8,stroke:#388e3c,stroke-width:2px,color:#000\n    classDef carta fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000\n    classDef firefly fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000\n    classDef contrib fill:#e0f2f1,stroke:#00695c,stroke-width:2px,color:#000\n    classDef batch fill:#ffebee,stroke:#d32f2f,stroke-width:2px,color:#000</code></pre> <p>Architecture Key Points</p> <ul> <li>Science Portal: Your web interface - no software installation required</li> <li>Kubernetes: Manages your computing requirements automatically</li> <li>Containers: Pre-built software environments with astronomy tools</li> <li>Storage Systems: Multiple types optimized for different use cases</li> <li>Authentication: Secure access via CADC integration</li> </ul>"},{"location":"user-guide/concepts/#containers","title":"\ud83d\udc33 Containers","text":"<p>Containers are at the heart of CANFAR's flexibility and power. Think of them as complete, portable software environments that include everything needed to run specific applications.</p> <p>Important Distinction</p> <p>Unlike virtual machines that include entire operating systems, containers share the host's kernel and only package the application and its dependencies. This makes them faster, more efficient, and easier to distribute.</p>"},{"location":"user-guide/concepts/#why-containers-matter-for-astronomy","title":"Why Containers Matter for Astronomy","text":"<p>Traditional Software Installation:</p> <ul> <li>Struggle with dependencies and conflicting versions</li> <li>Missing libraries and system requirements</li> <li>Different behavior across different machines</li> <li>Time-consuming setup and configuration</li> </ul> <p>CANFAR Containers:</p> <ul> <li>Consistent environment that works the same everywhere</li> <li>Pre-configured with astronomy packages</li> <li>No installation headaches</li> <li>Easy to share and reproduce results</li> </ul> <p>Research Reproducibility</p> <p>Containers ensure your analysis runs the same way for you, your collaborators, and future researchers. This is crucial for reproducible science.</p>"},{"location":"user-guide/concepts/#popular-canfar-containers","title":"Popular CANFAR Containers","text":"Container Purpose Best For astroml General astronomy analysis Python, NumPy, SciPy, Astropy, Matplotlib casa Radio interferometry CASA software, Python, astronomy tools desktop GUI applications Full Ubuntu desktop, Firefox, terminal carta Radio astronomy visualization CARTA viewer, analysis tools notebook Interactive computing JupyterLab, Python scientific stack <p>Getting Started</p> <p>Start with the astroml container for general astronomy work. It includes most common packages and is regularly updated.</p>"},{"location":"user-guide/concepts/#container-lifecycle","title":"Container Lifecycle","text":"<p>When you launch a session, here's what happens behind the scenes:</p> <ol> <li>Request: You choose a container type in the Science Portal</li> <li>Download: Kubernetes pulls the container image (first time: 2-3 minutes)</li> <li>Launch: Container starts with your storage connected</li> <li>Work: You use the pre-configured environment</li> <li>Cleanup: Container is destroyed when session ends (files persist in storage)</li> </ol> <p>Performance Note</p> <p>Subsequent launches of the same container are much faster (30-60 seconds) since the image is cached locally.</p>"},{"location":"user-guide/concepts/#sessions-and-computing-resources","title":"\u2638\ufe0f Sessions and Computing Resources","text":"<p>CANFAR uses Kubernetes to manage your computing sessions. You don't need to understand Kubernetes deeply, but here are the key concepts:</p> <p>Session Fundamentals</p> <ul> <li>Temporary: Each session creates a new container instance</li> <li>Persistent Data: Files persist through storage systems, not containers</li> <li>Resource Limits: CPU, memory, and storage based on your request</li> </ul>"},{"location":"user-guide/concepts/#session-types","title":"Session Types","text":"<p>Different session types provide different interfaces to the same underlying computing resources:</p> \ud83d\udcd3 Notebook Sessions\ud83d\udda5\ufe0f Desktop Sessions\ud83d\udcca CARTA Sessions\ud83d\udd25 Firefly Sessions\u2699\ufe0f Contributed Sessions <p>JupyterLab Interface for interactive analysis</p> <ul> <li>Perfect for data exploration and visualization</li> <li>Python, R, and other kernels available</li> <li>Rich text, code, and visualization in one interface</li> </ul> <p>Full Linux desktop environment for GUI applications</p> <ul> <li>CASA, DS9, and image viewers</li> <li>Traditional desktop workflow</li> <li>Multiple applications running simultaneously</li> </ul> <p>Specialized for radio astronomy visualization and analysis</p> <ul> <li>CARTA viewer for FITS files</li> <li>Radio astronomy workflows</li> <li>Interactive data exploration</li> </ul> <p>Table and image visualization tools</p> <ul> <li>Astronomical table viewing</li> <li>Image display and analysis</li> <li>Web-based interface</li> </ul> <p>Custom applications contributed by the community</p> <ul> <li>Specialized tools and workflows</li> <li>Community-maintained software</li> <li>Experimental features</li> </ul>"},{"location":"user-guide/concepts/#storage-systems","title":"\ud83d\udcbe Storage Systems","text":""},{"location":"user-guide/concepts/#data-persistence-rules","title":"Data Persistence Rules","text":"<p>CANFAR provides multiple storage systems optimized for different use cases:</p> <p>Critical: Where Your Files Are Saved</p> <p>Understanding where your files persist is crucial for not losing work:</p> Location Persistence Best For <code>/arc/projects/yourgroup/</code> \u2705 Permanent, backed up Datasets, results, shared code <code>/arc/home/yourusername/</code> \u2705 Permanent, backed up Personal configs, small files <code>/scratch/</code> \u274c Wiped at session end Large computations, temporary files <code>/tmp/</code> \u274c Lost when session ends Temporary processing only"},{"location":"user-guide/concepts/#arc-storage-arc","title":"ARC Storage (<code>/arc/</code>)","text":"<p>High-performance POSIX file system for active research:</p> <ul> <li>Speed: Fast, direct access for large computations</li> <li>Sharing: Group-based access control</li> <li>Backup: Daily snapshots</li> <li>Best For: Active analysis, large datasets, collaborative work</li> </ul>"},{"location":"user-guide/concepts/#vospace-vos","title":"VOSpace (<code>vos:</code>)","text":"<p>Web-accessible object store for long-term storage:</p> <ul> <li>IVOA: Based on the International Virtual Observatory Alliance (IVOA) standard</li> <li>Access: Web APIs and command-line tools</li> <li>Metadata: Astronomical metadata support</li> <li>Versioning: Track changes to datasets</li> <li>Best For: Archives, sharing, backups, metadata-rich data</li> </ul> <p>Storage Strategy</p> <p>Use ARC storage for active analysis and VOSpace for long-term archival and sharing.</p>"},{"location":"user-guide/concepts/#storage-comparison","title":"Storage Comparison","text":"Feature ARC Storage (<code>/arc/</code>) VOSpace (<code>vos:</code>) Access Method POSIX file system Web APIs, command tools Speed Fast (direct access) Medium (network-based) Best For Active analysis, large computations Archives, sharing, backups Quota Group-based User/project based Backup Daily snapshots Geo-redundant"},{"location":"user-guide/concepts/#programmatic-access","title":"\ud83c\udf10 Programmatic Access","text":"<p>CANFAR provides REST APIs for programmatic access, allowing you to:</p> <ul> <li>Launch and manage sessions from scripts</li> <li>Transfer files programmatically</li> <li>Integrate CANFAR into automated workflows</li> <li>Build custom applications using CANFAR resources</li> </ul>"},{"location":"user-guide/concepts/#key-api-endpoints","title":"Key API Endpoints","text":"Service Purpose Documentation CANFAR Python Client Session management TBD VOSpace File operations VOSpace API Access Control Authentication and Authorization CADC Services <p>Advanced Users</p> <p>The REST APIs enable automation and integration with external tools and workflows.</p>"},{"location":"user-guide/concepts/#whats-next","title":"\ud83d\udd17 What's Next?","text":"<p>Now that you understand the core concepts, dive into specific areas:</p> <ul> <li>Accounts &amp; Permissions \u2192 - Manage users and access</li> <li>Storage Systems \u2192 - Master data management</li> <li>Container Usage \u2192 - Work with software environments</li> <li>Interactive Sessions \u2192 - Start analyzing data</li> </ul> <p>Key Takeaway</p> <p>CANFAR provides the computing power of a research institution without the infrastructure overhead. Focus on your science - let CANFAR handle the computers, software, and data management.</p>"},{"location":"user-guide/containers/","title":"Containers","text":"<p>Working with astronomy software containers on CANFAR</p> <p>\ud83c\udfaf What You'll Learn</p> <ul> <li>What containers are and how they run on CANFAR</li> <li>How container types map to session types (Notebook, Desktop, Headless)</li> <li>How to choose and use existing containers effectively</li> <li>How containers are categorized (CANFAR-supported, community, team)</li> <li>How to build, manage, version, and distribute custom containers</li> <li>How containers integrate with CANFAR storage and workflows</li> </ul> <p>Containers provide pre-packaged software environments that include everything needed to run astronomy applications. On CANFAR, containers eliminate the \"works on my machine\" problem by ensuring consistent, reproducible computational environments across different sessions and workflows.</p> <p>Key Concept: Reproducible Environments</p> <p>Containers provide consistent, reproducible software environments for astronomy work across sessions and teams.</p>"},{"location":"user-guide/containers/#understanding-canfar-containers","title":"Understanding CANFAR Containers","text":"<p>Think of containers as complete software packages that bundle an operating system (typically Ubuntu Linux), astronomy software like CASA or Python packages, programming tools, system libraries, and environment configuration into a single portable unit. When you launch a session on CANFAR, you're essentially starting up one of these pre-configured environments with your data and home directory automatically mounted and accessible.</p> <p>The container ecosystem on CANFAR follows a layered approach. Base containers provide fundamental tools and the conda package manager, while specialized containers build upon these foundations to offer domain-specific software stacks. This architecture ensures consistency while allowing flexibility for different research needs.</p>"},{"location":"user-guide/containers/#runtime-environment","title":"Runtime Environment","text":"<p>How Containers Run on CANFAR</p> <ul> <li>Containers run as your CADC user (not root)</li> <li><code>/arc/home/[username]</code> is the container's home directory</li> <li>Project directories under <code>/arc/projects/</code> are mounted and accessible</li> <li><code>/scratch/</code> provides high-speed temporary storage</li> </ul> <pre><code># Inside a running container, check your environment\necho $USER                      # Your CADC username\necho $HOME                      # /arc/home/[username]\nls /arc/projects/               # Available project directories\nls /scratch/                    # Temporary high-speed storage\n</code></pre> <p>This runtime setup means there's an important compatibility consideration between code packaged in the container image and code stored on the <code>/arc</code> filesystem. Best practice involves keeping stable, tested code within the container image while placing development scripts and analysis notebooks in your <code>/arc/home</code> or project directories where they can be easily modified and version controlled.</p> <p>Persistence Reminder</p> <p>Software installed inside a running container (e.g., <code>pip install --user</code>) is temporary and lost when the session ends. Keep stable software in the image; keep notebooks/scripts on <code>/arc</code>.</p>"},{"location":"user-guide/containers/#container-types-and-session-integration","title":"Container Types and Session Integration","text":"<p>CANFAR containers are designed to work with different session types, each optimized for specific workflows and interaction patterns.</p>"},{"location":"user-guide/containers/#notebook-containers","title":"Notebook Containers","text":"<p>Notebook containers provide interactive Jupyter environments accessed through your web browser. These containers must include Jupyter Lab and are optimized for data analysis, visualization, and interactive computing. The astroml container exemplifies this type, offering a comprehensive Python astronomy stack with popular packages like Astropy, SciPy, and scikit-learn.</p> <pre><code># Example notebook session - check available packages\nimport astropy\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom astroquery import vizier\n\nprint(f\"Astropy version: {astropy.__version__}\")\nprint(f\"NumPy version: {np.__version__}\")\n\n# Access your data\nimport os\n\ndata_path = f\"/arc/projects/{os.environ.get('PROJECT_NAME', 'myproject')}\"\nprint(f\"Project data at: {data_path}\")\n</code></pre> <p>For GPU-accelerated computing, astroml-cuda includes the CUDA toolkit alongside the standard astronomy libraries, enabling machine learning and image processing workflows that leverage GPU acceleration.</p> <pre><code># Check GPU availability in astroml-cuda container\nimport torch\nimport tensorflow as tf\n\nprint(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n\nprint(f\"TensorFlow GPU devices: {len(tf.config.list_physical_devices('GPU'))}\")\n</code></pre>"},{"location":"user-guide/containers/#desktop-app-containers","title":"Desktop-App Containers","text":"<p>While CANFAR maintains the base desktop container that provides the Ubuntu desktop environment, users can create desktop-app containers that package specific GUI applications to run within desktop sessions. These containers focus on single applications or related tool suites rather than providing complete desktop environments.</p> <pre><code># Example desktop-app container for DS9 image viewer\nFROM ubuntu:22.04\n\n# Install DS9 and dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    saods9 \\\n    x11-apps \\\n    libx11-6 \\\n    libxft2 \\\n    &amp;&amp; apt-get clean \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Create startup script\nRUN echo '#!/bin/bash\\nds9 \"$@\"' &gt; /usr/local/bin/start-ds9 &amp;&amp; \\\n    chmod +x /usr/local/bin/start-ds9\n\n# Default command for desktop session\nCMD [\"/usr/local/bin/start-ds9\"]\n</code></pre> <p>Desktop-app containers are particularly useful for legacy astronomy software, specialized visualization tools, or applications that require specific library versions or configurations. When launched in a desktop session, these applications integrate seamlessly with the desktop environment while maintaining their isolated software dependencies.</p>"},{"location":"user-guide/containers/#headless-containers","title":"Headless Containers","text":"<p>Headless containers run without graphical interfaces and are designed for batch processing and automated workflows. These containers execute through the batch job system and are optimized for non-interactive processing tasks like data reduction pipelines, large-scale analysis, or scheduled computations.</p> <pre><code># Example headless processing container\nFROM images.canfar.net/skaha/astroml:latest\n\n# Install additional processing tools\nUSER root\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    parallel \\\n    rsync \\\n    &amp;&amp; apt-get clean\n\nUSER ${NB_USER}\n\n# Copy processing scripts\nCOPY scripts/ /opt/processing/\nRUN chmod +x /opt/processing/*.sh\n\n# Default processing command\nCMD [\"/opt/processing/batch_process.sh\"]\n</code></pre>"},{"location":"user-guide/containers/#working-with-existing-containers","title":"Working with Existing Containers","text":"<p>Most astronomy work on CANFAR can be accomplished using existing containers without requiring custom builds. The astroml container covers the majority of Python-based astronomy analysis needs, while casa handles radio astronomy workflows. For GUI applications, the desktop container provides a complete environment with Firefox, file managers, and terminal access.</p> <p>Choosing the right container depends on your specific workflow requirements. General Python astronomy work benefits from astroml in either notebook or desktop terminal sessions. Radio astronomy tasks requiring CASA tools work best with the casa container in notebook or desktop modes. Legacy GUI applications or IDL-based workflows should use desktop sessions with the desktop container.</p> <pre><code># Launch different session types via API\nTOKEN=$(curl -s https://ws-cadc.canfar.net/ac/login \\\n  -d \"username=myuser\" -d \"password=mypass\" | tr -d '\"')\n\n# Notebook session with astroml\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  -d \"name=analysis-session\" \\\n  -d \"image=images.canfar.net/skaha/astroml:latest\" \\\n  -d \"type=notebook\" \\\n  -d \"cores=2\" -d \"ram=4\" \\\n  https://ws-uv.canfar.net/skaha/v0/session\n\n# Desktop session with CASA\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  -d \"name=casa-desktop\" \\\n  -d \"image=images.canfar.net/skaha/casa:latest\" \\\n  -d \"type=desktop\" \\\n  -d \"cores=4\" -d \"ram=8\" \\\n  https://ws-uv.canfar.net/skaha/v0/session\n</code></pre> <p>Best Practice: Code Placement</p> <p>Keep stable, tested code inside the container image. Keep frequently edited analysis code and notebooks in <code>/arc/home</code> or project directories.</p> <p>Temporary Installs</p> <p>Software installations using <code>pip install --user</code> or <code>apt</code> inside a running container are temporary and will be lost when the session ends.</p>"},{"location":"user-guide/containers/#container-categories","title":"Container Categories","text":"<p>CANFAR containers fall into three main categories, each serving different purposes and maintained by different groups.</p>"},{"location":"user-guide/containers/#canfar-supported-containers","title":"CANFAR-Supported Containers","text":"<p>These are officially maintained by the CANFAR team and provide the foundation for most astronomy work. The core offerings include astroml for general astronomy analysis with Python, Astropy, and machine learning libraries; casa for radio interferometry work; notebook for lightweight Jupyter environments; and desktop for full Ubuntu desktop sessions with GUI applications.</p> <pre><code># Browse available CANFAR containers\ncurl -s https://images.canfar.net/api/v2.0/projects/skaha/repositories | \\\n  jq -r '.[] | .name' | sort\n\n# Check container details\ndocker inspect images.canfar.net/skaha/astroml:latest\n</code></pre> <p>For specialized visualization needs, CANFAR provides carta for radio astronomy data visualization and firefly for optical and infrared data exploration. These containers receive regular updates and official support from the CANFAR team.</p>"},{"location":"user-guide/containers/#community-maintained-containers","title":"Community-Maintained Containers","text":"<p>The astronomy community contributes specialized containers for emerging tools and workflows. Examples include marimo for modern reproducible notebook environments, vscode for browser-based code development, and pluto for interactive Julia computing. These containers are maintained by community members with oversight from CANFAR.</p>"},{"location":"user-guide/containers/#team-and-individual-containers","title":"Team and Individual Containers","text":"<p>Research groups and individuals can create custom containers for specific projects or workflows. These might include proprietary software, custom analysis pipelines, or specialized configurations needed for particular research programs. While these containers use CANFAR infrastructure, they are maintained by their creators.</p> <pre><code># Example team container structure\nimages.canfar.net/myproject/custom-pipeline:latest\nimages.canfar.net/myteam/analysis-env:v2.1\nimages.canfar.net/user123/specialized-tool:dev\n</code></pre>"},{"location":"user-guide/containers/#harbor-registry-and-distribution","title":"Harbor Registry and Distribution","text":"<p>The Harbor registry at <code>images.canfar.net</code> serves as the central repository for CANFAR containers. Users can browse available containers, examine metadata and documentation, and access containers for their sessions through the registry interface.</p> <p>Container versioning follows semantic patterns with <code>latest</code> tags for current stable releases, dated tags like <code>2024.03</code> for monthly snapshots, and specific commit hashes for development builds. This versioning strategy supports both reproducible research requiring fixed environments and ongoing development needing current software versions.</p> <p>Access to containers varies by category. CANFAR-supported containers are publicly available to all users. Community-maintained containers may have broader access depending on their purpose and licensing. Team and individual containers can be configured with specific access controls to support proprietary or sensitive work.</p>"},{"location":"user-guide/containers/#building-custom-containers","title":"Building Custom Containers","text":"<p>Custom container development becomes necessary when existing containers don't meet specific software requirements or when creating standardized environments for research teams. The process involves creating a Dockerfile that defines the software stack, building and testing the container locally, and pushing it to the Harbor registry for use on CANFAR.</p>"},{"location":"user-guide/containers/#development-workflow","title":"Development Workflow","text":"<p>Successful container development follows an iterative workflow starting with local development and testing. Begin by extending existing CANFAR base images rather than starting from scratch, as this ensures compatibility with the CANFAR runtime environment and includes necessary system configurations.</p> <pre><code># Local development workflow\ngit clone https://github.com/myteam/custom-container.git\ncd custom-container\n\n# Build container locally\ndocker build -t myteam/analysis-env:latest .\n\n# Test locally with mounted data\ndocker run -it --rm \\\n  -v $(pwd)/test-data:/arc/projects/test \\\n  -v $(pwd)/home:/arc/home/testuser \\\n  myteam/analysis-env:latest \\\n  /bin/bash\n</code></pre> <p>Create your Dockerfile starting from an appropriate base image like <code>images.canfar.net/skaha/astroml:latest</code> for astronomy work. Install additional system packages as needed, then switch to the non-root user context for application installations. Python packages should be installed using <code>pip</code> or <code>mamba</code>, while system-level software requires <code>apt</code> or similar package managers during the build process.</p>"},{"location":"user-guide/containers/#container-architecture-considerations","title":"Container Architecture Considerations","text":"<p>All CANFAR containers run on Linux x86_64 architecture and must support the CANFAR user context system. Containers execute as the user who submitted the job, never as root, though they can be configured with sudo access for specific operations during the build process.</p> <p>The container filesystem integrates with CANFAR storage at runtime. The <code>/arc</code> filesystem containing home and project directories is mounted automatically, providing access to persistent data and development code. Temporary high-speed storage is available under <code>/scratch/</code> for intensive processing tasks.</p> <p>When designing containers, separate stable production code that belongs in the container image from development and analysis code that should reside on the <code>/arc</code> filesystem. This separation enables easier maintenance and allows users to modify analysis scripts without rebuilding containers.</p>"},{"location":"user-guide/containers/#building-and-testing-process","title":"Building and Testing Process","text":"<p>Local testing ensures containers work correctly before deployment. Build your container using Docker and test core functionality locally. For notebook containers, verify that Jupyter Lab starts correctly and that key Python packages import properly. Desktop-app containers should be tested to ensure the target application launches and functions as expected.</p> <pre><code># Example notebook container extension\nFROM images.canfar.net/skaha/astroml:latest\n\n# Install additional system dependencies\nUSER root\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    gfortran \\\n    libcfitsio-dev \\\n    &amp;&amp; apt-get clean \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Switch to user context for application installs\nUSER ${NB_USER}\n\n# Install specialized astronomy packages\nRUN pip install --no-cache-dir \\\n    astroplan \\\n    photutils \\\n    reproject\n\n# Set up custom analysis tools\nRUN git clone https://github.com/myteam/analysis-tools.git /tmp/analysis-tools &amp;&amp; \\\n    cd /tmp/analysis-tools &amp;&amp; \\\n    pip install --no-cache-dir -e . &amp;&amp; \\\n    rm -rf /tmp/analysis-tools\n\nWORKDIR ${HOME}\n</code></pre> <pre><code># Example headless processing container\nFROM images.canfar.net/skaha/astroml:latest\n\nUSER root\n\n# Install processing dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    parallel \\\n    imagemagick \\\n    ffmpeg \\\n    &amp;&amp; apt-get clean\n\nUSER ${NB_USER}\n\n# Install Python processing packages\nRUN pip install --no-cache-dir \\\n    dask[complete] \\\n    zarr \\\n    xarray\n\n# Copy processing scripts\nCOPY --chown=${NB_USER}:${NB_GID} scripts/ /opt/processing/\nRUN chmod +x /opt/processing/*.py\n\n# Environment variables for processing\nENV PROCESSING_THREADS=4\nENV OUTPUT_FORMAT=fits\n\n# Default processing entry point\nCMD [\"python\", \"/opt/processing/main.py\"]\n</code></pre> <pre><code># Example desktop-app container for IRAF\nFROM ubuntu:22.04\n\n# Install IRAF and dependencies\nUSER root\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    iraf \\\n    saods9 \\\n    xgterm \\\n    tcsh \\\n    libx11-6 \\\n    libxaw7 \\\n    &amp;&amp; apt-get clean\n\n# Create IRAF user setup\nRUN useradd -m -s /bin/tcsh iraf\nCOPY iraf-setup.cl /home/iraf/\n\n# Setup script for CANFAR desktop session\nRUN echo '#!/bin/bash\\n\\\nexport IRAFARCH=linux64\\n\\\nexport TERM=xgterm\\n\\\ncd /arc/home/$USER\\n\\\nexec xgterm -sb -sl 1000 -j -ls -fn 9x15 -title \"IRAF\" &amp;\\n\\\nexec ds9 &amp;\\n\\\nwait\\n' &gt; /usr/local/bin/start-iraf &amp;&amp; \\\n    chmod +x /usr/local/bin/start-iraf\n\nCMD [\"/usr/local/bin/start-iraf\"]\n</code></pre>"},{"location":"user-guide/containers/#container-management-and-best-practices","title":"Container Management and Best Practices","text":"<p>Effective container management involves following established patterns for reproducibility, maintainability, and performance. Use specific version tags rather than <code>latest</code> for production workflows to ensure consistent environments over time. Layer Docker commands efficiently to minimize image size and build time.</p> <pre><code># Good layering practices\nFROM images.canfar.net/skaha/astroml:latest\n\n# Combine related operations\nUSER root\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    package1 \\\n    package2 \\\n    package3 \\\n    &amp;&amp; apt-get clean \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/* /var/tmp/*\n\nUSER ${NB_USER}\n\n# Pin package versions for reproducibility\nRUN pip install --no-cache-dir \\\n    astroplan==0.8 \\\n    photutils==1.8.0 \\\n    reproject==0.10.0\n\n# Use multi-stage builds for complex installations\nFROM images.canfar.net/skaha/astroml:latest as builder\nCOPY source/ /build/\nRUN cd /build &amp;&amp; make install\n\nFROM images.canfar.net/skaha/astroml:latest\nCOPY --from=builder /build/bin/* /usr/local/bin/\n</code></pre> <pre><code># Version management\ndocker tag myproject/tool:latest myproject/tool:v1.2.3\ndocker tag myproject/tool:latest myproject/tool:2024.03\n\n# Automated builds with GitHub Actions\ncat &gt; .github/workflows/build.yml &lt;&lt; 'EOF'\nname: Build Container\non:\n  push:\n    tags: ['v*']\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v3\n    - name: Build and push\n      run: |\n        docker build -t images.canfar.net/myproject/tool:${{ github.ref_name }} .\n        docker login images.canfar.net -u ${{ secrets.HARBOR_USER }} -p ${{ secrets.HARBOR_TOKEN }}\n        docker push images.canfar.net/myproject/tool:${{ github.ref_name }}\nEOF\n</code></pre> <p>Keep containers focused on their primary purpose rather than creating monolithic images that attempt to solve every possible use case. This approach makes containers easier to maintain and debug while providing clearer upgrade paths.</p> <p>For team containers, establish clear documentation including purpose, usage examples, and maintenance responsibilities. Version containers systematically and maintain compatibility with CANFAR's evolving infrastructure through regular updates and testing.</p> <pre><code># Container documentation template (README.md)\n# Custom Astronomy Analysis Container\n\n## Purpose\nThis container provides a specialized environment for X-ray astronomy analysis.\n\n## Usage\n```bash\n# Launch notebook session\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  -d \"image=images.canfar.net/myteam/xray-analysis:latest\" \\\n  -d \"type=notebook\" \\\n  https://ws-uv.canfar.net/skaha/v0/session\n</code></pre>"},{"location":"user-guide/containers/#included-software","title":"Included Software","text":"<ul> <li>XSPEC 12.12.1</li> <li>PyXspec</li> <li>Custom analysis tools v2.1</li> </ul>"},{"location":"user-guide/containers/#maintenance","title":"Maintenance","text":"<ul> <li>Maintainer: team@institution.edu</li> <li>Update schedule: Monthly</li> <li>Source: https://github.com/myteam/xray-container ```</li> </ul> <p>Regular maintenance includes updating base images, refreshing software dependencies, and testing compatibility with new CANFAR features. Community-maintained containers benefit from collaborative development practices including shared repositories and issue tracking.</p>"},{"location":"user-guide/containers/#integration-with-canfar-workflows","title":"Integration with CANFAR Workflows","text":"<p>Containers integrate seamlessly with CANFAR's interactive sessions and batch processing systems. Interactive sessions launch containers with full access to mounted storage and appropriate resource allocations. Batch jobs use headless containers for automated processing with results written back to persistent storage.</p> <p>The container system supports different resource configurations including CPU, memory, and GPU allocations based on computational requirements. GPU-enabled containers like astroml-cuda automatically gain access to GPU resources when launched on appropriate hardware nodes.</p> <p>Session persistence allows users to return to running containers across browser sessions while maintaining computational state. However, containers themselves are ephemeral - when sessions end, any changes made within the container filesystem are lost. This design encourages proper separation between stable container environments and dynamic analysis code.</p> <p>Understanding this integration helps optimize workflows by leveraging container strengths while working within system constraints. Plan computational workflows to use containers for consistent software environments while storing results, code, and data on the persistent <code>/arc</code> filesystem.</p> <p>Continue exploring CANFAR capabilities through Interactive Sessions for hands-on container usage, Batch Jobs for automated processing, or Storage Management for data organization strategies.</p>"},{"location":"user-guide/interactive-sessions/","title":"Interactive Sessions","text":"<p>Launch and manage interactive computing environments on CANFAR</p> <p>\ud83c\udfaf What You'll Learn</p> <ul> <li>The differences between session types and when to use each</li> <li>How to launch and connect to sessions quickly</li> <li>How to size resources (RAM/CPU/GPU) appropriately</li> <li>How to manage, share, and troubleshoot sessions</li> </ul> <p>Interactive sessions provide web-based access to powerful computing resources with different interfaces optimized for specific workflows. Whether you're analyzing data in Jupyter notebooks, visualizing radio astronomy images, or running GUI applications, CANFAR's interactive sessions make it easy to get started.</p>"},{"location":"user-guide/interactive-sessions/#session-types-overview","title":"\ud83c\udfaf Session Types Overview","text":"<p>CANFAR supports multiple session types, each optimized for different research workflows:</p> Session Type Interface Best For Key Features \ud83d\udcd3 Notebook JupyterLab Data analysis, coding, documentation Interactive Python, visualization, markdown \ud83d\udda5\ufe0f Desktop Linux desktop GUI applications, legacy software Full desktop environment, X11 apps \ud83d\udcca CARTA CARTA viewer Radio astronomy visualization Cube analysis, region tools, catalogs \ud83d\udd25 Firefly Firefly viewer Optical data, table visualization Image viewer, catalog overlay, cutouts \u2699\ufe0f Contributed Various Community applications Specialized tools, custom interfaces"},{"location":"user-guide/interactive-sessions/#quick-start-guide","title":"\ud83d\ude80 Quick Start Guide","text":""},{"location":"user-guide/interactive-sessions/#step-1-access-the-science-portal","title":"Step 1: Access the Science Portal","text":"<ol> <li>Login to CANFAR Portal</li> <li>Navigate to \"Science Portal\" </li> <li>Click the plus sign (+) to create a new session</li> </ol>"},{"location":"user-guide/interactive-sessions/#step-2-choose-session-type","title":"Step 2: Choose Session Type","text":"<p>Select the interface that best matches your workflow:</p> \ud83d\udcd3 Data Analysis\ud83d\udce1 Radio Astronomy\ud83d\udda5\ufe0f GUI Applications\ud83d\udd2c Table Analysis <p>Session Type: <code>notebook</code> Container: <code>astroml</code> Use Case: Python analysis, Jupyter notebooks, data exploration</p> <p>Session Type: <code>carta</code> Container: <code>carta</code> Use Case: Radio cube visualization, source analysis, imaging</p> <p>Session Type: <code>desktop</code> Container: <code>desktop</code> or <code>astroml</code> Use Case: CASA, DS9, image viewers, legacy tools</p> <p>Session Type: <code>firefly</code> Container: <code>firefly</code> Use Case: Optical data, catalog overlays, image cutouts</p>"},{"location":"user-guide/interactive-sessions/#step-3-configure-resources","title":"Step 3: Configure Resources","text":"<p>Session Name: Choose a descriptive name (e.g., \"galaxy-photometry\", \"alma-reduction\")</p> <p>Choosing Resources</p> <ul> <li>Start with defaults (2 cores, 8 GB RAM). Scale up only if needed</li> <li>Large data cubes or catalogs benefit from 32GB+ RAM</li> <li>GPU is only needed for ML or specialized GPU-enabled workflows</li> </ul> <p>Memory (RAM): - 8GB: Light analysis, small datasets - 16GB: Default, suitable for most work - 32GB+: Large datasets, memory-intensive tasks</p> <p>CPU Cores: - 2 cores: Default, recommended for most tasks - 4+ cores: Parallel processing, intensive computations</p> <p>GPU (if available): - None: Standard CPU-only work - 1 GPU: Machine learning, image processing</p>"},{"location":"user-guide/interactive-sessions/#step-4-launch-and-connect","title":"Step 4: Launch and Connect","text":"<ol> <li>Click \"Launch\" and wait for initialization (~30-60 seconds)</li> <li>Session appears on your portal dashboard</li> <li>Click the session icon to connect</li> <li>Start working in your interactive environment</li> </ol>"},{"location":"user-guide/interactive-sessions/#session-management","title":"\ud83d\udcf1 Session Management","text":""},{"location":"user-guide/interactive-sessions/#session-lifecycle","title":"Session Lifecycle","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Launching: Click Launch\n    Launching --&gt; Running: Session ready\n    Running --&gt; Running: Working\n    Running --&gt; Suspended: Close browser\n    Suspended --&gt; Running: Reconnect\n    Running --&gt; Terminated: Delete session\n    Terminated --&gt; [*]\n\n    note right of Running: Access from any device\n    note right of Suspended: Session continues running</code></pre>"},{"location":"user-guide/interactive-sessions/#session-limits","title":"Session Limits","text":"Limit Value Notes Concurrent sessions 3 active sessions Across all interactive session types Session duration 4 days maximum Can be renewed indefinitely Idle timeout None Sessions run until manually deleted Storage Persistent Files saved to <code>/arc/</code> persist"},{"location":"user-guide/interactive-sessions/#managing-active-sessions","title":"Managing Active Sessions","text":""},{"location":"user-guide/interactive-sessions/#from-the-science-portal","title":"From the Science Portal","text":"<ul> <li>View all sessions: Portal dashboard shows active sessions</li> <li>Connect to session: Click session icon</li> <li>Extend session: Use \"Renew\" button before expiration</li> <li>Delete session: Click \"X\" to terminate and free resources</li> </ul>"},{"location":"user-guide/interactive-sessions/#from-command-line","title":"From Command Line","text":"<pre><code># List your active sessions\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  https://ws-uv.canfar.net/skaha/v0/session\n\n# Delete specific session\ncurl -X DELETE \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  https://ws-uv.canfar.net/skaha/v0/session/SESSION_ID\n</code></pre>"},{"location":"user-guide/interactive-sessions/#session-sharing","title":"Session Sharing","text":"<p>Share running sessions with collaborators in your group:</p> <ol> <li>Copy session URL from browser address bar</li> <li>Share with team member (must be in same CANFAR group)</li> <li>Collaborate in real-time - both can see and modify the same session</li> </ol> <p>Security Note</p> <p>Only share session URLs with trusted collaborators. Anyone with the URL and proper group membership can access your session.</p>"},{"location":"user-guide/interactive-sessions/#advanced-session-features","title":"\ud83d\udd27 Advanced Session Features","text":""},{"location":"user-guide/interactive-sessions/#resource-allocation","title":"Resource Allocation","text":""},{"location":"user-guide/interactive-sessions/#memory-management","title":"Memory Management","text":"<pre><code># Check memory usage in session\nfree -h\nhtop\n\n# Monitor specific process\nps aux | grep python\n</code></pre> <p>Memory Tips: - Start with default 16GB, increase if needed - Large datasets may require 32GB+  - Memory is shared - be considerate of other users</p>"},{"location":"user-guide/interactive-sessions/#cpu-usage","title":"CPU Usage","text":"<pre><code># Check CPU cores available\nnproc\n\n# Monitor CPU usage\ntop\nhtop\n\n# Run parallel processing\npython -c \"import multiprocessing; print(f'CPUs: {multiprocessing.cpu_count()}')\"\n</code></pre>"},{"location":"user-guide/interactive-sessions/#gpu-access","title":"GPU Access","text":"<p>For containers with GPU support (e.g., <code>astroml-cuda</code>):</p> <pre><code># Check GPU availability\nnvidia-smi\n\n# Test GPU in Python\npython -c \"import torch; print(f'CUDA available: {torch.cuda.is_available()}')\"\n\n# Monitor GPU usage\nwatch -n 1 nvidia-smi\n</code></pre>"},{"location":"user-guide/interactive-sessions/#persistent-configuration","title":"Persistent Configuration","text":"<p>Save personal settings that persist across sessions:</p> <pre><code># Jupyter configuration\nmkdir -p /arc/home/$USER/.jupyter\ncp jupyter_config.py /arc/home/$USER/.jupyter/\n\n# Shell configuration\necho \"alias ll='ls -la'\" &gt;&gt; /arc/home/$USER/.bashrc\n\n# Python packages (user installation)\npip install --user astroplan # in some containers, the --user may not be needed\n</code></pre>"},{"location":"user-guide/interactive-sessions/#session-networking","title":"Session Networking","text":""},{"location":"user-guide/interactive-sessions/#port-forwarding","title":"Port Forwarding","text":"<p>For custom web applications running in sessions:</p> <pre><code># In session: Run application on specific port\npython -m http.server 8080\n\n# Application accessible at: https://SESSION_URL/proxy/8080/\n</code></pre>"},{"location":"user-guide/interactive-sessions/#external-access","title":"External Access","text":"<p>Sessions are accessible from anywhere with proper authentication:</p> <ul> <li>Same computer: Original browser window</li> <li>Different computer: Copy session URL, login with CADC credentials  </li> <li>Mobile device: Session URL works in mobile browsers</li> </ul>"},{"location":"user-guide/interactive-sessions/#security-and-best-practices","title":"\ud83d\udee1\ufe0f Security and Best Practices","text":""},{"location":"user-guide/interactive-sessions/#data-security","title":"Data Security","text":"<p>\u2705 Do: - Save important work to <code>/arc/projects/</code> or <code>/arc/home/</code> - Use group permissions for collaborative data - Regularly save and backup critical results - Log out of shared computers</p> <p>\u274c Don't: - Store sensitive data in <code>/scratch/</code> (wiped at session end) - Share session URLs publicly - Leave sessions running unnecessarily - Store passwords in plain text files</p>"},{"location":"user-guide/interactive-sessions/#performance-optimization","title":"Performance Optimization","text":""},{"location":"user-guide/interactive-sessions/#session-performance","title":"Session Performance","text":"<pre><code># Close unused applications to free memory\n# Kill runaway processes\nkill -9 PID\n\n# Clean temporary files\nrm -rf /scratch/temp_*\n</code></pre>"},{"location":"user-guide/interactive-sessions/#storage-performance","title":"Storage Performance","text":"<pre><code># Use /scratch/ for intensive I/O\ncp /arc/projects/data.fits /scratch/\n# ... process in /scratch/ ...\ncp /scratch/results.fits /arc/projects/\n\n# Compress large files\ngzip large_dataset.fits\n</code></pre>"},{"location":"user-guide/interactive-sessions/#troubleshooting-common-issues","title":"Troubleshooting Common Issues","text":""},{"location":"user-guide/interactive-sessions/#session-wont-start","title":"Session Won't Start","text":"<p>Problem: Session stuck in \"Launching\" state</p> <p>Solutions: 1. Check resource availability - try lower memory/CPU 2. Wait 2-3 minutes for container download 3. Try different container image 4. Contact support if persistent</p>"},{"location":"user-guide/interactive-sessions/#session-disconnected","title":"Session Disconnected","text":"<p>Problem: Lost connection to running session</p> <p>Solutions: 1. Refresh browser page 2. Click session icon again from portal 3. Check internet connection 4. Clear browser cache if needed</p>"},{"location":"user-guide/interactive-sessions/#out-of-memory-errors","title":"Out of Memory Errors","text":"<p>Problem: Application crashes with memory errors</p> <p>Solutions: 1. Launch new session with more memory 2. Process data in smaller chunks 3. Use <code>/scratch/</code> for temporary files 4. Optimize code for memory efficiency</p>"},{"location":"user-guide/interactive-sessions/#slow-performance","title":"Slow Performance","text":"<p>Problem: Session responding slowly</p> <p>Solutions: 1. Check system resources (<code>htop</code>, <code>free -h</code>) 2. Close unnecessary applications 3. Use <code>/scratch/</code> for I/O intensive tasks 4. Consider launching session with more resources</p>"},{"location":"user-guide/interactive-sessions/#session-specific-guides","title":"\ud83d\udd17 Session-Specific Guides","text":"<p>Detailed guides for each session type:</p> <ul> <li>\ud83d\udcd3 Jupyter Notebooks \u2192 - Interactive data analysis and visualization</li> <li>\ud83d\udda5\ufe0f Desktop Environment \u2192 - GUI applications and legacy software</li> <li>\ud83d\udcca CARTA Viewer \u2192 - Radio astronomy cube visualization</li> <li>\ud83d\udd25 Firefly Viewer \u2192 - LSST image and table visualization  </li> <li>\u2699\ufe0f Contributed Apps \u2192 - Community-developed tools</li> </ul>"},{"location":"user-guide/interactive-sessions/#whats-next","title":"\ud83d\udd17 What's Next?","text":"<p>Once you're comfortable with interactive sessions:</p> <ul> <li>Storage Guide \u2192 - Manage data across sessions</li> <li>Batch Jobs \u2192 - Automate workflows  </li> <li>Container Guide \u2192 - Customize software environments</li> <li>Radio Astronomy \u2192 - Specialized workflows</li> </ul> <p>Session Success Tips</p> <ol> <li>Start small - Use default resources and scale up if needed</li> <li>Save frequently - Important work should go in <code>/arc/</code> directories  </li> <li>Share wisely - Session URLs are powerful - only share with trusted collaborators</li> <li>Monitor resources - Keep an eye on memory and CPU usage with <code>htop</code></li> <li>Clean up - Delete finished sessions to free resources for others</li> </ol>"},{"location":"user-guide/interactive-sessions/launch-carta/","title":"Launching CARTA Sessions","text":"<p>CARTA (Cube Analysis and Rendering Tool for Astronomy) is a specialized image visualization and analysis tool designed for radio astronomy data. This guide walks you through launching and using CARTA sessions on the CANFAR Science Platform.</p> <p>\ud83c\udfaf What You'll Learn</p> <ul> <li>How to launch a CARTA session and choose the right version</li> <li>How to size RAM/CPU for your datasets</li> <li>How to load data from <code>/arc</code> and work with radio data cubes</li> <li>Tips for analysis features, performance, and troubleshooting</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-carta/#overview","title":"Overview","text":"<p>CARTA provides advanced features for:</p> <ul> <li>Image visualization: Multi-dimensional data cube exploration</li> <li>Spectral analysis: Line profiles and moment maps</li> <li>Region analysis: Statistical analysis of image regions</li> <li>Animation: Time-series and frequency animations</li> <li>Collaboration: Real-time session sharing</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-carta/#creating-a-carta-session","title":"Creating a CARTA Session","text":""},{"location":"user-guide/interactive-sessions/launch-carta/#step-1-select-session-type","title":"Step 1: Select Session Type","text":"<p>From the Science Portal dashboard, click the plus sign (+) to create a new session,  then select carta as your session type.</p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-carta/#step-2-choose-container-version","title":"Step 2: Choose Container Version","text":"<p>Note that the menu options update automatically after your session type selection.  Choose the CARTA version that meets your needs:</p> <ul> <li>CARTA 4.0 (recommended): Latest features and bug fixes (The screenshot is old and showed older versions only.) <p></p> </li> </ul>"},{"location":"user-guide/interactive-sessions/launch-carta/#step-3-configure-session","title":"Step 3: Configure Session","text":""},{"location":"user-guide/interactive-sessions/launch-carta/#session-name","title":"Session Name","text":"<p>Give your session a descriptive name that will help you identify it later  (e.g., \"m87-analysis\", \"ngc-1300-cube\").</p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-carta/#memory-configuration","title":"Memory Configuration","text":"<p>Select the maximum amount of RAM for your analysis. Choose the smallest value  reasonable for your needs, as resources are shared among all users:</p> <ul> <li>8GB: Small images and simple analysis</li> <li>16GB (default): Most radio astronomy datasets</li> <li>32GB+: Large data cubes or complex multi-image analysis</li> </ul> <p>Choosing Resources</p> <p>Start with 8GB RAM and 2 CPU cores. Increase memory for very large FITS or CASA images and increase cores for CPU-intensive operations like moment map generation.</p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-carta/#cpu-cores","title":"CPU Cores","text":"<p>Select the number of computing cores. CARTA can benefit from multiple cores  for certain operations:</p> <ul> <li>1 core: Basic image viewing</li> <li>2 cores (default): Recommended for most tasks</li> <li>4+ cores: Large data processing and animations</li> </ul> <p></p>"},{"location":"user-guide/interactive-sessions/launch-carta/#step-4-launch-session","title":"Step 4: Launch Session","text":"<p>Click the Launch button and wait for your session to initialize.</p> <p></p> <p>Your session will appear on the Science Portal dashboard with your chosen name.  Click the CARTA icon to access your session.</p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-carta/#using-carta","title":"Using CARTA","text":""},{"location":"user-guide/interactive-sessions/launch-carta/#initial-setup","title":"Initial Setup","text":"<p>Wait for CARTA to load completely. You'll see the main CARTA interface:</p> <p></p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-carta/#loading-data","title":"Loading Data","text":""},{"location":"user-guide/interactive-sessions/launch-carta/#navigate-to-your-files","title":"Navigate to Your Files","text":"<ol> <li>Click the folder icon in the upper left to navigate directories</li> <li>Browse to your data location:</li> <li>Project data: <code>/arc/projects/[group]/</code></li> <li>Personal data: <code>/arc/home/[username]/</code></li> </ol>"},{"location":"user-guide/interactive-sessions/launch-carta/#load-an-image","title":"Load an Image","text":"<ol> <li>Navigate through the directory structure to find your FITS file</li> <li>Select the file you want to visualize</li> <li>Click the Load button</li> </ol>"},{"location":"user-guide/interactive-sessions/launch-carta/#basic-operations","title":"Basic Operations","text":""},{"location":"user-guide/interactive-sessions/launch-carta/#image-display","title":"Image Display","text":"<p>Once loaded, your image appears in the main viewer with:</p> <ul> <li>Zoom controls: Mouse wheel or toolbar buttons</li> <li>Pan: Click and drag to move around the image</li> <li>Colormap: Adjust scaling and color scheme</li> </ul> <p></p>"},{"location":"user-guide/interactive-sessions/launch-carta/#data-cube-navigation","title":"Data Cube Navigation","text":"<p>For 3D data cubes:</p> <ul> <li>Channel slider: Navigate through frequency/velocity channels</li> <li>Animation controls: Play through channels automatically</li> <li>Spectral profile: Click on pixels to see spectral information</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-carta/#region-analysis","title":"Region Analysis","text":"<p>Create analysis regions:</p> <ol> <li>Select region tools from the toolbar</li> <li>Draw regions on your image</li> <li>View statistics in the statistics panel</li> <li>Export region data if needed</li> </ol>"},{"location":"user-guide/interactive-sessions/launch-carta/#advanced-features","title":"Advanced Features","text":""},{"location":"user-guide/interactive-sessions/launch-carta/#moment-maps","title":"Moment Maps","text":"<p>Create moment maps from data cubes:</p> <ol> <li>Load your data cube</li> <li>Go to File \u2192 Generate Moment Map</li> <li>Select moment type (0, 1, or 2)</li> <li>Set channel range</li> <li>Generate and display</li> </ol>"},{"location":"user-guide/interactive-sessions/launch-carta/#spectral-line-analysis","title":"Spectral Line Analysis","text":"<p>Analyze spectral profiles:</p> <ol> <li>Click on any pixel to see the spectrum</li> <li>Use the spectral profiler for detailed analysis</li> <li>Fit Gaussian profiles to lines</li> <li>Measure line properties</li> </ol>"},{"location":"user-guide/interactive-sessions/launch-carta/#contour-overlays","title":"Contour Overlays","text":"<p>Add contour overlays:</p> <ol> <li>Load a second image</li> <li>Go to View \u2192 Contours</li> <li>Adjust contour levels and styling</li> <li>Overlay on your main image</li> </ol>"},{"location":"user-guide/interactive-sessions/launch-carta/#session-sharing","title":"Session Sharing","text":""},{"location":"user-guide/interactive-sessions/launch-carta/#real-time-collaboration","title":"Real-time Collaboration","text":"<p>Share your CARTA session with collaborators:</p> <ol> <li>Click the session menu</li> <li>Select \"Share Session\"</li> <li>Add collaborator usernames</li> <li>Set permissions (view-only or full control)</li> </ol>"},{"location":"user-guide/interactive-sessions/launch-carta/#export-and-save","title":"Export and Save","text":"<p>Save your work:</p> <ul> <li>Export images: File \u2192 Export Image (PNG, JPEG, PDF)</li> <li>Save regions: File \u2192 Export Regions (DS9, CRTF formats)</li> <li>Save session: File \u2192 Save Layout (restore later)</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-carta/#data-format-support","title":"Data Format Support","text":"<p>CARTA supports multiple astronomical image formats:</p> <ul> <li>FITS: Standard astronomical format</li> <li>CASA images: Radio astronomy standard</li> <li>HDF5: Large dataset format</li> <li>MIRIAD: Legacy radio format</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-carta/#performance-tips","title":"Performance Tips","text":""},{"location":"user-guide/interactive-sessions/launch-carta/#optimization","title":"Optimization","text":"<ul> <li>Close unused images: Reduces memory usage</li> <li>Use appropriate data types: Float32 vs Float64</li> <li>Enable GPU acceleration: For supported operations</li> <li>Adjust cache settings: Balance memory vs speed</li> </ul> <p>Large Data Cubes</p> <p>Very large cubes can consume significant memory. Load subregions, work with decimated data, or increase RAM to avoid crashes.</p>"},{"location":"user-guide/interactive-sessions/launch-carta/#large-dataset-handling","title":"Large Dataset Handling","text":"<p>For very large files:</p> <ul> <li>Use decimation: View subsampled versions first</li> <li>Load subregions: Focus on areas of interest</li> <li>Consider preprocessing: Use CASA to create smaller working files</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-carta/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/interactive-sessions/launch-carta/#common-issues","title":"Common Issues","text":"<p>CARTA won't load - Check browser compatibility (Chrome/Firefox recommended) - Disable browser extensions that might interfere - Clear browser cache and cookies</p> <p>Performance problems - Reduce image size or resolution - Close other applications - Check available memory</p> <p>File loading errors - Verify file format compatibility - Check file permissions in storage - Ensure file isn't corrupted</p> <p>Display issues - Try different colormaps - Adjust image scaling - Check graphics driver compatibility</p>"},{"location":"user-guide/interactive-sessions/launch-carta/#getting-help","title":"Getting Help","text":"<ul> <li>CARTA Documentation: carta.casa.nrao.edu</li> <li>Support: Email support@canfar.net</li> <li>Community: Join our Discord for CARTA tips and tricks</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-carta/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/interactive-sessions/launch-carta/#workflow-organization","title":"Workflow Organization","text":"<ul> <li>Organize data: Keep raw and processed data separate</li> <li>Document analysis: Save session layouts for reproducibility</li> <li>Version control: Track analysis parameters and results</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-carta/#resource-management","title":"Resource Management","text":"<ul> <li>Monitor usage: Check memory consumption during analysis</li> <li>Clean up: Close sessions when finished</li> <li>Share efficiently: Use view-only sharing when appropriate</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-carta/#next-steps","title":"Next Steps","text":"<ul> <li>Radio Astronomy Workflows: CARTA in radio astronomy pipelines</li> <li>Batch Processing: Automate CARTA operations</li> <li>CASA Integration: Combine CARTA with CASA analysis</li> <li>Desktop Sessions: Full desktop environment with CARTA</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-contributed/","title":"Launching Contributed Applications","text":"<p>Access community-developed tools and specialized research applications</p> <p>\ud83c\udfaf What You'll Learn</p> <ul> <li>What contributed applications are and when to use them</li> <li>How to launch and size contributed application sessions</li> <li>How these apps integrate with CANFAR storage and authentication</li> <li>Best practices for collaboration, performance, and security</li> </ul> <p>Contributed applications represent an exciting expansion of CANFAR's capabilities beyond the standard notebook and desktop environments. These specialized tools have been developed by the CANFAR community and external collaborators to address specific astronomical workflows and research needs that aren't well-served by conventional interfaces.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#contributed-apps","title":"\ud83c\udfaf Contributed Apps","text":"<p>Think of contributed applications as purpose-built web tools that seamlessly integrate with CANFAR's infrastructure while offering unique capabilities. Unlike the general-purpose notebook or desktop sessions you might be familiar with, these applications are crafted for specific tasks and often provide interfaces that would be difficult or impossible to replicate in standard environments.</p> <p>These applications extend CANFAR's reach by providing specialized interfaces for targeted research tasks, integrating naturally with CANFAR's storage and authentication systems, and offering workflows that leverage the unique aspects of web-based scientific computing. What makes them particularly valuable is how they support community innovation and enable researchers to share specialized tools with colleagues worldwide.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#the-landscape-of-contributed-applications","title":"The Landscape of Contributed Applications","text":"<p>Current Ecosystem</p> <p>The catalog evolves regularly. Expect reactive notebooks (Pluto.jl, Marimo), browser IDEs (VSCode), and specialized computational interfaces contributed by the community.</p> <p>The current ecosystem of contributed applications focuses on interactive computing environments that offer alternatives to traditional Jupyter notebooks. You'll find reactive notebook systems that provide real-time feedback as you modify code, browser-based development environments that give you the full power of modern IDEs without local installation, and specialized computational interfaces designed for specific programming languages or workflows.</p> <p>Rather than trying to be everything to everyone, each contributed application excels in its particular domain. This focused approach means you can choose the tool that best matches your specific research workflow, whether you're doing exploratory data analysis, developing complex algorithms, or collaborating on code with distributed teams.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#getting-started","title":"\ud83d\ude80 Getting Started","text":""},{"location":"user-guide/interactive-sessions/launch-contributed/#accessing-the-application-catalog","title":"Accessing the Application Catalog","text":"<p>Beginning your journey with contributed applications starts just like any other CANFAR session. After logging into the CANFAR Science Portal, you'll click the familiar plus sign (+) to create a new session. The key difference comes when you select <code>contributed</code> as your session type, which opens up the specialized application catalog.</p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#exploring-available-applications","title":"Exploring Available Applications","text":"<p>Once you've selected the contributed session type, the container dropdown reveals the current catalog of available applications. This list represents the cutting edge of community-developed tools, and it evolves as new applications are contributed and existing ones are updated.</p> <p></p> <p>Currently Available Applications:</p> <p>Pluto.jl (<code>images.canfar.net/skaha/pluto:latest</code>) offers a revolutionary approach to Julia programming through reactive notebooks. Unlike traditional notebook environments where cells execute in sequence, Pluto creates a dynamic environment where changing any variable automatically updates all dependent computations throughout the notebook. This makes it exceptionally powerful for exploratory data analysis and interactive visualization.</p> <p>Marimo (<code>images.canfar.net/skaha/marimo:latest</code>) brings reactive computing to Python, offering a modern alternative to Jupyter notebooks. Marimo notebooks are stored as pure Python files, making them easy to version control and share. The reactive execution model ensures your notebook stays consistent as you develop and modify your analysis.</p> <p>VSCode Browser (<code>images.canfar.net/skaha/code-browser:latest</code>) provides the full Visual Studio Code experience directly in your web browser. This application is particularly valuable for software development projects, complex multi-file analyses, and situations where you need the rich editing capabilities and extensions ecosystem that VSCode provides.</p> <p>Session Sizing</p> <p>Start with 16GB RAM and 2-4 CPU cores for most contributed apps. Increase memory for large datasets or memory-intensive reactive notebooks.</p> <p>The beauty of this system lies in its dynamic nature. As the community develops new tools and contributes them to the platform, the available applications expand to meet emerging research needs. If you have ideas for applications that would benefit the astronomy community, the CANFAR team encourages you to reach out to support@canfar.net.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#configuring-your-session","title":"Configuring Your Session","text":""},{"location":"user-guide/interactive-sessions/launch-contributed/#choosing-a-meaningful-name","title":"Choosing a Meaningful Name","text":"<p>When setting up your contributed application session, choose a name that reflects both the application you're using and the purpose of your work. Names like <code>pluto-galaxy-analysis-2024</code>, <code>marimo-pipeline-development</code>, or <code>vscode-survey-processing</code> help you quickly identify the session's purpose when you return to your work later.</p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#resource-planning","title":"Resource Planning","text":"<p>The resource requirements for contributed applications can vary significantly depending on the nature of your work and the specific application you're using. Web-based development environments like VSCode Browser typically run comfortably with 8-16GB of memory and 2-4 CPU cores, while reactive notebook environments processing large datasets might benefit from 16-32GB of memory.</p> <p>For memory allocation, consider starting with 16GB as a reasonable default for most contributed applications. If you're working with large datasets or computationally intensive visualizations, you might want to increase this to 32GB or more. The reactive nature of some applications means they might use more memory than traditional notebooks since they maintain the state of all computations simultaneously.</p> <p>CPU requirements are generally modest for most contributed applications, with 2-4 cores being sufficient for typical workflows. However, if your work involves parallel processing or you're running multiple computational tasks simultaneously, additional cores can significantly improve performance.</p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#launching-and-connecting","title":"Launching and Connecting","text":"<p>After configuring your session parameters, clicking \"Launch\" initiates the container deployment process. The session will appear on your portal dashboard, and you can monitor its startup progress. Contributed applications typically take 30-90 seconds to fully initialize, as they need to start the web service and establish connections to CANFAR's storage systems.</p> <p>Once the session is running, clicking the session icon will open the application in a new browser tab. The first connection might take a few additional moments as the application completes its startup sequence and presents its interface.</p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#working-effectively","title":"\ud83d\udd27 Working Effectively","text":""},{"location":"user-guide/interactive-sessions/launch-contributed/#understanding-application-interfaces","title":"Understanding Application Interfaces","text":"<p>Most contributed applications follow modern web application conventions, but each has its own personality and workflow patterns. Rather than trying to force a one-size-fits-all approach, take some time to explore each application's unique features and interface paradigms.</p> <p>The typical structure you'll encounter includes a navigation or menu area that provides access to the application's main features, a central content area where your work happens, and various panels or sidebars for configuration, file management, and tool access. Status information and feedback usually appear in designated areas that don't interfere with your primary workflow.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#integrating-with-canfar-storage","title":"Integrating with CANFAR Storage","text":"<p>Persistence Reminder</p> <p>Save important results to <code>/arc/projects/</code> or <code>/arc/home/</code>. Temporary paths and in-app caches may not persist after the session ends.</p> <p>One of the most powerful aspects of contributed applications is their seamless integration with CANFAR's storage infrastructure. Your applications can directly access your project data through <code>/arc/projects/yourproject/</code>, your personal files via <code>/arc/home/yourusername/</code>, and temporary processing space in <code>/scratch/</code>. This integration means you can move fluidly between different types of sessions and applications while maintaining access to the same data.</p> <p>Understanding these storage patterns helps you organize your work effectively. You might use your personal home directory for notebooks and scripts under development, project directories for shared data and collaborative work, and scratch space for temporary files and intermediate processing results that don't need long-term storage.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#authentication-and-collaboration","title":"Authentication and Collaboration","text":"<p>The integration with CANFAR's authentication system means you don't need to manage separate credentials for each application. Your existing CANFAR account provides access to all contributed applications, and the same group-based permissions that govern your access to shared storage also apply within applications.</p> <p>This seamless authentication enables powerful collaboration patterns. You can share session URLs with collaborators who have appropriate permissions, work together in real-time on analysis projects, and maintain consistent access controls across different tools and workflows.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#real-world-examples","title":"\ud83d\udee0\ufe0f Real-World Examples","text":""},{"location":"user-guide/interactive-sessions/launch-contributed/#interactive-data-exploration-with-plutojl","title":"Interactive Data Exploration with Pluto.jl","text":"<p>Imagine you're working with a large astronomical catalog and want to explore correlations between different measured parameters. Traditional notebook approaches require you to re-run cells manually as you adjust parameters or add new visualizations. With Pluto.jl, you can create sliders and interactive controls that automatically update all dependent visualizations and calculations in real-time.</p> <p>You might start by loading your catalog data and creating a basic scatter plot. As you add interactive controls for magnitude cuts, color selections, or coordinate ranges, the plot updates automatically. When you decide to add a histogram showing the distribution of selected objects, it immediately reflects your current filter settings. This reactive approach makes exploratory data analysis feel more like an interactive conversation with your data.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#collaborative-development-with-vscode-browser","title":"Collaborative Development with VSCode Browser","text":"<p>Consider a scenario where you're collaborating with colleagues on a complex data processing pipeline that involves multiple Python modules, configuration files, and documentation. Using VSCode Browser, you can work in a full-featured development environment that includes syntax highlighting, debugging capabilities, integrated terminal access, and extension support for specialized astronomical tools.</p> <p>The browser-based nature means your collaborators can access the same development environment without worrying about local software installation or version compatibility issues. Everyone works with the same tools, the same Python environment, and the same file system, eliminating the \"works on my machine\" problem that often plagues collaborative software development.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#modern-python-notebooks-with-marimo","title":"Modern Python Notebooks with Marimo","text":"<p>If you've experienced frustration with traditional Jupyter notebooks becoming inconsistent as you develop and modify your analysis, Marimo offers a refreshing alternative. Because Marimo notebooks are reactive and stored as standard Python files, you can develop complex analyses that remain consistent and reproducible.</p> <p>The reactive execution model means that when you modify a function or variable definition, all dependent computations automatically update. This eliminates the common notebook problem where cells are executed out of order, leaving you with inconsistent results. The fact that notebooks are stored as Python files also makes them easy to version control with Git and share with colleagues who might not be using notebook environments.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#best-practices","title":"\ud83d\udd12 Best Practices","text":""},{"location":"user-guide/interactive-sessions/launch-contributed/#understanding-application-permissions","title":"Understanding Application Permissions","text":"<p>Contributed applications operate within the same security framework as other CANFAR services, inheriting your account permissions and access controls. This means they can access your home directory, project directories where you're a member, and VOSpace areas where you have appropriate permissions. However, they cannot access other users' private data or perform system administration functions.</p> <p>When working with contributed applications, it's important to understand what data the application might access and how it processes that information. Most applications are designed to work locally with your data and don't transmit information to external services, but it's always good practice to review the documentation for any application you're using for the first time.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#data-security-considerations","title":"Data Security Considerations","text":"<p>The web-based nature of contributed applications introduces some unique security considerations. Always use HTTPS connections when accessing applications, be cautious about uploading sensitive credentials or tokens to applications unless specifically required, and use CANFAR's group-based permissions to manage access to shared data appropriately.</p> <p>For researchers working with sensitive or proprietary data, it's worth understanding how each application handles data processing and whether any information might be cached or logged. Most contributed applications are designed with these concerns in mind, but understanding the data flow helps you make informed decisions about which tools to use for different types of work.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#contributing-your-apps","title":"\ud83e\uddd1\u200d\ud83d\udcbb Contributing Your Apps","text":""},{"location":"user-guide/interactive-sessions/launch-contributed/#understanding-the-technical-framework","title":"Understanding the Technical Framework","text":"<p>If you're interested in developing your own contributed application, the technical requirements are designed to be straightforward while ensuring security and compatibility with CANFAR's infrastructure. Your application needs to be containerized and provide a web interface that runs on port 5000.</p> <p>The key technical requirement is including a startup script at <code>/skaha/startup.sh</code> in your container image. This script serves as the entry point for your application and should handle the initialization and startup of your web service. Here's how this typically works in practice:</p> <pre><code># Expose the required port\nEXPOSE 5000\n\n# Create the skaha directory and copy your startup script\nRUN mkdir /skaha\nCOPY your_startup_script.sh /skaha/startup.sh\nRUN chmod gou+x /skaha/startup.sh\n\n# Set the startup script as the entrypoint\nENTRYPOINT [ \"/skaha/startup.sh\" ]\n</code></pre> <p>Your startup script needs to launch your web application in a way that handles signals properly and listens on the correct interface. Here's the pattern used by the Marimo application:</p> <pre><code>#!/bin/bash -e\nset -e\necho \"[Application Startup] Starting application server...\"\n\n# Use 'exec' to replace the script process with your application process.\n# This is important for signal handling (e.g., SIGTERM from Kubernetes).\nexec your_application \\\n  --port 5000 \\\n  --host 0.0.0.0 \\\n  --other-required-options\n</code></pre> <p>The <code>exec</code> command is crucial because it ensures proper signal handling when the container needs to shut down. The <code>--host 0.0.0.0</code> flag makes your application accessible from outside the container, and <code>--port 5000</code> uses the standard port that CANFAR expects.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#development-and-testing-workflow","title":"Development and Testing Workflow","text":"<p>Developing a contributed application typically follows an iterative process. You'll start by building and testing your application locally using Docker, ensuring it works correctly in a containerized environment. Once you have a working container, you can test it on CANFAR by pushing it to a container registry and launching it as a contributed application session.</p> <p>During development, pay particular attention to how your application integrates with CANFAR's storage systems and authentication. Test that your application can access the expected file system paths and that it behaves correctly when running under the CANFAR user account rather than as root.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#community-integration","title":"Community Integration","text":"<p>The most successful contributed applications solve real problems that multiple researchers face and provide capabilities that aren't easily replicated with existing tools. Before beginning development, consider reaching out to the CANFAR community through the support channels to discuss your ideas and gather feedback on potential use cases.</p> <p>When you're ready to contribute your application, contact support@canfar.net with information about your application's purpose, target user community, and key features. The CANFAR team will work with you to integrate your application into the platform and ensure it meets the technical and security requirements.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#troubleshooting","title":"\ud83c\udd98 Troubleshooting","text":""},{"location":"user-guide/interactive-sessions/launch-contributed/#application-startup-problems","title":"Application Startup Problems","text":"<p>If your contributed application doesn't load or seems to hang during startup, the most common cause is that the application is still initializing. Web applications can take 60-90 seconds to fully start up, especially if they need to install packages or perform initial configuration. Try waiting a bit longer before concluding there's a problem.</p> <p>Browser caching can sometimes cause issues with contributed applications, especially if you've used the same application before and it has been updated. Try refreshing the page or opening the application in a private/incognito browser window to bypass potential caching issues.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#data-access-challenges","title":"Data Access Challenges","text":"<p>Problems accessing data usually stem from incorrect file paths or permission issues. Verify that the files you're trying to access exist in the expected locations and that you have the necessary permissions. Remember that contributed applications access the same file system as other CANFAR sessions, so paths that work in Jupyter notebooks should work in contributed applications as well.</p> <p>If you're having trouble accessing shared project data, check your group membership and ensure that the project directory has the correct permissions. Sometimes data access issues are actually authentication problems in disguise.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#performance-and-resource-issues","title":"Performance and Resource Issues","text":"<p>If your contributed application feels slow or unresponsive, consider whether you've allocated sufficient resources for your workload. Web-based applications can be more memory-intensive than you might expect, especially reactive notebook environments that maintain state for all computations.</p> <p>You can often improve performance by closing unnecessary browser tabs, ensuring you have sufficient memory allocated to your session, and monitoring your resource usage through the browser's developer tools if available.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#evolving-ecosystem","title":"\ud83d\udcda Evolving Ecosystem","text":""},{"location":"user-guide/interactive-sessions/launch-contributed/#current-applications-and-their-strengths","title":"Current Applications and Their Strengths","text":"<p>The current catalog of contributed applications represents different approaches to interactive scientific computing, each with its own strengths and ideal use cases. Pluto.jl excels in situations where you want immediate feedback on how changes affect your analysis and is particularly powerful for teaching and exploration. Marimo brings similar reactive capabilities to Python while maintaining compatibility with standard Python tooling and version control systems.</p> <p>VSCode Browser provides the most comprehensive development environment, making it ideal for complex software projects, multi-file analyses, and situations where you need advanced editing capabilities or specific extensions. It's particularly valuable when you're developing tools that others will use or when you need the debugging and profiling capabilities that come with a full IDE.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#looking-forward","title":"Looking Forward","text":"<p>The contributed applications ecosystem continues to evolve as the community identifies new needs and develops innovative solutions. Future applications might focus on specialized domains like time-series analysis, interactive 3D visualization, or collaborative annotation tools. The flexibility of the platform means that if you can envision a web-based tool that would benefit astronomical research, it can likely be implemented as a contributed application.</p> <p>The key to this ecosystem's success is community engagement. As more researchers use these tools and provide feedback, applications improve and new ideas emerge. If you have suggestions for improvements to existing applications or ideas for entirely new tools, the CANFAR team encourages you to share them.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#research-integration","title":"\ud83d\udd17 Research Integration","text":""},{"location":"user-guide/interactive-sessions/launch-contributed/#building-comprehensive-workflows","title":"Building Comprehensive Workflows","text":"<p>Contributed applications work best when integrated into comprehensive research workflows that leverage CANFAR's full capabilities. You might begin analysis in a Jupyter notebook session, move to a contributed application for specialized processing or visualization, and then return to notebooks for final analysis and documentation.</p> <p>The seamless access to shared storage means you can hand off work between different session types and applications without worrying about data transfer or synchronization. This flexibility allows you to choose the best tool for each phase of your research rather than being constrained by the limitations of any single environment.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#collaboration-and-knowledge-sharing","title":"Collaboration and Knowledge Sharing","text":"<p>The web-based nature of contributed applications makes them particularly powerful for collaboration and knowledge sharing. You can share session URLs with colleagues for real-time collaboration, use the same applications for training workshops and educational activities, and ensure that everyone on your team has access to the same tools and capabilities regardless of their local computing environment.</p> <p>This democratization of access to specialized tools can significantly impact how research teams work together and how knowledge is transferred between experienced and novice researchers.</p>"},{"location":"user-guide/interactive-sessions/launch-contributed/#whats-next","title":"\ud83d\udd17 What's Next?","text":"<p>Contributed applications represent just one facet of CANFAR's comprehensive research platform. To make the most of these tools, consider exploring how they integrate with CANFAR's other capabilities. The Storage Guide will help you effectively manage data for use with contributed applications. Understanding Notebook Sessions can help you prepare data for specialized processing in contributed applications. For automated workflows, Batch Processing can complement the interactive analysis you do in contributed applications. And if you're interested in developing your own tools, the Container Development guide provides the technical foundation for creating contributed applications.</p> <p>Making the Most of Contributed Applications</p> <p>The key to success with contributed applications lies in matching the right tool to your specific workflow needs. Take time to explore each application's unique capabilities, don't hesitate to experiment with different approaches to your analysis challenges, and remember that the most powerful workflows often combine multiple tools and session types. The CANFAR community is always eager to help you find the best approaches for your research, so don't hesitate to reach out with questions or suggestions.</p>"},{"location":"user-guide/interactive-sessions/launch-desktop/","title":"Launching Desktop Sessions","text":"<p>Desktop sessions provide a full Linux graphical environment in your browser, giving you access to traditional astronomy software with familiar desktop interfaces. This guide walks you through launching and using desktop sessions on the CANFAR Science Platform.</p> <p>\ud83c\udfaf What You'll Learn</p> <ul> <li>How to launch, connect, and size desktop sessions</li> <li>What software is available and how to launch it</li> <li>How to manage files and storage within desktop sessions</li> <li>Tips for collaboration, performance, and troubleshooting</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-desktop/#overview","title":"Overview","text":"<p>Desktop sessions offer:</p> <ul> <li>Full Linux desktop: Complete graphical environment in your browser</li> <li>Multi-application workflow: Run multiple programs simultaneously</li> <li>Traditional interfaces: Use software with graphical user interfaces</li> <li>File management: Visual file browser and management tools</li> <li>Session persistence: Resume work exactly where you left off</li> </ul> <p>Common use cases include:</p> <ul> <li>Running GUI-based astronomy software (DS9, SAOImage, IRAF)</li> <li>Complex multi-step workflows requiring multiple applications</li> <li>Teaching and demonstration scenarios</li> <li>Legacy software that requires a desktop environment</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-desktop/#creating-a-desktop-session","title":"Creating a Desktop Session","text":""},{"location":"user-guide/interactive-sessions/launch-desktop/#step-1-select-session-type","title":"Step 1: Select Session Type","text":"<p>From the Science Portal dashboard, click the plus sign (+) to create a new session,  then select desktop as your session type.</p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-desktop/#step-2-choose-container","title":"Step 2: Choose Container","text":"<p>The desktop container includes a comprehensive set of astronomy software. Currently,  there's one main desktop environment available with pre-installed tools.</p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-desktop/#step-3-configure-session","title":"Step 3: Configure Session","text":""},{"location":"user-guide/interactive-sessions/launch-desktop/#session-name","title":"Session Name","text":"<p>Give your session a descriptive name that will help you identify it later  (e.g., \"data-reduction\", \"teaching-session\", \"multi-instrument-analysis\").</p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-desktop/#resource-configuration","title":"Resource Configuration","text":"<p>Desktop sessions typically require more resources than other session types:</p> <p>Memory (RAM): - 16GB (recommended): Standard desktop usage - 32GB: Multiple applications or large datasets - 64GB: Intensive workflows with large data</p> <p>CPU Cores: - 2 cores: Basic desktop operations - 4 cores (recommended): Multiple applications - 8+ cores: Compute-intensive desktop workflows</p>"},{"location":"user-guide/interactive-sessions/launch-desktop/#step-4-launch-session","title":"Step 4: Launch Session","text":"<p>Click the Launch button and wait for your session to initialize. Desktop sessions  may take slightly longer to start than other session types.</p> <p></p> <p>Your session will appear on the Science Portal dashboard. Click the desktop icon to access your session.</p> <p></p> <p>Connection Timing</p> <p>Sometimes it takes a few seconds for the session link to work properly. If you see a \"Bad gateway\" error, wait a moment and try again.</p>"},{"location":"user-guide/interactive-sessions/launch-desktop/#connecting-to-your-desktop","title":"Connecting to Your Desktop","text":""},{"location":"user-guide/interactive-sessions/launch-desktop/#initial-connection","title":"Initial Connection","text":"<p>Click the Connect button to access your desktop environment.</p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-desktop/#desktop-environment","title":"Desktop Environment","text":"<p>You'll see a full Linux desktop environment with:</p> <ul> <li>Taskbar: Application launcher and system controls</li> <li>File manager: Browse your storage and files</li> <li>Terminal: Command-line access</li> <li>Pre-installed software: Astronomy applications ready to use</li> </ul> <p></p>"},{"location":"user-guide/interactive-sessions/launch-desktop/#session-persistence","title":"Session Persistence","text":"<p>When your session becomes inactive, you'll be returned to the connection page.  Click Connect again to resume exactly where you left off - all your applications  and work remain open.</p>"},{"location":"user-guide/interactive-sessions/launch-desktop/#available-software","title":"Available Software","text":""},{"location":"user-guide/interactive-sessions/launch-desktop/#astronomy-applications","title":"Astronomy Applications","text":"<p>Your desktop session includes:</p> <ul> <li>DS9: Advanced FITS image viewer and analyzer</li> <li>SAOImage: Astronomical image display</li> <li>CASA: Complete radio astronomy suite with GUI</li> <li>Python environments: With Jupyter, AstroPy, and other libraries</li> <li>IRAF/PyRAF: Legacy optical astronomy reduction (if needed)</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-desktop/#development-tools","title":"Development Tools","text":"<ul> <li>Text editors: gedit, vim, emacs</li> <li>IDEs: Available through package installation</li> <li>Version control: Git and other VCS tools</li> <li>Compilers: GCC, Python, and other development tools</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-desktop/#system-tools","title":"System Tools","text":"<ul> <li>File manager: Graphical file operations</li> <li>Terminal: Full shell access</li> <li>System monitor: Resource usage monitoring</li> <li>Network tools: File transfer and connectivity utilities</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-desktop/#working-with-applications","title":"Working with Applications","text":""},{"location":"user-guide/interactive-sessions/launch-desktop/#launching-applications","title":"Launching Applications","text":"<p>Method 1: Application Menu 1. Click the applications menu in the taskbar 2. Browse categories (Graphics, Science, Development) 3. Click to launch your chosen application</p> <p>Method 2: Terminal <pre><code># Launch DS9\nds9 &amp;\n\n# Launch CASA with GUI\ncasa --gui &amp;\n\n# Launch Python with astronomy libraries\nipython --pylab\n</code></pre></p> <p>Method 3: File Association - Double-click FITS files to open in DS9 - Right-click files for \"Open with\" options</p>"},{"location":"user-guide/interactive-sessions/launch-desktop/#example-multi-application-workflow","title":"Example: Multi-Application Workflow","text":"<p>Here's a typical desktop workflow for optical astronomy:</p> <ol> <li>File Management: Use file manager to organize data</li> <li>Image Display: Open FITS files in DS9 for inspection</li> <li>Analysis: Launch Python/Jupyter for data analysis</li> <li>Documentation: Use text editor for notes and scripts</li> <li>Results: Save plots and analysis outputs</li> </ol>"},{"location":"user-guide/interactive-sessions/launch-desktop/#casa-desktop-usage","title":"CASA Desktop Usage","text":"<p>To use CASA with its graphical interface:</p> <pre><code># Launch CASA with GUI\ncasa --gui\n\n# Or use the interactive shell\ncasa\n</code></pre> <p>The desktop environment allows you to use CASA's plotting and visualization  tools that aren't available in command-line mode.</p>"},{"location":"user-guide/interactive-sessions/launch-desktop/#desktop-session-tips","title":"Desktop Session Tips","text":""},{"location":"user-guide/interactive-sessions/launch-desktop/#copy-paste-between-containers","title":"Copy &amp; Paste Between Containers","text":"<p>Since different containers (e.g., CASA and terminal windows) in a desktop session may run on different remote computers, copying and pasting text between containers requires using the Clipboard application.</p>"},{"location":"user-guide/interactive-sessions/launch-desktop/#accessing-the-clipboard","title":"Accessing the Clipboard","text":"<ol> <li>Open the Clipboard: Click the arrow at the far left of the desktop to open the application menu</li> <li>Find Clipboard: Look for \"Clipboard\" in the middle of the application list and click it</li> </ol>"},{"location":"user-guide/interactive-sessions/launch-desktop/#using-the-clipboard","title":"Using the Clipboard","text":"<p>The Clipboard serves as an intermediary for transferring text between containers:</p> <ol> <li>Copy text: Highlight text in the source container and use <code>Ctrl+Shift+C</code></li> <li>Transfer via Clipboard: The text should appear in the Clipboard application</li> <li>Select in Clipboard: Highlight the text in the Clipboard and press <code>Ctrl+Shift+C</code></li> <li>Paste to target: Click in the destination container and use <code>Ctrl+Shift+V</code></li> </ol> <p></p> <p>Keyboard Shortcuts</p> <ul> <li>Copy: <code>Ctrl+Shift+C</code></li> <li>Paste: <code>Ctrl+Shift+V</code></li> <li>These shortcuts work consistently across all desktop containers</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-desktop/#adjusting-font-size","title":"Adjusting Font Size","text":"<p>Desktop containers support adjustable font sizes for better readability:</p>"},{"location":"user-guide/interactive-sessions/launch-desktop/#changing-terminal-font-size","title":"Changing Terminal Font Size","text":"<ol> <li>Access font menu: Hold <code>Ctrl</code> and right-click anywhere in a terminal window</li> <li>Select size: Choose from the available font size options (Small, Medium, Large)</li> <li>Apply immediately: Font changes take effect instantly</li> </ol> <p>This feature works in: - Terminal windows - CASA command-line interface - Text-based applications</p> <p>Font Persistence</p> <p>Font size changes apply only to the current session. You'll need to readjust when starting new sessions.</p>"},{"location":"user-guide/interactive-sessions/launch-desktop/#file-management","title":"File Management","text":""},{"location":"user-guide/interactive-sessions/launch-desktop/#storage-access","title":"Storage Access","text":"<p>Your desktop session provides access to:</p> <ul> <li><code>/arc/projects/[group]/</code>: Shared project storage</li> <li><code>/arc/home/[username]/</code>: Personal persistent storage</li> <li><code>/home/[username]/</code>: Session-local home directory</li> <li><code>/tmp/</code>: Temporary scratch space</li> </ul> <p>Persistence Reminder</p> <p>Use <code>/arc/projects/</code> or <code>/arc/home/</code> for important files. The session-local home and <code>/tmp/</code> are not guaranteed to persist after the session ends.</p>"},{"location":"user-guide/interactive-sessions/launch-desktop/#file-operations","title":"File Operations","text":"<p>Use the graphical file manager for:</p> <ul> <li>Drag-and-drop: Move files between directories</li> <li>Visual browsing: Preview images and data files</li> <li>Batch operations: Select multiple files for operations</li> <li>Permissions: Set file and directory permissions</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-desktop/#data-transfer","title":"Data Transfer","text":"<p>Transfer files to/from your desktop session:</p> <ul> <li>Browser upload: Use Science Portal file manager</li> <li>Command line: <code>scp</code>, <code>rsync</code>, <code>wget</code></li> <li>Cloud storage: Mount external storage systems</li> <li>USB/local: Upload through browser interface</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-desktop/#session-management","title":"Session Management","text":""},{"location":"user-guide/interactive-sessions/launch-desktop/#resource-monitoring","title":"Resource Monitoring","text":"<p>Monitor your session resources:</p> <pre><code># Check memory usage\nfree -h\n\n# Monitor CPU usage\nhtop\n\n# Check disk space\ndf -h /arc /tmp\n</code></pre>"},{"location":"user-guide/interactive-sessions/launch-desktop/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Close unused applications: Free up memory and CPU</li> <li>Use virtual desktops: Organize workflows across multiple desktops</li> <li>Monitor network: Large file transfers can affect responsiveness</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-desktop/#ending-sessions","title":"Ending Sessions","text":"<p>To properly end your desktop session:</p> <ol> <li>Save all work: Ensure data is saved to persistent storage</li> <li>Close applications: Exit programs cleanly</li> <li>Disconnect: Close the browser tab</li> <li>Delete session: Use Science Portal to free resources</li> </ol>"},{"location":"user-guide/interactive-sessions/launch-desktop/#collaboration-features","title":"Collaboration Features","text":""},{"location":"user-guide/interactive-sessions/launch-desktop/#screen-sharing","title":"Screen Sharing","text":"<p>Share your desktop session with collaborators:</p> <ol> <li>Access session sharing from Science Portal</li> <li>Add collaborator usernames</li> <li>Set permissions (view-only or full control)</li> <li>Collaborators see your full desktop in real-time</li> </ol>"},{"location":"user-guide/interactive-sessions/launch-desktop/#teaching-and-demonstration","title":"Teaching and Demonstration","text":"<p>Desktop sessions are ideal for:</p> <ul> <li>Live demonstrations: Show software usage to groups</li> <li>Hands-on training: Students can follow along</li> <li>Collaborative debugging: Work together on problems</li> <li>Code review: Visual examination of code and results</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-desktop/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/interactive-sessions/launch-desktop/#common-issues","title":"Common Issues","text":"<p>Session won't connect - Wait 30 seconds and try again - Check browser compatibility (Chrome/Firefox recommended) - Disable browser extensions that might interfere</p> <p>Poor performance - Check resource usage with <code>htop</code> - Close unnecessary applications - Consider increasing session memory</p> <p>Applications won't start - Check for error messages in terminal - Verify sufficient memory available - Try launching from command line for error details</p> <p>File access problems - Verify paths to <code>/arc/projects/[group]/</code> - Check group permissions - Ensure files aren't locked by other processes</p>"},{"location":"user-guide/interactive-sessions/launch-desktop/#browser-optimization","title":"Browser Optimization","text":"<p>For best performance:</p> <ul> <li>Use Chrome or Firefox: Best compatibility and performance</li> <li>Close other tabs: Free up browser memory</li> <li>Stable connection: Ensure reliable internet connection</li> <li>Disable browser extensions: Remove potential conflicts</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-desktop/#getting-help","title":"Getting Help","text":"<ul> <li>Support: Email support@canfar.net</li> <li>Community: Join our Discord for desktop tips</li> <li>Documentation: Check software-specific guides for DS9, CASA, etc.</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-desktop/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/interactive-sessions/launch-desktop/#resource-management","title":"Resource Management","text":"<ul> <li>Plan resource needs: Estimate memory for your workflow</li> <li>Monitor usage: Check system resources regularly</li> <li>Clean up: Remove temporary files when finished</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-desktop/#workflow-organization","title":"Workflow Organization","text":"<ul> <li>Organize windows: Use multiple desktops for complex workflows</li> <li>Save frequently: Desktop sessions can be terminated for maintenance</li> <li>Document work: Keep notes on your analysis steps</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-desktop/#data-management","title":"Data Management","text":"<ul> <li>Use persistent storage: Save important work to <code>/arc/</code></li> <li>Organize files: Create clear directory structures</li> <li>Backup results: Important outputs should be backed up</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-desktop/#next-steps","title":"Next Steps","text":"<ul> <li>CASA Desktop Workflows: Advanced CASA usage</li> <li>Radio Astronomy Guide: Desktop-based radio analysis workflows</li> <li>Batch Processing: Scale up desktop workflows</li> <li>Notebook Sessions: Alternative analysis environment</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-firefly/","title":"Launching a Firefly Session","text":"<p>The LSST table and image visualizer for astronomical data exploration</p> <p>\ud83c\udfaf What You'll Learn</p> <ul> <li>How to launch a Firefly session and choose the right version</li> <li>How to load images, tables, and access CANFAR storage</li> <li>How to perform catalog overlays, plotting, and cutouts</li> <li>Performance tips for large surveys and troubleshooting guidance</li> </ul> <p>Firefly is a powerful web-based visualization tool originally developed for the Rubin Observatory LSST. It provides advanced capabilities for viewing images, overlaying catalogs, and analyzing tabular data - making it perfect for survey data analysis and multi-wavelength astronomy.</p>"},{"location":"user-guide/interactive-sessions/launch-firefly/#what-is-firefly","title":"\ud83c\udfaf What is Firefly?","text":"<p>Firefly offers specialized tools for:</p> <ul> <li>Image visualization with advanced stretch and color controls</li> <li>Catalog overlay and source analysis tools  </li> <li>Table viewer with filtering, plotting, and statistical tools</li> <li>Multi-wavelength data comparison and analysis</li> <li>Large survey datasets like LSST, HSC, and WISE</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-firefly/#key-features","title":"Key Features","text":"Feature Capability Image Display FITS images with WCS support, multiple panels Catalog Overlay Plot sources on images, interactive selection Table Analysis Sort, filter, plot columns, statistical analysis Multi-band RGB color composites, band switching Cutout Services Extract subimages from large surveys Coordinate Systems Support for all standard astronomical coordinates"},{"location":"user-guide/interactive-sessions/launch-firefly/#launching-firefly","title":"\ud83d\ude80 Launching Firefly","text":""},{"location":"user-guide/interactive-sessions/launch-firefly/#step-1-create-new-session","title":"Step 1: Create New Session","text":"<ol> <li>Login to the CANFAR Science Portal</li> <li>Click the plus sign (+) to create a new session</li> <li>Select <code>firefly</code> as your session type</li> </ol>"},{"location":"user-guide/interactive-sessions/launch-firefly/#step-2-choose-container","title":"Step 2: Choose Container","text":"<p>The container selection updates automatically after choosing the session type. Select the Firefly container version you need:</p> <ul> <li>firefly:latest - Most recent stable version (recommended)</li> <li>firefly:X.X - Specific version for reproducible analysis</li> </ul> <p></p>"},{"location":"user-guide/interactive-sessions/launch-firefly/#step-3-configure-session","title":"Step 3: Configure Session","text":""},{"location":"user-guide/interactive-sessions/launch-firefly/#session-name","title":"Session Name","text":"<p>Choose a descriptive name that helps identify your work: - <code>lsst-photometry</code> - <code>hsc-catalog-analysis</code>  - <code>multiband-survey</code></p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-firefly/#memory-requirements","title":"Memory Requirements","text":"<p>Select RAM based on your data size:</p> <ul> <li>8GB: Small catalogs, single images</li> <li>16GB: Default, suitable for most work</li> <li>32GB: Large catalogs, multiple images</li> <li>64GB: Very large survey datasets</li> </ul> <p>Memory Planning</p> <p>Tables with millions of rows and multi-image layouts benefit from 32GB+ RAM. Start with 8GB and scale up if you hit browser or session limits.</p>"},{"location":"user-guide/interactive-sessions/launch-firefly/#cpu-cores","title":"CPU Cores","text":"<p>Most Firefly work is I/O bound rather than CPU intensive:</p> <ul> <li>2 cores: Default, sufficient for most visualization tasks</li> <li>4 cores: Large table operations, complex filtering</li> </ul> <p></p>"},{"location":"user-guide/interactive-sessions/launch-firefly/#step-4-launch-session","title":"Step 4: Launch Session","text":"<ol> <li>Click \"Launch\" button</li> <li>Wait for container initialization (~30-60 seconds)</li> <li>Session appears on your portal dashboard</li> <li>Click the session icon to access Firefly</li> </ol>"},{"location":"user-guide/interactive-sessions/launch-firefly/#using-firefly","title":"\ud83d\udd25 Using Firefly","text":""},{"location":"user-guide/interactive-sessions/launch-firefly/#interface-overview","title":"Interface Overview","text":"<p>Firefly's interface consists of several main areas:</p> <pre><code>graph TD\n    Interface[Firefly Interface]\n\n    Interface --&gt; Upload[\"\ud83d\udcc1 File Upload Area\"]\n    Interface --&gt; Images[\"\ud83d\uddbc\ufe0f Image Display\"]\n    Interface --&gt; Tables[\"\ud83d\udcca Table Viewer\"]\n    Interface --&gt; Tools[\"\ud83d\udd27 Analysis Tools\"]\n\n    Upload --&gt; Local[Local Files]\n    Upload --&gt; URLs[Remote URLs]\n    Upload --&gt; VOSpace[VOSpace Files]\n\n    Images --&gt; Display[Image Canvas]\n    Images --&gt; Controls[Display Controls]\n    Images --&gt; Overlays[Catalog Overlays]\n\n    Tables --&gt; Browse[Data Browser]\n    Tables --&gt; Filter[Filtering Tools]\n    Tables --&gt; Plot[Plotting Tools]</code></pre>"},{"location":"user-guide/interactive-sessions/launch-firefly/#loading-data","title":"Loading Data","text":""},{"location":"user-guide/interactive-sessions/launch-firefly/#upload-local-files","title":"Upload Local Files","text":"<p>FITS Images: <pre><code>1. Click \"Images\" tab\n2. Select \"Upload\" \n3. Choose FITS file from your computer\n4. Image loads automatically with WCS if available\n</code></pre></p> <p>Catalog Tables: <pre><code>1. Click \"Tables\" tab\n2. Select \"Upload\"\n3. Choose CSV, FITS table, or VOTable\n4. Table opens in browser interface\n</code></pre></p>"},{"location":"user-guide/interactive-sessions/launch-firefly/#access-canfar-storage","title":"Access CANFAR Storage","text":"<p>From <code>arc</code> Projects: <pre><code># Files in your project directory are accessible via:\n# /arc/projects/yourproject/data/image.fits\n# /arc/projects/yourproject/catalogs/sources.csv\n</code></pre></p> <p>From VOSpace: <pre><code>1. In Firefly, use \"File\" \u2192 \"Open\"\n2. Navigate to VOSpace URLs\n3. Access: vos://cadc.nrc.ca~vault/yourproject/\n</code></pre></p>"},{"location":"user-guide/interactive-sessions/launch-firefly/#remote-data-access","title":"Remote Data Access","text":"<p>Survey Archives: <pre><code># Example URLs for Firefly\nhttps://archive.stsci.edu/hlsp/data.fits\nhttps://irsa.ipac.caltech.edu/data/WISE/cutouts/\n</code></pre></p>"},{"location":"user-guide/interactive-sessions/launch-firefly/#image-analysis","title":"Image Analysis","text":""},{"location":"user-guide/interactive-sessions/launch-firefly/#basic-image-display","title":"Basic Image Display","text":"<pre><code>1. Load FITS image\n2. Adjust stretch (log, linear, sqrt)\n3. Set scale limits (min/max values)\n4. Choose color table (heat, cool, rainbow)\n</code></pre>"},{"location":"user-guide/interactive-sessions/launch-firefly/#multi-band-rgb","title":"Multi-band RGB","text":"<pre><code>1. Load three images (e.g., g, r, i bands)\n2. Select \"RGB\" mode\n3. Assign each image to R, G, or B channel\n4. Adjust relative scaling\n</code></pre>"},{"location":"user-guide/interactive-sessions/launch-firefly/#coordinate-systems","title":"Coordinate Systems","text":"<pre><code># Firefly supports standard coordinate systems:\n- Equatorial (RA/Dec) - J2000, B1950\n- Galactic coordinates\n- Ecliptic coordinates  \n- Pixel coordinates\n</code></pre>"},{"location":"user-guide/interactive-sessions/launch-firefly/#catalog-analysis","title":"Catalog Analysis","text":""},{"location":"user-guide/interactive-sessions/launch-firefly/#table-operations","title":"Table Operations","text":"<p>Basic Navigation: <pre><code>- Sort columns by clicking headers\n- Filter rows using search box\n- Select multiple rows with Ctrl+click\n- Pan/zoom table with mouse wheel\n</code></pre></p> <p>Advanced Filtering: <pre><code>// Example filters (use in filter box):\nmagnitude &lt; 20.5                    // Bright sources\ncolor_g_r &gt; 0.5 &amp;&amp; color_g_r &lt; 1.5  // Color selection\ndistance &lt; 100                      // Distance constraint\n</code></pre></p>"},{"location":"user-guide/interactive-sessions/launch-firefly/#plotting-tools","title":"Plotting Tools","text":"<p>Column Plots: <pre><code>1. Select table columns for X and Y axes\n2. Choose plot type (scatter, histogram, line)\n3. Apply color coding by third column\n4. Add error bars if available\n</code></pre></p> <p>Image-Catalog Overlay: <pre><code>1. Load image and catalog table\n2. Match coordinate columns (RA, Dec)\n3. Select overlay symbol (circle, cross, diamond)\n4. Adjust symbol size and color\n5. Sources appear overlaid on image\n</code></pre></p>"},{"location":"user-guide/interactive-sessions/launch-firefly/#advanced-features","title":"Advanced Features","text":""},{"location":"user-guide/interactive-sessions/launch-firefly/#cutout-services","title":"Cutout Services","text":"<p>Extract subimages from large surveys:</p> <pre><code># Using Firefly's cutout interface\n1. Right-click on image location\n2. Select \"Create Cutout\"\n3. Specify size (arcmin)\n4. Choose format (FITS, JPEG, PNG)\n5. Download or save to VOSpace\n</code></pre>"},{"location":"user-guide/interactive-sessions/launch-firefly/#multi-wavelength-analysis","title":"Multi-wavelength Analysis","text":"<pre><code>1. Load images in different bands\n2. Use \"Blink\" mode to compare\n3. Create RGB composite\n4. Overlay catalog with color-magnitude selection\n5. Identify sources across wavelengths\n</code></pre>"},{"location":"user-guide/interactive-sessions/launch-firefly/#data-export","title":"Data Export","text":"<p>Save Results: <pre><code>- Modified tables \u2192 CSV, FITS, VOTable formats\n- Image displays \u2192 PNG, PDF for publications  \n- Analysis plots \u2192 Vector formats for papers\n- Session state \u2192 Save/restore workspace\n</code></pre></p>"},{"location":"user-guide/interactive-sessions/launch-firefly/#common-workflows","title":"\ud83d\udee0\ufe0f Common Workflows","text":""},{"location":"user-guide/interactive-sessions/launch-firefly/#survey-photometry","title":"Survey Photometry","text":"<pre><code>1. Load survey image (HSC, LSST, etc.)\n2. Upload photometric catalog\n3. Overlay sources on image\n4. Filter by magnitude and color\n5. Create color-magnitude diagram\n6. Export selected sources\n</code></pre>"},{"location":"user-guide/interactive-sessions/launch-firefly/#multi-object-analysis","title":"Multi-object Analysis","text":"<pre><code>1. Load target list (CSV with coordinates)\n2. Create cutouts around each target\n3. Measure properties in each cutout\n4. Compile results in table\n5. Plot trends and correlations\n6. Save analysis products\n</code></pre>"},{"location":"user-guide/interactive-sessions/launch-firefly/#time-series-visualization","title":"Time Series Visualization","text":"<pre><code>1. Load time-series table (time, magnitude, error)\n2. Create light curve plot\n3. Apply period folding if needed\n4. Identify outliers and trends\n5. Export cleaned data\n</code></pre>"},{"location":"user-guide/interactive-sessions/launch-firefly/#integration-with-canfar","title":"\ud83d\udd27 Integration with CANFAR","text":""},{"location":"user-guide/interactive-sessions/launch-firefly/#storage-access","title":"Storage Access","text":"<p>ARC Projects: <pre><code># Your project data appears in Firefly file browser\n/arc/projects/yourproject/\n\u251c\u2500\u2500 images/           # FITS images\n\u251c\u2500\u2500 catalogs/         # Source tables  \n\u251c\u2500\u2500 results/          # Analysis products\n\u2514\u2500\u2500 plots/            # Exported figures\n</code></pre></p> <p>VOSpace Integration: <pre><code># Access archived data\nvos://cadc.nrc.ca~vault/yourproject/\n\u251c\u2500\u2500 published_data/   # Public datasets\n\u251c\u2500\u2500 working_data/     # Analysis in progress\n\u2514\u2500\u2500 final_products/   # Paper-ready results\n</code></pre></p>"},{"location":"user-guide/interactive-sessions/launch-firefly/#collaborative-features","title":"Collaborative Features","text":"<p>Session Sharing: <pre><code>1. Copy Firefly session URL\n2. Share with team members (same CANFAR group)\n3. Collaborate on analysis in real-time\n4. Each user sees same data and visualizations\n</code></pre></p> <p>Data Sharing: <pre><code>1. Save analysis results to shared project space\n2. Export publication-quality figures\n3. Share VOSpace links for external collaborators\n4. Version control important datasets\n</code></pre></p>"},{"location":"user-guide/interactive-sessions/launch-firefly/#performance-tips","title":"\ud83d\udcca Performance Tips","text":""},{"location":"user-guide/interactive-sessions/launch-firefly/#large-dataset-handling","title":"Large Dataset Handling","text":"<p>Memory Management: <pre><code>- Load subsets of large catalogs first\n- Use server-side filtering when possible\n- Close unused tables and images\n- Monitor memory usage in browser\n</code></pre></p> <p>Network Optimization: <pre><code>- Use compressed file formats (gzip FITS)\n- Access local files when possible (/arc/projects)\n- Cache frequently used data locally\n- Use cutout services for large images\n</code></pre></p>"},{"location":"user-guide/interactive-sessions/launch-firefly/#visualization-performance","title":"Visualization Performance","text":"<p>Image Display: <pre><code>- Use appropriate image size for screen resolution\n- Apply reasonable stretch limits\n- Close unused image panels\n- Use PNG format for screenshots\n</code></pre></p> <p>Table Operations: <pre><code>- Filter large tables before plotting\n- Use sampling for very large datasets\n- Index frequently used columns\n- Batch operations when possible\n</code></pre></p>"},{"location":"user-guide/interactive-sessions/launch-firefly/#troubleshooting","title":"\ud83c\udd98 Troubleshooting","text":""},{"location":"user-guide/interactive-sessions/launch-firefly/#common-issues","title":"Common Issues","text":"<p>Firefly Won't Load: <pre><code>- Check browser compatibility (Chrome, Firefox recommended)\n- Clear browser cache and cookies\n- Disable browser extensions that might interfere\n- Try incognito/private browsing mode\n</code></pre></p> <p>Images Not Displaying: <pre><code>- Verify FITS file format and WCS headers\n- Check file permissions and accessibility\n- Try loading smaller test image first\n- Ensure sufficient memory allocation\n</code></pre></p> <p>Tables Not Loading: <pre><code>- Verify file format (CSV, FITS table, VOTable)\n- Check column headers and data types\n- Ensure proper delimiter in CSV files\n- Try loading subset of data first\n</code></pre></p> <p>Performance Issues: <pre><code>- Reduce number of overlay sources\n- Close unused browser tabs\n- Increase session memory allocation\n- Use more efficient file formats\n</code></pre></p>"},{"location":"user-guide/interactive-sessions/launch-firefly/#external-resources","title":"\ud83d\udd17 External Resources","text":""},{"location":"user-guide/interactive-sessions/launch-firefly/#documentation","title":"Documentation","text":"<ul> <li>Firefly User Guide - Comprehensive documentation</li> <li>LSST Science Pipelines - Integration with LSST tools</li> <li>IRSA Tutorials - Survey data tutorials</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-firefly/#data-archives","title":"Data Archives","text":"<ul> <li>LSST Data Portal - LSST survey data</li> <li>HSC Archive - Hyper Suprime-Cam data</li> <li>IRSA - Infrared survey data</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-firefly/#whats-next","title":"\ud83d\udd17 What's Next?","text":"<p>Firefly works great with other CANFAR tools:</p> <ul> <li>Table Analysis \u2192 - Advanced catalog management</li> <li>Desktop Sessions \u2192 - Use Firefly with other GUI tools</li> <li>Batch Processing \u2192 - Automate large survey analysis</li> <li>Container Guide \u2192 - Customize Firefly environment</li> </ul> <p>Firefly Best Practices</p> <ol> <li>Start with small datasets to learn the interface before tackling large surveys</li> <li>Use appropriate memory - large catalogs need more RAM than single images  </li> <li>Save your work frequently - export important results to <code>/arc/projects/</code></li> <li>Collaborate effectively - share session URLs for real-time teamwork</li> <li>Optimize performance - close unused data and use efficient file formats</li> </ol>"},{"location":"user-guide/interactive-sessions/launch-notebook/","title":"Launching Jupyter Notebook Sessions","text":"<p>Interactive Jupyter Lab sessions provide a powerful environment for data analysis, visualization, and computational astronomy. This guide walks you through launching and using notebook sessions on the CANFAR Science Platform.</p> <p>\ud83c\udfaf What You'll Learn</p> <ul> <li>How to launch a Jupyter notebook session on CANFAR</li> <li>How to choose the right container and resources</li> <li>How storage works inside notebooks and what persists</li> <li>Tips for performance, collaboration, and troubleshooting</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-notebook/#overview","title":"Overview","text":"<p>Jupyter notebooks combine code execution, rich text documentation, and inline visualizations in a single interface. CANFAR's notebook sessions include:</p> <ul> <li>Jupyter Lab: Full-featured development environment</li> <li>Pre-configured containers: Astronomy-specific software stacks</li> <li>Persistent storage: Access to your ARC and VOSpace data</li> <li>Collaborative sharing: Share sessions with team members</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-notebook/#creating-a-new-session","title":"Creating a New Session","text":""},{"location":"user-guide/interactive-sessions/launch-notebook/#step-1-access-session-creation","title":"Step 1: Access Session Creation","text":"<p>From the Science Portal dashboard, click the plus sign (+) to create a new session,  then select notebook as your session type.</p> <p></p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-notebook/#step-2-choose-your-container","title":"Step 2: Choose Your Container","text":"<p>Select a container image that includes the software you need. Each container comes pre-configured with specific tools and libraries:</p> <ul> <li>astroml (recommended): Modern Python astronomy libraries (AstroPy, NumPy, SciPy, Matplotlib)</li> <li>CASA 6.5-notebook: Includes CASA (Common Astronomy Software Applications) for radio astronomy</li> <li>General purpose: Standard Python data science stack</li> </ul> <p></p> <p>Container Selection</p> <p>Start with astroml for most astronomy workflows. It includes the latest astronomy libraries and is actively maintained. Use CASA containers only when you specifically need CASA functionality.</p>"},{"location":"user-guide/interactive-sessions/launch-notebook/#step-3-configure-session-resources","title":"Step 3: Configure Session Resources","text":""},{"location":"user-guide/interactive-sessions/launch-notebook/#session-name","title":"Session Name","text":"<p>Choose a descriptive name that helps you identify this session later (e.g., \"galaxy-photometry\", \"pulsar-analysis\").</p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-notebook/#memory-ram-selection","title":"Memory (RAM) Selection","text":"<p>Select the maximum memory your analysis will require. Start conservatively\u2014you can always launch a new session with more memory if needed.</p> <ul> <li>8GB: Light data analysis, small datasets</li> <li>16GB (default): Suitable for most analyses, equivalent to a MacBook Pro</li> <li>32GB+: Large datasets, memory-intensive computations</li> </ul> <p>Resource sharing: Computing resources are shared among all users. Large memory requests may delay session startup if resources are unavailable.</p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-notebook/#cpu-cores","title":"CPU Cores","text":"<p>Choose the number of processing cores based on your computational needs:</p> <ul> <li>1 core: Simple analysis, single-threaded code</li> <li>2 cores (default): Recommended for most tasks</li> <li>4+ cores: Parallel processing, intensive computations</li> </ul> <p>Most astronomy software uses only one core unless specifically configured for parallel processing.</p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-notebook/#step-4-launch-your-session","title":"Step 4: Launch Your Session","text":"<p>Click the Launch button to create your Notebook session. The system will:</p> <ol> <li>Allocate computing resources</li> <li>Pull the container image (if not cached)</li> <li>Initialize your environment</li> <li>Start Jupyter Lab</li> </ol> <p>First Launch Timing</p> <p>The first launch of a specific container may take 2-3 minutes while the image is downloaded and cached. Subsequent launches are typically 30-60 seconds.</p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-notebook/#step-5-connect-to-your-session","title":"Step 5: Connect to Your Session","text":"<p>Wait for the Notebook icon to appear on your dashboard, then click it to access your session. Initial startup may take 2-3 minutes if the container hasn't been used recently on this server.</p> <p></p>"},{"location":"user-guide/interactive-sessions/launch-notebook/#working-in-jupyter-lab","title":"Working in Jupyter Lab","text":""},{"location":"user-guide/interactive-sessions/launch-notebook/#available-interfaces","title":"Available Interfaces","text":"<ul> <li>Python 3 (ipykernel): Standard Python with astronomy libraries</li> <li>Terminal: Command-line access for advanced operations</li> <li>File Browser: Navigate your <code>/arc</code> storage directories</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-notebook/#storage-access","title":"Storage Access","text":"<p>Your notebook session automatically mounts:</p> <ul> <li><code>/arc/projects/[group]/</code>: Shared project storage</li> <li><code>/arc/home/[username]/</code>: Personal storage</li> <li><code>/tmp/</code>: Temporary space (cleared when session ends)</li> </ul> <p>Save to Persistent Storage</p> <p>Files in <code>/tmp/</code> do not persist when the session ends. Save important work to <code>/arc/projects/</code> or <code>/arc/home/</code>. For heavy I/O, use <code>/scratch/</code> if available and copy results to <code>/arc</code> when done.</p>"},{"location":"user-guide/interactive-sessions/launch-notebook/#example-astronomy-analysis","title":"Example: Astronomy Analysis","text":"<p>Here's a simple example using AstroPy to work with FITS data:</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom astropy.io import fits\nfrom astropy.wcs import WCS\n\n# Load a FITS file\nhdul = fits.open(\"/arc/projects/myproject/data/image.fits\")\ndata = hdul[0].data\nheader = hdul[0].header\n\n# Display the image\nplt.figure(figsize=(10, 8))\nplt.imshow(data, origin=\"lower\", cmap=\"viridis\")\nplt.colorbar(label=\"Flux\")\nplt.title(\"Astronomical Image\")\nplt.show()\n</code></pre>"},{"location":"user-guide/interactive-sessions/launch-notebook/#using-casa-in-jupyter","title":"Using CASA in Jupyter","text":"<p>If you're using a CASA container, you can run CASA commands directly in Python notebooks:</p> <p></p> <pre><code># CASA example\nimport casa_tools as tools\nimport casa_tasks as tasks\n\n# Create measurement set summary\ntasks.listobs(vis=\"/arc/projects/myproject/data/observation.ms\")\n\n# Image the data\ntasks.tclean(\n    vis=\"/arc/projects/myproject/data/observation.ms\",\n    imagename=\"my_image\",\n    imsize=1024,\n    cell=\"0.1arcsec\",\n)\n</code></pre>"},{"location":"user-guide/interactive-sessions/launch-notebook/#session-management","title":"Session Management","text":""},{"location":"user-guide/interactive-sessions/launch-notebook/#sharing-sessions","title":"Sharing Sessions","text":"<p>Share your session with collaborators:</p> <ol> <li>Click the session menu in Jupyter Lab</li> <li>Select \"Share Session\"</li> <li>Add collaborator usernames</li> <li>Set permissions (read-only or read-write)</li> </ol>"},{"location":"user-guide/interactive-sessions/launch-notebook/#saving-your-work","title":"Saving Your Work","text":"<ul> <li>Auto-save: Notebooks auto-save every 2 minutes</li> <li>Manual save: Use Ctrl+S or File \u2192 Save</li> <li>Version control: Consider using Git for code versioning</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-notebook/#ending-sessions","title":"Ending Sessions","text":"<p>Always properly shut down your session to free resources:</p> <ol> <li>Save all work</li> <li>Close Jupyter Lab tab</li> <li>Return to Science Portal</li> <li>Click the session icon and select \"Delete\"</li> </ol>"},{"location":"user-guide/interactive-sessions/launch-notebook/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/interactive-sessions/launch-notebook/#resource-usage","title":"Resource Usage","text":"<ul> <li>Start small: Begin with minimal resources and scale up if needed</li> <li>Monitor usage: Use the terminal to check memory with <code>htop</code> or <code>free -h</code></li> <li>Clean up: Remove large temporary files when finished</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-notebook/#data-management","title":"Data Management","text":"<ul> <li>Organize files: Create clear directory structures in your <code>/arc</code> space</li> <li>Document work: Use markdown cells to explain your analysis</li> <li>Backup results: Important results should be saved to persistent storage</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-notebook/#collaboration","title":"Collaboration","text":"<ul> <li>Share sessions: Real-time collaboration for debugging and teaching</li> <li>Version control: Use Git for code sharing and version management</li> <li>Documentation: Well-documented notebooks help collaborators understand your work</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-notebook/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/interactive-sessions/launch-notebook/#common-issues","title":"Common Issues","text":"<p>Session won't start - Check resource availability - Try reducing memory/CPU requirements - Contact support if persistent</p> <p>Can't access files - Verify file paths in <code>/arc/projects/[group]/</code> - Check group permissions - Ensure files were uploaded correctly</p> <p>Notebook kernel crashes - Often due to memory overuse - Restart kernel and reduce data size - Consider using more memory</p> <p>Performance issues - Check if other users are sharing resources - Use <code>htop</code> to monitor system usage - Consider running during off-peak hours</p>"},{"location":"user-guide/interactive-sessions/launch-notebook/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: Storage Guide | Container Guide</li> <li>Support: Email support@canfar.net</li> <li>Community: Join our Discord community for peer support</li> </ul>"},{"location":"user-guide/interactive-sessions/launch-notebook/#next-steps","title":"Next Steps","text":"<ul> <li>Batch Jobs: Scale up to non-interactive processing</li> <li>CARTA Sessions: Specialized image visualization</li> <li>Desktop Sessions: Full graphical desktop environment</li> <li>Radio Astronomy Guide: Learn common astronomy workflows with CANFAR</li> </ul>"},{"location":"user-guide/radio-astronomy/","title":"Radio Astronomy on CANFAR","text":"<p>The CANFAR Science Platform provides comprehensive support for radio astronomy data processing, with specialized containers and workflows optimized for radio interferometry, single-dish observations, and VLBI analysis.</p> <p>\ud83c\udfaf What You'll Learn</p> <ul> <li>The radio astronomy software stack available on CANFAR (CASA, CARTA, tools)</li> <li>How to choose session types and containers for common workflows</li> <li>Typical interferometry, single-dish, and VLBI workflows</li> <li>Strategies for large-scale processing, storage, and performance</li> <li>Troubleshooting tips and best practices for reliable pipelines</li> </ul>"},{"location":"user-guide/radio-astronomy/#overview","title":"Overview","text":"<p>Radio astronomy on CANFAR includes:</p> <ul> <li>CASA (Common Astronomy Software Applications): Complete radio interferometry suite</li> <li>CARTA: Advanced radio data cube visualization</li> <li>Specialized containers: Optimized for radio astronomy workflows</li> <li>Large-scale processing: Handle multi-terabyte datasets efficiently</li> <li>Collaborative analysis: Share sessions and results with your team</li> </ul>"},{"location":"user-guide/radio-astronomy/#radio-astronomy-software-stack","title":"Radio Astronomy Software Stack","text":""},{"location":"user-guide/radio-astronomy/#casa-environments","title":"CASA Environments","text":"<p>CANFAR provides multiple CASA versions and configurations:</p> <ul> <li>CASA 6.5 (recommended): Latest stable release with Python 3 support</li> <li>CASA 6.4: Previous stable version for compatibility</li> <li>CASA Pipeline: Automated calibration and imaging pipelines</li> <li>Custom builds: Specialized versions for specific instruments</li> </ul>"},{"location":"user-guide/radio-astronomy/#supporting-tools","title":"Supporting Tools","text":"<ul> <li>CARTA: Interactive visualization of radio data cubes</li> <li>Miriad: Legacy radio astronomy package</li> <li>AIPS: Classic NRAO package (limited support)</li> <li>Python libraries: RadioAstro tools, APLpy, spectral-cube</li> </ul>"},{"location":"user-guide/radio-astronomy/#data-format-support","title":"Data Format Support","text":"<ul> <li>Measurement Sets (MS): CASA native format</li> <li>FITS: Single-dish and processed data</li> <li>UVFITS: Legacy interferometry format</li> <li>HDF5: Large dataset storage</li> <li>MIRIAD: Legacy format support</li> </ul> <p>Choosing a Container</p> <p>For interactive analysis, start with <code>casa:6.5-notebook</code> or <code>casa:6.5-desktop</code>. Use <code>carta</code> for visualization. For pipelines, use a headless CASA container via batch jobs.</p>"},{"location":"user-guide/radio-astronomy/#common-radio-astronomy-workflows","title":"Common Radio Astronomy Workflows","text":""},{"location":"user-guide/radio-astronomy/#interferometry-data-reduction","title":"Interferometry Data Reduction","text":"<pre><code>graph TD\n    A[Raw Visibility Data] --&gt; B[Data Import]\n    B --&gt; C[Flagging]\n    C --&gt; D[Calibration]\n    D --&gt; E[Imaging]\n    E --&gt; F[Self-calibration]\n    F --&gt; G[Final Images]\n\n    D --&gt; H[Bandpass]\n    D --&gt; I[Gain]\n    D --&gt; J[Flux Scale]</code></pre> <p>Typical steps:</p> <ol> <li>Data import: Convert raw data to Measurement Set format</li> <li>Inspection: Check data quality and structure</li> <li>Flagging: Remove RFI and bad data</li> <li>Calibration: Bandpass, gain, and flux scale calibration</li> <li>Imaging: Create maps with CLEAN algorithm</li> <li>Self-calibration: Iterative improvement</li> <li>Analysis: Extract scientific results</li> </ol>"},{"location":"user-guide/radio-astronomy/#single-dish-processing","title":"Single-dish Processing","text":"<p>Workflow elements:</p> <ul> <li>Data import: Load single-dish observations</li> <li>Baseline subtraction: Remove instrumental effects</li> <li>Calibration: Temperature and flux calibration</li> <li>Gridding: Combine multiple observations</li> <li>Imaging: Create final maps</li> </ul>"},{"location":"user-guide/radio-astronomy/#vlbi-processing","title":"VLBI Processing","text":"<p>Specialized tools:</p> <ul> <li>CASA VLBI pipeline: Automated correlation and calibration</li> <li>AIPS integration: For legacy VLBI workflows</li> <li>Custom scripts: Institution-specific pipelines</li> </ul> <p>Large Datasets</p> <p>Radio data can be very large. Use <code>/scratch/</code> for temporary processing and save results promptly to <code>/arc/projects/</code>. Plan resource allocations (RAM/CPU) accordingly.</p>"},{"location":"user-guide/radio-astronomy/#getting-started-with-radio-astronomy","title":"Getting Started with Radio Astronomy","text":""},{"location":"user-guide/radio-astronomy/#choosing-the-right-session-type","title":"Choosing the Right Session Type","text":"<p>For interactive analysis: - Notebook sessions: Python-based analysis with CASA - Desktop sessions: Full CASA GUI access - CARTA sessions: Data cube visualization</p> <p>For large-scale processing: - Batch jobs: Automated pipeline execution - API submissions: Programmatic job control</p> <p>Resource Sizing</p> <p>Start with 16GB RAM and 2-4 cores for interactive work; increase for imaging and large cubes. Batch jobs can request more resources but may queue longer.</p>"},{"location":"user-guide/radio-astronomy/#container-selection","title":"Container Selection","text":"<p>Choose containers based on your needs:</p> <pre><code># Latest CASA with Jupyter\nimages.canfar.net/skaha/casa:6.5-notebook\n\n# CASA desktop environment\nimages.canfar.net/skaha/casa:6.5-desktop\n\n# CARTA for visualization\nimages.canfar.net/skaha/carta:3.0\n\n# Custom radio astronomy stack\nimages.canfar.net/skaha/radio-submm:latest\n</code></pre>"},{"location":"user-guide/radio-astronomy/#casa-usage-examples","title":"CASA Usage Examples","text":""},{"location":"user-guide/radio-astronomy/#basic-data-inspection","title":"Basic Data Inspection","text":"<pre><code># In a CASA-enabled Python environment\nimport casa_tools as tools\nimport casa_tasks as tasks\n\n# List observation details\ntasks.listobs(vis=\"observation.ms\", verbose=True)\n\n# Plot UV coverage\ntasks.plotuv(vis=\"observation.ms\")\n\n# Check data quality\ntasks.plotms(vis=\"observation.ms\", xaxis=\"time\", yaxis=\"amp\", coloraxis=\"antenna1\")\n</code></pre>"},{"location":"user-guide/radio-astronomy/#calibration-pipeline","title":"Calibration Pipeline","text":"<pre><code># Typical CASA calibration sequence\nimport os\nfrom casa_tasks import *\n\n# Set up paths\nmsname = \"observation.ms\"\ncaldir = \"calibration/\"\nos.makedirs(caldir, exist_ok=True)\n\n# 1. Flagging\nflagdata(vis=msname, mode=\"manual\", antenna=\"ant5\")  # Bad antenna\nflagdata(vis=msname, mode=\"tfcrop\", datacolumn=\"data\")  # RFI\n\n# 2. Set flux scale for calibrator\nsetjy(vis=msname, field=\"3C273\", standard=\"Perley-Butler-2017\")\n\n# 3. Bandpass calibration\nbandpass(\n    vis=msname,\n    caltable=caldir + \"bandpass.bcal\",\n    field=\"3C273\",\n    refant=\"ant1\",\n    solint=\"inf\",\n)\n\n# 4. Gain calibration\ngaincal(\n    vis=msname,\n    caltable=caldir + \"phase.gcal\",\n    field=\"3C273\",\n    calmode=\"p\",\n    refant=\"ant1\",\n    solint=\"int\",\n)\n\ngaincal(\n    vis=msname,\n    caltable=caldir + \"amp.gcal\",\n    field=\"3C273\",\n    calmode=\"ap\",\n    refant=\"ant1\",\n    solint=\"10min\",\n    gaintable=[caldir + \"bandpass.bcal\", caldir + \"phase.gcal\"],\n)\n\n# 5. Apply calibration\napplycal(\n    vis=msname,\n    field=\"target\",\n    gaintable=[caldir + \"bandpass.bcal\", caldir + \"phase.gcal\", caldir + \"amp.gcal\"],\n)\n</code></pre>"},{"location":"user-guide/radio-astronomy/#imaging","title":"Imaging","text":"<pre><code># Create images with tclean\ntclean(\n    vis=\"observation.ms\",\n    imagename=\"target_image\",\n    field=\"target\",\n    imsize=1024,\n    cell=\"0.1arcsec\",\n    weighting=\"briggs\",\n    robust=0.0,\n    niter=1000,\n    threshold=\"0.1mJy\",\n    interactive=False,\n)\n\n# Create moment maps for spectral line data\nimmoments(imagename=\"target_image.image\", moments=[0, 1, 2], outfile=\"target_moments\")\n</code></pre>"},{"location":"user-guide/radio-astronomy/#spectral-line-analysis","title":"Spectral Line Analysis","text":"<pre><code># Extract spectral profiles\nimval(imagename=\"datacube.image\", region=\"circle[[12h30m45s, -30d15m30s], 5arcsec]\")\n\n# Create position-velocity diagrams\nimpv(\n    imagename=\"datacube.image\",\n    outfile=\"pv_diagram.image\",\n    mode=\"coords\",\n    start=\"12h30m40s -30d15m30s\",\n    end=\"12h30m50s -30d15m30s\",\n    width=\"2arcsec\",\n)\n</code></pre>"},{"location":"user-guide/radio-astronomy/#carta-for-radio-data","title":"CARTA for Radio Data","text":""},{"location":"user-guide/radio-astronomy/#loading-data-cubes","title":"Loading Data Cubes","text":"<p>CARTA excels at visualizing radio data cubes:</p> <ol> <li>Launch CARTA session: Use CARTA 3.0 for best performance</li> <li>Load cube: Open your CASA image or FITS cube</li> <li>Navigate channels: Use channel slider for frequency/velocity</li> <li>Create animations: Generate movies through the cube</li> </ol>"},{"location":"user-guide/radio-astronomy/#advanced-carta-features","title":"Advanced CARTA Features","text":"<p>Moment map generation: - Calculate moment 0, 1, and 2 maps interactively - Define custom velocity ranges - Export results for further analysis</p> <p>Spectral analysis: - Click on pixels to see spectra - Fit Gaussian profiles to lines - Measure line properties (velocity, width, flux)</p> <p>Region analysis: - Define analysis regions - Extract statistical properties - Generate publication-quality plots</p>"},{"location":"user-guide/radio-astronomy/#large-scale-radio-processing","title":"Large-Scale Radio Processing","text":""},{"location":"user-guide/radio-astronomy/#batch-processing-strategies","title":"Batch Processing Strategies","text":"<p>For large surveys or multi-epoch observations:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"\nBatch process multiple observations\n\"\"\"\n\nimport os\nimport glob\nfrom casa_tasks import *\n\n\ndef process_observation(msname):\n    \"\"\"Process a single measurement set\"\"\"\n\n    print(f\"Processing {msname}\")\n\n    # Create output directories\n    caldir = f\"{msname}.cal/\"\n    imgdir = f\"{msname}.img/\"\n    os.makedirs(caldir, exist_ok=True)\n    os.makedirs(imgdir, exist_ok=True)\n\n    try:\n        # Calibration\n        calibrate_data(msname, caldir)\n\n        # Imaging\n        image_data(msname, imgdir)\n\n        print(f\"Completed {msname}\")\n\n    except Exception as e:\n        print(f\"Error processing {msname}: {e}\")\n\n\ndef calibrate_data(msname, caldir):\n    \"\"\"Standard calibration pipeline\"\"\"\n\n    # Flagging\n    flagdata(vis=msname, mode=\"tfcrop\")\n\n    # Calibration steps (simplified)\n    bandpass(vis=msname, caltable=f\"{caldir}/bandpass.bcal\")\n    gaincal(vis=msname, caltable=f\"{caldir}/phase.gcal\")\n    applycal(vis=msname, gaintable=[f\"{caldir}/bandpass.bcal\"])\n\n\ndef image_data(msname, imgdir):\n    \"\"\"Create standard images\"\"\"\n\n    # Continuum image\n    tclean(vis=msname, imagename=f\"{imgdir}/continuum\", niter=1000, threshold=\"0.1mJy\")\n\n    # Spectral cube (if line data)\n    tclean(vis=msname, imagename=f\"{imgdir}/cube\", specmode=\"cube\", niter=500)\n\n\n# Main processing loop\nif __name__ == \"__main__\":\n\n    # Find all measurement sets\n    ms_files = glob.glob(\"/arc/projects/survey/data/*.ms\")\n\n    for msname in ms_files:\n        process_observation(msname)\n\n    print(\"Batch processing complete\")\n</code></pre>"},{"location":"user-guide/radio-astronomy/#parallel-processing","title":"Parallel Processing","text":"<p>For very large datasets, use parallel processing:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"\nParallel radio data processing\n\"\"\"\n\nfrom multiprocessing import Pool\nimport functools\n\n\ndef process_with_casa(msname):\n    \"\"\"Process single MS with CASA\"\"\"\n\n    # Import CASA tools in subprocess\n    import casa_tasks as tasks\n\n    # Your processing code here\n    tasks.flagdata(vis=msname, mode=\"tfcrop\")\n    # ... rest of processing\n\n    return f\"Processed {msname}\"\n\n\ndef main():\n    # List of measurement sets\n    ms_files = [\n        \"/arc/projects/survey/data/obs1.ms\",\n        \"/arc/projects/survey/data/obs2.ms\",\n        \"/arc/projects/survey/data/obs3.ms\",\n    ]\n\n    # Process in parallel\n    with Pool(processes=4) as pool:\n        results = pool.map(process_with_casa, ms_files)\n\n    for result in results:\n        print(result)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Batch vs Interactive</p> <p>Use interactive sessions for development and QA of pipelines, then switch to batch jobs for production processing of many datasets.</p>"},{"location":"user-guide/radio-astronomy/#data-management-for-radio-astronomy","title":"Data Management for Radio Astronomy","text":""},{"location":"user-guide/radio-astronomy/#storage-strategy","title":"Storage Strategy","text":"<p>Radio astronomy data requires careful storage planning:</p> <p>Raw data: Store in <code>/arc/projects/[group]/raw/</code> - Original measurement sets - Backup copies of critical observations - Metadata and observation logs</p> <p>Processed data: Organize in <code>/arc/projects/[group]/processed/</code> - Calibrated measurement sets - Final images and cubes - Derived products (catalogs, moment maps)</p> <p>Results: Save to <code>/arc/projects/[group]/results/</code> - Publication-ready images - Scientific catalogs - Analysis scripts and notebooks</p>"},{"location":"user-guide/radio-astronomy/#file-organization","title":"File Organization","text":"<pre><code>/arc/projects/radio-survey/\n\u251c\u2500\u2500 raw/\n\u2502   \u251c\u2500\u2500 2024/\n\u2502   \u2502   \u251c\u2500\u2500 jan/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 obs_20240115.ms\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 obs_20240116.ms\n\u2502   \u2502   \u2514\u2500\u2500 feb/\n\u2502   \u2514\u2500\u2500 2023/\n\u251c\u2500\u2500 processed/\n\u2502   \u251c\u2500\u2500 calibrated/\n\u2502   \u251c\u2500\u2500 images/\n\u2502   \u2514\u2500\u2500 cubes/\n\u251c\u2500\u2500 results/\n\u2502   \u251c\u2500\u2500 catalogs/\n\u2502   \u251c\u2500\u2500 plots/\n\u2502   \u2514\u2500\u2500 papers/\n\u2514\u2500\u2500 scripts/\n    \u251c\u2500\u2500 calibration/\n    \u251c\u2500\u2500 imaging/\n    \u2514\u2500\u2500 analysis/\n</code></pre> <p>Data Hygiene</p> <p>Maintain clear directory structures, version your scripts, and document parameters for reproducibility.</p>"},{"location":"user-guide/radio-astronomy/#data-transfer","title":"Data Transfer","text":"<p>For large radio datasets:</p> <p>From observatories: - Use <code>rsync</code> for efficient transfer - Transfer during off-peak hours - Verify data integrity with checksums</p> <p>Between CANFAR and external systems: - Use VOSpace for large files - Consider data compression - Plan transfer schedules</p>"},{"location":"user-guide/radio-astronomy/#performance-optimization","title":"Performance Optimization","text":""},{"location":"user-guide/radio-astronomy/#memory-management","title":"Memory Management","text":"<p>Radio data processing is memory-intensive:</p> <pre><code># Monitor memory usage in CASA\nimport psutil\nimport os\n\n\ndef check_memory():\n    \"\"\"Check current memory usage\"\"\"\n    process = psutil.Process(os.getpid())\n    memory_gb = process.memory_info().rss / 1024**3\n    print(f\"Memory usage: {memory_gb:.1f} GB\")\n\n\n# Use memory-efficient processing\ncheck_memory()\ntclean(\n    vis=\"large_dataset.ms\",\n    imagename=\"output\",\n    # Use smaller chunk sizes for large data\n    parallel=True,\n    pbcor=False,\n)  # Skip if not needed\ncheck_memory()\n</code></pre>"},{"location":"user-guide/radio-astronomy/#disk-io-optimization","title":"Disk I/O Optimization","text":"<pre><code># Use scratch space for temporary files\nimport tempfile\nimport shutil\n\n# Create temporary directory in scratch space\nwith tempfile.TemporaryDirectory(dir=\"/tmp\") as tmpdir:\n\n    # Copy data to scratch for processing\n    scratch_ms = f\"{tmpdir}/working.ms\"\n    shutil.copytree(\"original.ms\", scratch_ms)\n\n    # Process on fast scratch storage\n    tclean(vis=scratch_ms, imagename=f\"{tmpdir}/temp_image\")\n\n    # Copy results back to persistent storage\n    shutil.copy(f\"{tmpdir}/temp_image.image\", \"/arc/projects/myproject/results/\")\n</code></pre>"},{"location":"user-guide/radio-astronomy/#troubleshooting-radio-workflows","title":"Troubleshooting Radio Workflows","text":""},{"location":"user-guide/radio-astronomy/#common-casa-issues","title":"Common CASA Issues","text":"<p>Memory errors: - Reduce image size or increase session memory - Use chunked processing for large datasets - Clear CASA cache regularly</p> <p>Calibration failures: - Check data quality with <code>plotms</code> - Verify calibrator flux scales - Inspect antenna flagging</p> <p>Imaging problems: - Adjust <code>tclean</code> parameters - Check UV coverage and weighting - Verify coordinate systems</p>"},{"location":"user-guide/radio-astronomy/#performance-issues","title":"Performance Issues","text":"<p>Slow processing: - Use appropriate number of CPU cores - Enable parallel processing where available - Monitor system resources</p> <p>Disk space problems: - Clean up temporary files regularly - Use scratch space for intermediate products - Compress completed datasets</p>"},{"location":"user-guide/radio-astronomy/#getting-help","title":"Getting Help","text":"<p>CASA Documentation: - CASA Guides - CASA Reference Manual</p> <p>CANFAR Support: - Email support@canfar.net - Discord community for peer support - Check existing tutorials and examples</p>"},{"location":"user-guide/radio-astronomy/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/radio-astronomy/#workflow-documentation","title":"Workflow Documentation","text":"<ul> <li>Script versioning: Use Git for analysis scripts</li> <li>Parameter logging: Record all processing parameters</li> <li>Provenance tracking: Document data lineage</li> <li>Reproducibility: Ensure workflows can be repeated</li> </ul>"},{"location":"user-guide/radio-astronomy/#collaboration","title":"Collaboration","text":"<ul> <li>Shared scripts: Develop reusable pipeline components</li> <li>Session sharing: Collaborate on interactive analysis</li> <li>Result sharing: Use consistent output formats</li> <li>Knowledge sharing: Document lessons learned</li> </ul>"},{"location":"user-guide/radio-astronomy/#quality-control","title":"Quality Control","text":"<ul> <li>Validation steps: Include quality checks in pipelines</li> <li>Sanity checks: Verify results at each stage</li> <li>Backup strategies: Protect critical intermediate products</li> <li>Error handling: Robust error recovery in automated pipelines</li> </ul>"},{"location":"user-guide/radio-astronomy/#next-steps","title":"Next Steps","text":"<ul> <li>Interactive Sessions: Get started with CASA and CARTA</li> <li>Batch Processing: Scale up to large datasets</li> <li>Container Development: Customize your radio astronomy environment</li> <li>Storage Guide: Optimize data management strategies</li> </ul>"},{"location":"user-guide/radio-astronomy/casa-workflows/","title":"CASA Desktop Workflows","text":"<p>Advanced CASA workflows and desktop integration for radio astronomy data analysis on the CANFAR Science Platform.</p> <p>\ud83c\udfaf What You'll Learn</p> <ul> <li>How to launch and work efficiently with CASA in desktop sessions</li> <li>Advanced calibration, imaging, and self-calibration workflows</li> <li>Integration patterns with DS9 and CARTA</li> <li>Parallel strategies, memory management, and automation</li> </ul>"},{"location":"user-guide/radio-astronomy/casa-workflows/#overview","title":"Overview","text":"<p>This guide covers sophisticated CASA workflows that leverage the desktop environment for complex analysis, visualization, and data processing tasks.</p>"},{"location":"user-guide/radio-astronomy/casa-workflows/#desktop-casa-setup","title":"Desktop CASA Setup","text":""},{"location":"user-guide/radio-astronomy/casa-workflows/#launching-casa-desktop","title":"Launching CASA Desktop","text":"<ol> <li>Start Desktop Session:</li> <li>Go to CANFAR Portal</li> <li>Click \"Desktop\" session</li> <li>Choose <code>radio-astronomy/casa</code> container</li> <li> <p>Set resources: 4+ cores, 8+ GB RAM for large datasets</p> </li> <li> <p>Open CASA:</p> </li> <li>Click desktop \"Applications\" menu</li> <li>Navigate to \"Science\" \u2192 \"CASA\"</li> <li>Or open terminal and type <code>casa</code></li> </ol> <p>Persistence Reminder</p> <p>Save important results to <code>/arc/projects/</code> or <code>/arc/home/</code>. Temporary locations or session-local directories may not persist after session end.</p>"},{"location":"user-guide/radio-astronomy/casa-workflows/#desktop-environment-advantages","title":"Desktop Environment Advantages","text":"<ul> <li>Multiple CASA sessions: Run parallel analysis tasks</li> <li>GUI tools: Access plotms, casaviewer, casabrowser</li> <li>File management: Visual file browser with FITS preview</li> <li>External tools: Use ds9, CARTA, Python IDEs alongside CASA</li> <li>Session persistence: Keep analysis state across disconnections</li> </ul>"},{"location":"user-guide/radio-astronomy/casa-workflows/#advanced-analysis-workflows","title":"Advanced Analysis Workflows","text":""},{"location":"user-guide/radio-astronomy/casa-workflows/#multi-dataset-calibration-pipeline","title":"Multi-Dataset Calibration Pipeline","text":"<pre><code># casa_calibration_pipeline.py\nimport os\nimport glob\n\n\ndef full_calibration_pipeline(raw_data_dir, output_dir):\n    \"\"\"Complete calibration pipeline for multiple datasets\"\"\"\n\n    # Setup directories\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Find all measurement sets\n    ms_list = glob.glob(f\"{raw_data_dir}/*.ms\")\n\n    for ms in ms_list:\n        print(f\"Processing {ms}\")\n\n        # 1. Initial flagging\n        flagdata(vis=ms, mode=\"manual\", autocorr=True, flagbackup=True)\n\n        # 2. Set flux scale\n        setjy(vis=ms, field=\"3C48\", standard=\"Perley-Butler-2017\")  # Calibrator\n\n        # 3. Bandpass calibration\n        bp_table = f\"{output_dir}/{os.path.basename(ms)}.B1\"\n        bandpass(vis=ms, caltable=bp_table, field=\"3C48\", solint=\"inf\", combine=\"scan\")\n\n        # 4. Phase calibration\n        phase_table = f\"{output_dir}/{os.path.basename(ms)}.G1\"\n        gaincal(\n            vis=ms,\n            caltable=phase_table,\n            field=\"3C48\",\n            calmode=\"p\",\n            solint=\"int\",\n            gaintable=[bp_table],\n        )\n\n        # 5. Amplitude calibration\n        amp_table = f\"{output_dir}/{os.path.basename(ms)}.G2\"\n        gaincal(\n            vis=ms,\n            caltable=amp_table,\n            field=\"3C48\",\n            calmode=\"ap\",\n            solint=\"inf\",\n            gaintable=[bp_table, phase_table],\n        )\n\n        # 6. Apply calibrations\n        applycal(\n            vis=ms,\n            field=\"\",  # All fields\n            gaintable=[bp_table, phase_table, amp_table],\n            gainfield=[\"3C48\", \"3C48\", \"3C48\"],\n        )\n\n        # 7. Split calibrated data\n        output_ms = f\"{output_dir}/{os.path.basename(ms)}_calibrated.ms\"\n        split(vis=ms, outputvis=output_ms, datacolumn=\"corrected\")\n\n        print(f\"Calibration complete: {output_ms}\")\n\n\n# Run pipeline\nfull_calibration_pipeline(\n    \"/arc/projects/survey/raw/\", \"/arc/projects/survey/calibrated/\"\n)\n</code></pre>"},{"location":"user-guide/radio-astronomy/casa-workflows/#imaging-workflow-with-quality-assessment","title":"Imaging Workflow with Quality Assessment","text":"<pre><code># casa_imaging_workflow.py\n\n\ndef imaging_workflow_with_qa(ms_file, target_field, output_dir):\n    \"\"\"Comprehensive imaging with quality assessment\"\"\"\n\n    import matplotlib.pyplot as plt\n    import numpy as np\n\n    base_name = f\"{output_dir}/{target_field}\"\n\n    # 1. Initial dirty image for assessment\n    tclean(\n        vis=ms_file,\n        imagename=f\"{base_name}_dirty\",\n        field=target_field,\n        imsize=[1024, 1024],\n        cell=[\"2arcsec\"],\n        niter=0,  # Dirty image\n        deconvolver=\"hogbom\",\n    )\n\n    # 2. Analyze dirty image for parameters\n    ia.open(f\"{base_name}_dirty.image\")\n    stats = ia.statistics()\n    peak = stats[\"max\"][0]\n    rms = stats[\"rms\"][0]\n    dynamic_range = peak / rms\n    ia.close()\n\n    print(f\"Dirty image stats:\")\n    print(f\"  Peak: {peak:.3e} Jy/beam\")\n    print(f\"  RMS: {rms:.3e} Jy/beam\")\n    print(f\"  Dynamic range: {dynamic_range:.1f}\")\n\n    # 3. Determine cleaning parameters\n    threshold = 3 * rms  # 3-sigma threshold\n    niter = min(10000, int(dynamic_range * 100))\n\n    # 4. Clean image\n    tclean(\n        vis=ms_file,\n        imagename=f\"{base_name}_clean\",\n        field=target_field,\n        imsize=[1024, 1024],\n        cell=[\"2arcsec\"],\n        niter=niter,\n        threshold=f\"{threshold}Jy\",\n        deconvolver=\"multiscale\",\n        scales=[0, 6, 18],\n        gain=0.1,\n        cycleniter=1000,\n        usemask=\"auto-multithresh\",\n        interactive=False,\n    )\n\n    # 5. Primary beam correction\n    impbcor(\n        imagename=f\"{base_name}_clean.image\",\n        pbimage=f\"{base_name}_clean.pb\",\n        outfile=f\"{base_name}_clean.pbcor\",\n        overwrite=True,\n    )\n\n    # 6. Generate diagnostic plots\n    create_qa_plots(f\"{base_name}_clean\", target_field)\n\n    print(f\"Imaging complete: {base_name}_clean.pbcor\")\n\n\ndef create_qa_plots(image_base, field_name):\n    \"\"\"Create quality assessment plots\"\"\"\n\n    # Import CASA plotting tools\n    from casaplotms import plotms\n\n    # 1. uv-coverage plot\n    plotms(\n        vis=f\"{image_base}.ms\",\n        xaxis=\"uvdist\",\n        yaxis=\"amp\",\n        avgtime=\"60s\",\n        plotfile=f\"{image_base}_uvcoverage.png\",\n        showgui=False,\n    )\n\n    # 2. Image histogram\n    ia.open(f\"{image_base}.image\")\n    pixels = ia.getchunk()\n    ia.close()\n\n    plt.figure(figsize=(10, 6))\n    plt.hist(pixels.flatten(), bins=100, alpha=0.7)\n    plt.xlabel(\"Intensity (Jy/beam)\")\n    plt.ylabel(\"Number of pixels\")\n    plt.title(f\"Intensity Distribution - {field_name}\")\n    plt.yscale(\"log\")\n    plt.savefig(f\"{image_base}_histogram.png\")\n    plt.close()\n\n    print(f\"QA plots saved: {image_base}_*.png\")\n\n\n# Example usage\nimaging_workflow_with_qa(\"calibrated_data.ms\", \"M31\", \"/arc/projects/m31/images/\")\n</code></pre>"},{"location":"user-guide/radio-astronomy/casa-workflows/#self-calibration-loop","title":"Self-Calibration Loop","text":"<pre><code># casa_selfcal.py\n\n\ndef self_calibration_loop(\n    ms_file, source_field, output_dir, nloops=3, gain_solint=[\"inf\", \"30s\", \"10s\"]\n):\n    \"\"\"Iterative self-calibration\"\"\"\n\n    base_name = f\"{output_dir}/{source_field}\"\n\n    # Initial image\n    current_ms = ms_file\n\n    for loop in range(nloops):\n        print(f\"\\n=== Self-cal loop {loop + 1} ===\")\n\n        # 1. Image current data\n        img_name = f\"{base_name}_selfcal{loop}\"\n        tclean(\n            vis=current_ms,\n            imagename=img_name,\n            field=source_field,\n            imsize=[512, 512],\n            cell=[\"1arcsec\"],\n            niter=5000,\n            threshold=\"0.1mJy\",\n            deconvolver=\"hogbom\",\n            interactive=False,\n        )\n\n        # 2. Calculate gain solutions\n        cal_table = f\"{base_name}_selfcal{loop}.gcal\"\n        gaincal(\n            vis=current_ms,\n            caltable=cal_table,\n            field=source_field,\n            gaintype=\"G\",\n            calmode=\"p\",  # Phase-only first loops\n            solint=gain_solint[min(loop, len(gain_solint) - 1)],\n            refant=\"auto\",\n        )\n\n        # 3. Apply calibration\n        applycal(vis=current_ms, field=source_field, gaintable=[cal_table])\n\n        # 4. Split corrected data for next loop\n        if loop &lt; nloops - 1:\n            next_ms = f\"{base_name}_selfcal{loop+1}.ms\"\n            split(\n                vis=current_ms,\n                outputvis=next_ms,\n                field=source_field,\n                datacolumn=\"corrected\",\n            )\n            current_ms = next_ms\n\n        # 5. Assess improvement\n        assess_selfcal_improvement(img_name, loop)\n\n\ndef assess_selfcal_improvement(image_name, loop):\n    \"\"\"Assess self-calibration improvement\"\"\"\n\n    ia.open(f\"{image_name}.image\")\n    stats = ia.statistics()\n    peak = stats[\"max\"][0]\n    rms = stats[\"rms\"][0]\n    ia.close()\n\n    print(f\"Loop {loop + 1} results:\")\n    print(f\"  Peak: {peak*1000:.2f} mJy/beam\")\n    print(f\"  RMS: {rms*1000:.2f} mJy/beam\")\n    print(f\"  S/N: {peak/rms:.1f}\")\n\n\n# Run self-calibration\nself_calibration_loop(\"target_data.ms\", \"NGC1068\", \"/arc/projects/agn/selfcal/\")\n</code></pre>"},{"location":"user-guide/radio-astronomy/casa-workflows/#integration-with-external-tools","title":"Integration with External Tools","text":""},{"location":"user-guide/radio-astronomy/casa-workflows/#casa-ds9-workflow","title":"CASA + DS9 Workflow","text":"<pre><code># casa_ds9_integration.py\n\n\ndef casa_to_ds9_analysis(casa_image, region_file=None):\n    \"\"\"Export CASA image to DS9 for detailed analysis\"\"\"\n\n    # 1. Export to FITS\n    fits_name = casa_image.replace(\".image\", \".fits\")\n    exportfits(imagename=casa_image, fitsimage=fits_name, overwrite=True)\n\n    # 2. Launch DS9 with image\n    os.system(f\"ds9 {fits_name} &amp;\")\n\n    # 3. If region file provided, load it\n    if region_file:\n        print(f\"Load region file {region_file} in DS9\")\n        print(\"File \u2192 Region \u2192 Load\")\n\n    # 4. Return to CASA for further analysis\n    print(f\"Image {fits_name} loaded in DS9\")\n    print(\"Create regions in DS9, save as .reg file\")\n    print(\"Use importuvfits() to load back to CASA if needed\")\n\n\n# Usage\ncasa_to_ds9_analysis(\"M31_clean.image\", \"spiral_arms.reg\")\n</code></pre>"},{"location":"user-guide/radio-astronomy/casa-workflows/#casa-carta-integration","title":"CASA + CARTA Integration","text":"<pre><code># casa_carta_workflow.py\n\n\ndef casa_carta_cube_analysis(cube_ms, output_cube):\n    \"\"\"Create spectral cube for CARTA analysis\"\"\"\n\n    # 1. Create spectral cube\n    tclean(\n        vis=cube_ms,\n        imagename=output_cube,\n        imsize=[256, 256, 1, 100],  # spatial + spectral\n        cell=[\"2arcsec\"],\n        niter=1000,\n        deconvolver=\"hogbom\",\n        specmode=\"cube\",\n        start=\"1.4GHz\",\n        width=\"1MHz\",\n        nchan=100,\n    )\n\n    # 2. Export for CARTA\n    fits_cube = f\"{output_cube}.fits\"\n    exportfits(imagename=f\"{output_cube}.image\", fitsimage=fits_cube, overwrite=True)\n\n    # 3. Launch CARTA\n    print(f\"Load {fits_cube} in CARTA for:\")\n    print(\"- Spectral profile analysis\")\n    print(\"- Moment map generation\")\n    print(\"- Region statistics\")\n    print(\"- 3D visualization\")\n\n    return fits_cube\n\n\n# Create cube for analysis\ncube_fits = casa_carta_cube_analysis(\"line_data.ms\", \"HI_cube\")\n</code></pre>"},{"location":"user-guide/radio-astronomy/casa-workflows/#parallel-processing-strategies","title":"Parallel Processing Strategies","text":""},{"location":"user-guide/radio-astronomy/casa-workflows/#multi-core-casa-operations","title":"Multi-Core CASA Operations","text":"<pre><code># casa_parallel.py\nimport multiprocessing as mp\nimport os\n\n\ndef parallel_imaging(ms_list, output_dir, ncores=None):\n    \"\"\"Image multiple datasets in parallel\"\"\"\n\n    if ncores is None:\n        ncores = mp.cpu_count() - 1\n\n    def image_single_ms(ms_file):\n        \"\"\"Image a single measurement set\"\"\"\n        base_name = os.path.basename(ms_file).replace(\".ms\", \"\")\n\n        tclean(\n            vis=ms_file,\n            imagename=f\"{output_dir}/{base_name}\",\n            imsize=[512, 512],\n            cell=[\"2arcsec\"],\n            niter=1000,\n            deconvolver=\"hogbom\",\n        )\n\n        return f\"Completed: {base_name}\"\n\n    # Use multiprocessing\n    with mp.Pool(ncores) as pool:\n        results = pool.map(image_single_ms, ms_list)\n\n    for result in results:\n        print(result)\n\n\n# Process multiple observations\nms_files = glob.glob(\"/arc/projects/survey/*.ms\")\nparallel_imaging(ms_files, \"/arc/projects/survey/images/\", ncores=4)\n</code></pre>"},{"location":"user-guide/radio-astronomy/casa-workflows/#memory-efficient-large-dataset-processing","title":"Memory-Efficient Large Dataset Processing","text":"<pre><code># casa_memory_efficient.py\n\n\ndef process_large_cube(input_cube, chunk_size=10):\n    \"\"\"Process large spectral cubes in chunks\"\"\"\n\n    # Get cube dimensions\n    ia.open(input_cube)\n    shape = ia.shape()\n    nchans = shape[3]\n    ia.close()\n\n    # Process in chunks\n    for start_chan in range(0, nchans, chunk_size):\n        end_chan = min(start_chan + chunk_size, nchans)\n\n        print(f\"Processing channels {start_chan}-{end_chan}\")\n\n        # Extract channel subset\n        chunk_name = f\"temp_chunk_{start_chan}_{end_chan}\"\n        imsubimage(\n            imagename=input_cube,\n            outfile=chunk_name,\n            box=\"\",\n            chans=f\"{start_chan}~{end_chan}\",\n        )\n\n        # Process chunk (example: smooth)\n        imsmooth(\n            imagename=chunk_name,\n            outfile=f\"{chunk_name}_smooth\",\n            kernel=\"gauss\",\n            major=\"3arcsec\",\n            minor=\"3arcsec\",\n        )\n\n        # Clean up temporary files\n        os.system(f\"rm -rf {chunk_name}\")\n\n        print(f\"Chunk {start_chan}-{end_chan} complete\")\n\n\n# Process 1000-channel cube in 50-channel chunks\nprocess_large_cube(\"large_HI_cube.image\", chunk_size=50)\n</code></pre> <p>Performance Planning</p> <p>Imaging and spectral cubes can be resource-intensive. Plan for sufficient RAM and use chunking or parallelization where possible.</p>"},{"location":"user-guide/radio-astronomy/casa-workflows/#automation-and-scripting","title":"Automation and Scripting","text":""},{"location":"user-guide/radio-astronomy/casa-workflows/#batch-processing-script","title":"Batch Processing Script","text":"<pre><code>#!/bin/bash\n# casa_batch_processing.sh\n\n# Set up environment\nexport OMP_NUM_THREADS=4\nexport CASA_ENGINE_LOG_LEVEL=WARN\n\n# Define directories\nRAW_DIR=\"/arc/projects/survey/raw\"\nCAL_DIR=\"/arc/projects/survey/calibrated\"  \nIMG_DIR=\"/arc/projects/survey/images\"\n\n# Create output directories\nmkdir -p $CAL_DIR $IMG_DIR\n\n# Process all measurement sets\nfor ms_file in $RAW_DIR/*.ms; do\n    echo \"Processing $(basename $ms_file)\"\n\n    # Run CASA calibration\n    casa --nogui -c \"execfile('calibration_pipeline.py'); \\\n                     full_calibration_pipeline('$ms_file', '$CAL_DIR')\"\n\n    # Run imaging\n    casa --nogui -c \"execfile('imaging_workflow.py'); \\\n                     imaging_workflow('$CAL_DIR/$(basename $ms_file .ms)_cal.ms', '$IMG_DIR')\"\ndone\n\necho \"Batch processing complete\"\n</code></pre>"},{"location":"user-guide/radio-astronomy/casa-workflows/#quality-assessment-dashboard","title":"Quality Assessment Dashboard","text":"<pre><code># casa_qa_dashboard.py\nimport glob\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\ndef generate_qa_dashboard(image_dir, output_html):\n    \"\"\"Generate HTML quality assessment dashboard\"\"\"\n\n    images = glob.glob(f\"{image_dir}/*.image\")\n\n    html_content = \"\"\"\n    &lt;html&gt;\n    &lt;head&gt;&lt;title&gt;CASA Processing QA Dashboard&lt;/title&gt;&lt;/head&gt;\n    &lt;body&gt;\n    &lt;h1&gt;Quality Assessment Dashboard&lt;/h1&gt;\n    &lt;table border=\"1\"&gt;\n    &lt;tr&gt;&lt;th&gt;Image&lt;/th&gt;&lt;th&gt;Peak (mJy)&lt;/th&gt;&lt;th&gt;RMS (mJy)&lt;/th&gt;&lt;th&gt;Dynamic Range&lt;/th&gt;&lt;/tr&gt;\n    \"\"\"\n\n    for image in images:\n        # Get statistics\n        ia.open(image)\n        stats = ia.statistics()\n        peak = stats[\"max\"][0] * 1000  # Convert to mJy\n        rms = stats[\"rms\"][0] * 1000\n        dynamic_range = peak / rms\n        ia.close()\n\n        # Add to HTML\n        base_name = os.path.basename(image)\n        html_content += f\"\"\"\n        &lt;tr&gt;\n        &lt;td&gt;{base_name}&lt;/td&gt;\n        &lt;td&gt;{peak:.2f}&lt;/td&gt;\n        &lt;td&gt;{rms:.2f}&lt;/td&gt;\n        &lt;td&gt;{dynamic_range:.1f}&lt;/td&gt;\n        &lt;/tr&gt;\n        \"\"\"\n\n    html_content += \"\"\"\n    &lt;/table&gt;\n    &lt;/body&gt;\n    &lt;/html&gt;\n    \"\"\"\n\n    with open(output_html, \"w\") as f:\n        f.write(html_content)\n\n    print(f\"QA dashboard saved: {output_html}\")\n\n\n# Generate dashboard\ngenerate_qa_dashboard(\n    \"/arc/projects/survey/images/\", \"/arc/projects/survey/qa_dashboard.html\"\n)\n</code></pre>"},{"location":"user-guide/radio-astronomy/casa-workflows/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/radio-astronomy/casa-workflows/#resource-management","title":"Resource Management","text":"<ul> <li>Memory allocation: Reserve 2GB per core for imaging</li> <li>Disk space: Allow 5x input data size for intermediate files</li> <li>Parallel processing: Use n-1 cores to maintain system responsiveness</li> <li>Cleanup: Remove temporary files regularly</li> </ul>"},{"location":"user-guide/radio-astronomy/casa-workflows/#workflow-organization","title":"Workflow Organization","text":"<pre><code># Directory structure for complex projects\nproject_structure = {\n    \"raw/\": \"Original measurement sets\",\n    \"calibrated/\": \"Calibrated data\",\n    \"images/\": \"Final images\",\n    \"scripts/\": \"Processing scripts\",\n    \"logs/\": \"Processing logs\",\n    \"qa/\": \"Quality assessment outputs\",\n    \"docs/\": \"Analysis documentation\",\n}\n</code></pre>"},{"location":"user-guide/radio-astronomy/casa-workflows/#error-handling","title":"Error Handling","text":"<pre><code>def robust_casa_operation(operation_func, *args, max_retries=3, **kwargs):\n    \"\"\"Execute CASA operation with error handling\"\"\"\n\n    for attempt in range(max_retries):\n        try:\n            result = operation_func(*args, **kwargs)\n            return result\n        except Exception as e:\n            print(f\"Attempt {attempt + 1} failed: {e}\")\n            if attempt &lt; max_retries - 1:\n                print(\"Retrying...\")\n                time.sleep(5)\n            else:\n                print(\"Operation failed after all retries\")\n                raise e\n\n\n# Usage\nrobust_casa_operation(tclean, vis=\"data.ms\", imagename=\"output\", niter=1000)\n</code></pre>"},{"location":"user-guide/radio-astronomy/casa-workflows/#next-steps","title":"Next Steps","text":"<ul> <li>Radio Astronomy Guide \u2192 - Complete radio astronomy workflows</li> <li>CARTA Integration \u2192 - Advanced visualization</li> <li>Batch Processing \u2192 - Automate CASA workflows</li> <li>Storage Management \u2192 - Organize large datasets</li> </ul>"},{"location":"user-guide/storage/","title":"CANFAR Storage Systems","text":"<p>Master CANFAR's storage systems for efficient data management</p> <p>\ud83c\udfaf What You'll Learn</p> <p>By the end of this guide, you'll understand: - The different storage systems available on CANFAR - When and how to use each storage type for your research - Best practices for data management, transfer, and backup - How to optimize your workflow for performance and data safety</p> <p>CANFAR provides multiple storage systems optimized for different stages of your research workflow. Understanding when and how to use each storage type is crucial for efficient data analysis and collaboration.</p>"},{"location":"user-guide/storage/#types-comparison","title":"\ud83d\udcca Types Comparison","text":"Storage Mount Path Speed Persistence Backup Quota Best For ARC Projects <code>/arc/projects/group/</code> Fast SSD \u2705 Permanent \u2705 Daily snapshots Project-based Active research, shared data ARC Home <code>/arc/home/username/</code> Fast SSD \u2705 Permanent \u2705 Daily snapshots 10GB default Personal configs, keys Scratch <code>/scratch/</code> Fastest NVMe \u274c Wiped at session end \u274c No backup Unlimited Temporary processing VOSpace <code>vos:username/</code> Medium \u2705 Permanent \u2705 Geo-redundant User/project based Archives, public data"},{"location":"user-guide/storage/#storage-lifecycle-overview","title":"\ud83d\uddfa\ufe0f Storage Lifecycle Overview","text":"<p>CANFAR's storage architecture is designed around the astronomy research lifecycle:</p> <pre><code>graph LR\n    Archive[\"\ud83d\udce6 External Archives&lt;br/&gt;ALMA, HST, etc.\"] \n    Download[\"\u2b07\ufe0f Download\"]\n    Scratch[\"\u26a1 Scratch Storage&lt;br/&gt;Fast processing\"]\n    Process[\"\ud83d\udd04 Data Processing\"]\n    ARC[\"\ud83d\udcc1 ARC Projects&lt;br/&gt;Shared results\"]\n    VOSpace[\"\u2601\ufe0f VOSpace&lt;br/&gt;Long-term archive\"]\n\n    Archive --&gt; Download\n    Download --&gt; Scratch\n    Scratch --&gt; Process\n    Process --&gt; ARC\n    ARC --&gt; VOSpace\n    ARC -.-&gt; |Backup| Process</code></pre>"},{"location":"user-guide/storage/#arc-storage","title":"\ud83d\udcc1 ARC Storage","text":"<p>ARC (Advanced Research Computing) storage provides high-performance, persistent storage for active research.</p>"},{"location":"user-guide/storage/#arcprojectsgroupname-shared-research-storage","title":"<code>/arc/projects/groupname/</code> - Shared Research Storage","text":"<p>When to Use ARC Projects</p> <ul> <li>Raw and processed datasets</li> <li>Analysis scripts and notebooks  </li> <li>Results and publications</li> <li>Shared team resources</li> <li>Collaborative workflows</li> </ul> <p>\ud83d\udd27 Features:</p> <ul> <li>Shared access - All group members can read/write</li> <li>Fast SSD storage - Optimized for data analysis</li> <li>Daily backups - 30-day retention policy</li> <li>ACL support - Fine-grained permission control</li> </ul> <p>\ud83d\udcc2 Recommended Structure:</p> <pre><code>/arc/projects/myproject/\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 raw/              # Original observational data\n\u2502   \u251c\u2500\u2500 processed/        # Calibrated/reduced data  \n\u2502   \u251c\u2500\u2500 catalogs/         # Reference catalogs\n\u2502   \u2514\u2500\u2500 simulations/      # Synthetic datasets\n\u251c\u2500\u2500 code/\n\u2502   \u251c\u2500\u2500 pipelines/        # Data processing workflows\n\u2502   \u251c\u2500\u2500 analysis/         # Analysis scripts\n\u2502   \u251c\u2500\u2500 notebooks/        # Jupyter notebooks\n\u2502   \u2514\u2500\u2500 tools/            # Custom utilities\n\u251c\u2500\u2500 results/\n\u2502   \u251c\u2500\u2500 plots/            # Figures and visualizations\n\u2502   \u251c\u2500\u2500 tables/           # Output measurements\n\u2502   \u251c\u2500\u2500 papers/           # Manuscripts and drafts\n\u2502   \u2514\u2500\u2500 presentations/    # Conference materials\n\u2514\u2500\u2500 docs/\n    \u251c\u2500\u2500 README.md         # Project documentation\n    \u251c\u2500\u2500 data_notes.md     # Dataset descriptions\n    \u2514\u2500\u2500 procedures.md     # Analysis procedures\n</code></pre>"},{"location":"user-guide/storage/#archomeusername-personal-space","title":"<code>/arc/home/username/</code> - Personal Space","text":"<p>When to Use ARC Home</p> <ul> <li>Personal configuration files (<code>.bashrc</code>, <code>.jupyter/</code>)</li> <li>SSH keys and authentication credentials</li> <li>Personal scripts and utilities</li> <li>Small reference files</li> </ul> <p>\u26a0\ufe0f Limitations:</p> <ul> <li>10GB default quota (contact support for increases)</li> <li>Personal access only (not shared)</li> <li>Not suitable for large datasets</li> </ul>"},{"location":"user-guide/storage/#storage-management","title":"Managing ARC Storage","text":""},{"location":"user-guide/storage/#check-usage-and-quotas","title":"Check Usage and Quotas","text":"<pre><code># Check project storage usage\ndf -h /arc/projects/myproject\n\n# Detailed usage breakdown\ndu -sh /arc/projects/myproject/*\n\n# Check home directory usage\ndu -sh /arc/home/$USER/*\n\n# Check available space\ndf -h /arc\n</code></pre>"},{"location":"user-guide/storage/#organizing-data","title":"Organizing Data","text":"<pre><code># Create organized directory structure\nmkdir -p /arc/projects/myproject/{data/{raw,processed,catalogs},code,results,docs}\n\n# Set group permissions for collaboration\nchmod -R g+rw /arc/projects/myproject/\nchmod g+s /arc/projects/myproject/  # Inherit group ownership\n</code></pre>"},{"location":"user-guide/storage/#backup-and-recovery","title":"Backup and Recovery","text":"<p>ARC Backup</p> <p>ARC storage is automatically backed up daily with a 30-day retention policy. You can also restore files from snapshots if needed.</p> <pre><code># List available snapshots (if enabled)\nls /arc/projects/myproject/.snapshots/\n\n# Restore from snapshot\ncp /arc/projects/myproject/.snapshots/daily.2024-03-15/important_file.fits \\\n   /arc/projects/myproject/restored_file.fits\n</code></pre>"},{"location":"user-guide/storage/#scratch-storage","title":"\u26a1 Scratch Storage","text":"<p>Scratch provides the fastest storage available on CANFAR, but files are temporary.</p> <p>Important: Scratch Storage Lifecycle</p> <p>Scratch storage is wiped at the end of each session, not nightly as some older documentation stated. When your interactive session ends or your batch job completes, all files in <code>/scratch/</code> are permanently deleted.</p>"},{"location":"user-guide/storage/#when-to-use-scratch","title":"When to Use Scratch","text":"<p>\u2705 Excellent for: - Large intermediate files during processing - Temporary downloads before organizing in ARC - High I/O operations requiring maximum speed - Uncompressing large archives - Sorting and filtering large datasets</p> <p>\u274c Never use for: - Important results (will be lost!) - Files you need to keep between sessions - Shared data (only accessible within your session)</p>"},{"location":"user-guide/storage/#scratch-lifecycle","title":"Scratch Lifecycle","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Session as Session/Job\n    participant Scratch as /scratch/\n\n    User-&gt;&gt;Session: Start session\n    Session-&gt;&gt;Scratch: Create empty /scratch/ directory\n    User-&gt;&gt;Scratch: Work with temporary files\n    Note over Scratch: Fast NVMe storage\n    User-&gt;&gt;Session: End session\n    Session-&gt;&gt;Scratch: DELETE ALL FILES\n    Note over Scratch: Directory wiped clean</code></pre>"},{"location":"user-guide/storage/#scratch-best-practices","title":"Scratch Best Practices","text":"<pre><code># 1. Download large files to scratch first\ncd /scratch\nwget https://archive.alma.cl/large_dataset.tar.gz\n\n# 2. Process immediately\ntar -xzf large_dataset.tar.gz\ncasa --nologger -c \"process_data.py\"\n\n# 3. Save results to permanent storage\ncp processed_results.fits /arc/projects/myproject/data/processed/\n\n# 4. Clean up isn't necessary (done automatically)\n# but good practice during long sessions\nrm large_dataset.tar.gz intermediate_*.fits\n</code></pre>"},{"location":"user-guide/storage/#multi-step-processing-workflow","title":"Multi-step Processing Workflow","text":"<pre><code>#!/bin/bash\n# Example: ALMA data reduction workflow using scratch\n\n# Step 1: Download to scratch\ncd /scratch\nalmaget 2019.1.00123.S\n\n# Step 2: Process with CASA\ncasa --nologger --agg -c \"\"\"\n# CASA script here\nexecfile('/arc/projects/myproject/code/reduction_script.py')\n\"\"\"\n\n# Step 3: Save important results\nmkdir -p /arc/projects/myproject/data/2019.1.00123.S/\ncp *.image.fits /arc/projects/myproject/data/2019.1.00123.S/\ncp *.uvfits /arc/projects/myproject/data/2019.1.00123.S/\n\n# Step 4: Create processing log\necho \"Processed $(date): 2019.1.00123.S\" &gt;&gt; /arc/projects/myproject/processing_log.txt\n</code></pre>"},{"location":"user-guide/storage/#vospace","title":"\u2601\ufe0f VOSpace","text":"<p>VOSpace provides web-accessible, long-term archive storage based on IVOA standards.</p> <p>When to Use VOSpace</p> <ul> <li>Archives and public data</li> <li>Long-term preservation</li> <li>Sharing data with external collaborators</li> <li>Metadata-rich datasets</li> </ul> <p>\ud83d\udd27 Features:</p> <ul> <li>Web-based access - Upload/download via browser or command line</li> <li>Metadata support - Store astronomical metadata with files</li> <li>Version control - Track changes to datasets</li> <li>Sharing controls - Fine-grained access permissions</li> <li>Geographic redundancy - Multiple backup locations</li> </ul> <p>\u26a0\ufe0f Considerations:</p> <ul> <li>Slower access than ARC storage (network-based)</li> <li>Better for archives than active analysis</li> <li>Command-line tools required for advanced features</li> </ul>"},{"location":"user-guide/storage/#vospace-vs-arc-comparison","title":"VOSpace vs ARC Comparison","text":"Use Case VOSpace ARC Projects Active analysis \u274c Too slow \u2705 Optimized Data sharing \u2705 Web interface \u26a0\ufe0f Requires group membership Public releases \u2705 Public URLs \u274c Access controlled Long-term preservation \u2705 Geo-redundant \u2705 Daily backups Large file processing \u274c Network overhead \u2705 Direct access"},{"location":"user-guide/storage/#using-vospace","title":"Using VOSpace","text":""},{"location":"user-guide/storage/#web-interface","title":"Web Interface","text":"<p>Access VOSpace through the CANFAR portal: \ud83d\udd17 VOSpace File Manager</p>"},{"location":"user-guide/storage/#command-line-tools","title":"Command Line Tools","text":"<pre><code># Install VOSpace tools\npip install vostools\n\n# List VOSpace contents\nvls vos:myproject\n\n# Upload file\nvcp local_file.fits vos:myproject/\n\n# Download file  \nvcp vos:myproject/data.fits ./\n\n# Create directory\nvmkdir vos:myproject/results\n\n# Set permissions\nvchmod o+r vos:myproject/public_data.fits  # Make publicly readable\n</code></pre>"},{"location":"user-guide/storage/#vospace-python-api","title":"VOSpace Python API","text":"<pre><code>import vos\n\n# Create client\nclient = vos.Client()\n\n# Upload file with metadata\nclient.copy(\"local_file.fits\", \"vos:myproject/survey_data.fits\")\n\n# Set metadata\nnode = client.get_node(\"vos:myproject/survey_data.fits\")\nnode.props[\"TELESCOPE\"] = \"ALMA\"\nnode.props[\"OBJECT\"] = \"NGC1365\"\nclient.update(node)\n\n# Download with progress\nclient.copy(\"vos:myproject/large_file.fits\", \"local_copy.fits\", send_md5=True)\n</code></pre>"},{"location":"user-guide/storage/#data-transfer-strategies","title":"\ud83d\udd04 Data Transfers","text":"<p>Data Transfer Best Practice</p> <p>Always move important results from <code>/scratch/</code> to <code>/arc/projects/</code> or VOSpace before ending your session. Use the right tool for your file size and workflow.</p>"},{"location":"user-guide/storage/#transfer-strategies-by-data-size","title":"Transfer Strategies by Data Size","text":""},{"location":"user-guide/storage/#small-files-1gb","title":"Small Files (&lt;1GB)","text":"<pre><code># Direct copy (fastest for small files)\ncp /scratch/result.fits /arc/projects/myproject/results/\n\n# VOSpace upload\nvcp /arc/projects/myproject/final_catalog.fits vos:myproject/\n</code></pre>"},{"location":"user-guide/storage/#medium-files-1-100gb","title":"Medium Files (1-100GB)","text":"<pre><code># Use rsync for reliability\nrsync -av --progress /scratch/large_dataset/ /arc/projects/myproject/data/\n\n# VOSpace with compression\nvcp --enable-compression /arc/projects/myproject/datacube.fits vos:myproject/\n</code></pre>"},{"location":"user-guide/storage/#large-files-100gb","title":"Large Files (&gt;100GB)","text":"<pre><code># Process in chunks\nfor file in /scratch/survey_*.fits; do\n    # Process individual file\n    process_file.py \"$file\" \n    # Save results immediately\n    cp \"${file%.fits}_processed.fits\" /arc/projects/myproject/processed/\n    # Remove processed input to save space\n    rm \"$file\"\ndone\n</code></pre>"},{"location":"user-guide/storage/#sshfs-setup-for-external-access","title":"SSHFS Setup for External Access","text":"<p>Mount CANFAR storage on your local computer:</p> <pre><code># Install SSHFS (macOS with Homebrew)\nbrew install --cask macfuse\nbrew install sshfs\n\n# Create mount point\nmkdir ~/canfar\n\n# Mount ARC storage\nsshfs username@ws-uv.canfar.net:/arc/projects/myproject ~/canfar\n\n# Work with files locally\nls ~/canfar\ncp ~/local_analysis.py ~/canfar/code/\n\n# Unmount when done\numount ~/canfar\n</code></pre>"},{"location":"user-guide/storage/#sshfs-on-different-platforms","title":"SSHFS on Different Platforms","text":"macOSLinuxWindows <pre><code># Install dependencies\nbrew install --cask macfuse\nbrew install sshfs\n\n# Mount\nsshfs username@ws-uv.canfar.net:/arc/projects/myproject ~/canfar\n</code></pre> <pre><code># Install SSHFS\nsudo apt install sshfs  # Ubuntu/Debian\n# or\nsudo yum install sshfs  # CentOS/RHEL\n\n# Mount\nsshfs username@ws-uv.canfar.net:/arc/projects/myproject ~/canfar\n</code></pre> <pre><code># Install WinFsp and SSHFS-Win\n# Download from: https://github.com/billziss-gh/sshfs-win\n\n# Mount using SSHFS-Win GUI or command line\n</code></pre>"},{"location":"user-guide/storage/#advanced-storage-operations","title":"\ud83d\udee0\ufe0f Advanced Storage Operations","text":""},{"location":"user-guide/storage/#full-vospace-api-usage","title":"Full VOSpace API Usage","text":""},{"location":"user-guide/storage/#metadata-management","title":"Metadata Management","text":"<pre><code># Set custom metadata\nvattr vos:myproject/observation.fits TELESCOPE ALMA\nvattr vos:myproject/observation.fits OBJECT \"NGC 1365\"\nvattr vos:myproject/observation.fits DATE-OBS \"2024-03-15\"\n\n# View metadata\nvattr vos:myproject/observation.fits\n</code></pre>"},{"location":"user-guide/storage/#advanced-permissions","title":"Advanced Permissions","text":"<pre><code># Make file publicly readable\nvchmod o+r vos:myproject/public_catalog.fits\n\n# Grant read access to specific group\nvchmod g+r:external-collaborators vos:myproject/shared_data.fits\n\n# Set up public directory\nvmkdir vos:myproject/public\nvchmod o+r vos:myproject/public\n</code></pre>"},{"location":"user-guide/storage/#cutout-services","title":"Cutout Services","text":"<p>Access subsections of large files without downloading the entire dataset:</p> <pre><code>import requests\n\n# Get cutout from FITS file in VOSpace\ncutout_url = \"https://ws-cadc.canfar.net/vospace/data/myproject/large_image.fits\"\nparams = {\"cutout\": \"[1:100,1:100]\", \"format\": \"fits\"}  # Section to extract\n\nresponse = requests.get(cutout_url, params=params)\nwith open(\"cutout.fits\", \"wb\") as f:\n    f.write(response.content)\n</code></pre>"},{"location":"user-guide/storage/#automated-data-workflows","title":"Automated Data Workflows","text":"<pre><code>#!/usr/bin/env python\n\"\"\"\nAutomated data processing workflow using multiple storage systems\n\"\"\"\nimport os\nimport shutil\nimport vos\nfrom pathlib import Path\n\n\ndef process_dataset(dataset_id):\n    \"\"\"Process a dataset using optimal storage strategy\"\"\"\n\n    # 1. Download to scratch for fast processing\n    scratch_dir = Path(f\"/scratch/{dataset_id}\")\n    scratch_dir.mkdir(exist_ok=True)\n\n    # Download from VOSpace to scratch\n    client = vos.Client()\n    client.copy(f\"vos:archive/{dataset_id}.fits\", str(scratch_dir / \"raw_data.fits\"))\n\n    # 2. Process data (using scratch for speed)\n    os.chdir(scratch_dir)\n    # ... processing code here ...\n\n    # 3. Save results to ARC projects\n    results_dir = Path(f\"/arc/projects/myproject/results/{dataset_id}\")\n    results_dir.mkdir(parents=True, exist_ok=True)\n\n    # Copy important results\n    shutil.copy(\"processed_image.fits\", results_dir)\n    shutil.copy(\"measurements.csv\", results_dir)\n    shutil.copy(\"processing.log\", results_dir)\n\n    # 4. Archive final products to VOSpace\n    client.copy(\n        str(results_dir / \"processed_image.fits\"),\n        f\"vos:myproject/processed/{dataset_id}_final.fits\",\n    )\n\n    # Scratch cleanup happens automatically at session end\n    print(f\"Processed {dataset_id} successfully\")\n\n\n# Process multiple datasets\nfor dataset in [\"obs001\", \"obs002\", \"obs003\"]:\n    process_dataset(dataset)\n</code></pre>"},{"location":"user-guide/storage/#whats-next","title":"\ud83d\udd17 What's Next?","text":"<p>Now that you understand CANFAR's storage systems:</p> <ul> <li>VOSpace API Guide \u2192 - Advanced programmatic access and detailed transfer methods</li> <li>Interactive Sessions \u2192 - Access storage from sessions</li> <li>Batch Jobs \u2192 - Automated storage workflows</li> <li>Container Guide \u2192 - Storage access in containers</li> </ul> <p>Storage Strategy Summary</p> <p>Golden Rule: Use <code>/scratch/</code> for fast temporary work, save everything important to <code>/arc/projects/</code>, and archive final results in VOSpace. Plan your data workflow around these three storage tiers for optimal performance and data safety.</p>"},{"location":"user-guide/storage/vospace-api/","title":"VOSpace API and Advanced Tools","text":"<p>Advanced data management capabilities using VOSpace APIs and command-line tools for automation and bulk operations.</p>"},{"location":"user-guide/storage/vospace-api/#overview","title":"Overview","text":"<p>While the Storage Guide covers basic file operations, this guide focuses on programmatic access to your data using VOSpace APIs, command-line tools, and advanced workflows.</p>"},{"location":"user-guide/storage/vospace-api/#command-line-tools","title":"Command-Line Tools","text":""},{"location":"user-guide/storage/vospace-api/#installation","title":"Installation","text":"<p>VOSpace tools are pre-installed in all CANFAR containers. For local use:</p> <pre><code># In CANFAR notebook/desktop session\npip install vos\n\n# Verify installation\nvls --help\n</code></pre>"},{"location":"user-guide/storage/vospace-api/#authentication","title":"Authentication","text":"<pre><code># Get a security certificate (valid for 24 hours)\ncadc-get-cert --cert ~/.ssl/cadcproxy.pem\n\n# Or use your username/password\nexport CADC_USERNAME=your_username\nexport CADC_PASSWORD=your_password\n</code></pre>"},{"location":"user-guide/storage/vospace-api/#basic-operations","title":"Basic Operations","text":"<pre><code># List files and directories\nvls vos:CANFAR/your_username/\n\n# Copy files to VOSpace\nvcp mydata.fits vos:CANFAR/your_username/data/\n\n# Copy files from VOSpace  \nvcp vos:CANFAR/your_username/data/mydata.fits ./\n\n# Create directories\nvmkdir vos:CANFAR/your_username/projects/survey_analysis/\n\n# Move/rename files\nvmv vos:CANFAR/your_username/old.fits vos:CANFAR/your_username/new.fits\n\n# Remove files\nvrm vos:CANFAR/your_username/temp/old_data.fits\n</code></pre>"},{"location":"user-guide/storage/vospace-api/#bulk-operations","title":"Bulk Operations","text":"<pre><code># Sync entire directories\nvsync --recursive ./local_data/ vos:CANFAR/your_username/backup/\n\n# Download project data\nvsync --recursive vos:CANFAR/shared_project/survey_data/ ./project_data/\n\n# Upload analysis results\nvsync --recursive ./results/ vos:CANFAR/your_username/analysis_outputs/\n</code></pre>"},{"location":"user-guide/storage/vospace-api/#python-api","title":"Python API","text":""},{"location":"user-guide/storage/vospace-api/#basic-usage","title":"Basic Usage","text":"<pre><code>import vos\n\n# Initialize client\nclient = vos.Client()\n\n# List directory contents\nfiles = client.listdir(\"vos:CANFAR/your_username/\")\nprint(files)\n\n# Check if file exists\nexists = client.isfile(\"vos:CANFAR/your_username/data.fits\")\n\n# Get file info\ninfo = client.get_info(\"vos:CANFAR/your_username/data.fits\")\nprint(f\"Size: {info['size']} bytes\")\nprint(f\"Modified: {info['date']}\")\n</code></pre>"},{"location":"user-guide/storage/vospace-api/#file-operations","title":"File Operations","text":"<pre><code># Copy file to VOSpace\nclient.copy(\"mydata.fits\", \"vos:CANFAR/your_username/data/mydata.fits\")\n\n# Copy file from VOSpace\nclient.copy(\"vos:CANFAR/your_username/data/results.txt\", \"./results.txt\")\n\n# Create directory\nclient.mkdir(\"vos:CANFAR/your_username/new_project/\")\n\n# Delete file\nclient.delete(\"vos:CANFAR/your_username/temp/old_file.txt\")\n</code></pre>"},{"location":"user-guide/storage/vospace-api/#advanced-operations","title":"Advanced Operations","text":"<pre><code>import os\nfrom astropy.io import fits\n\n\ndef process_fits_files(vospace_dir, output_dir):\n    \"\"\"Process all FITS files in a VOSpace directory\"\"\"\n\n    # List all FITS files\n    files = client.listdir(vospace_dir)\n    fits_files = [f for f in files if f.endswith(\".fits\")]\n\n    for fits_file in fits_files:\n        vospace_path = f\"{vospace_dir}/{fits_file}\"\n        local_path = f\"./temp_{fits_file}\"\n\n        # Download file\n        client.copy(vospace_path, local_path)\n\n        # Process with astropy\n        with fits.open(local_path) as hdul:\n            # Your processing here\n            processed_data = hdul[0].data * 2  # Example processing\n\n            # Save processed file\n            output_path = f\"{output_dir}/processed_{fits_file}\"\n            fits.writeto(output_path, processed_data, overwrite=True)\n\n            # Upload to VOSpace\n            client.copy(output_path, f\"vos:CANFAR/your_username/processed/{fits_file}\")\n\n        # Clean up temporary file\n        os.remove(local_path)\n\n\n# Usage\nprocess_fits_files(\"vos:CANFAR/your_username/raw_data\", \"./processed/\")\n</code></pre>"},{"location":"user-guide/storage/vospace-api/#automation-workflows","title":"Automation Workflows","text":""},{"location":"user-guide/storage/vospace-api/#batch-processing-script","title":"Batch Processing Script","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"\nAutomated data processing pipeline using VOSpace\n\"\"\"\nimport vos\nimport sys\nimport logging\nfrom pathlib import Path\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\ndef setup_vospace():\n    \"\"\"Initialize VOSpace client with authentication\"\"\"\n    try:\n        client = vos.Client()\n        # Test connection\n        client.listdir(\"vos:CANFAR/\")\n        return client\n    except Exception as e:\n        logger.error(f\"VOSpace authentication failed: {e}\")\n        sys.exit(1)\n\n\ndef sync_input_data(client, remote_dir, local_dir):\n    \"\"\"Download input data from VOSpace\"\"\"\n    logger.info(f\"Syncing {remote_dir} to {local_dir}\")\n\n    Path(local_dir).mkdir(parents=True, exist_ok=True)\n\n    # Get list of files\n    files = client.listdir(remote_dir)\n\n    for file in files:\n        if file.endswith((\".fits\", \".txt\", \".csv\")):\n            remote_path = f\"{remote_dir}/{file}\"\n            local_path = f\"{local_dir}/{file}\"\n\n            if not Path(local_path).exists():\n                logger.info(f\"Downloading {file}\")\n                client.copy(remote_path, local_path)\n\n\ndef upload_results(client, local_dir, remote_dir):\n    \"\"\"Upload processing results to VOSpace\"\"\"\n    logger.info(f\"Uploading results from {local_dir} to {remote_dir}\")\n\n    # Ensure remote directory exists\n    try:\n        client.mkdir(remote_dir)\n    except:\n        pass  # Directory might already exist\n\n    for file_path in Path(local_dir).glob(\"*\"):\n        if file_path.is_file():\n            remote_path = f\"{remote_dir}/{file_path.name}\"\n            logger.info(f\"Uploading {file_path.name}\")\n            client.copy(str(file_path), remote_path)\n\n\ndef main():\n    \"\"\"Main processing pipeline\"\"\"\n    client = setup_vospace()\n\n    # Configuration\n    input_remote = \"vos:CANFAR/shared_project/raw_data\"\n    output_remote = \"vos:CANFAR/your_username/processed_results\"\n    local_input = \"./input_data\"\n    local_output = \"./output_data\"\n\n    # Download input data\n    sync_input_data(client, input_remote, local_input)\n\n    # Your processing code here\n    logger.info(\"Processing data...\")\n    # ... processing logic ...\n\n    # Upload results\n    upload_results(client, local_output, output_remote)\n\n    logger.info(\"Pipeline completed successfully\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"user-guide/storage/vospace-api/#monitoring-and-logging","title":"Monitoring and Logging","text":""},{"location":"user-guide/storage/vospace-api/#transfer-progress","title":"Transfer Progress","text":"<pre><code>def copy_with_progress(client, source, destination):\n    \"\"\"Copy file with progress monitoring\"\"\"\n    import time\n\n    # Start transfer\n    start_time = time.time()\n    client.copy(source, destination)\n    end_time = time.time()\n\n    # Get file size for speed calculation\n    if source.startswith(\"vos:\"):\n        info = client.get_info(source)\n        size_mb = info[\"size\"] / (1024 * 1024)\n    else:\n        size_mb = os.path.getsize(source) / (1024 * 1024)\n\n    duration = end_time - start_time\n    speed = size_mb / duration if duration &gt; 0 else 0\n\n    print(f\"Transfer completed: {size_mb:.1f} MB in {duration:.1f}s ({speed:.1f} MB/s)\")\n</code></pre>"},{"location":"user-guide/storage/vospace-api/#error-handling","title":"Error Handling","text":"<pre><code>def robust_copy(client, source, destination, max_retries=3):\n    \"\"\"Copy with retry logic\"\"\"\n    import time\n\n    for attempt in range(max_retries):\n        try:\n            client.copy(source, destination)\n            return True\n        except Exception as e:\n            logger.warning(f\"Copy attempt {attempt + 1} failed: {e}\")\n            if attempt &lt; max_retries - 1:\n                time.sleep(2**attempt)  # Exponential backoff\n            else:\n                logger.error(f\"Copy failed after {max_retries} attempts\")\n                return False\n</code></pre>"},{"location":"user-guide/storage/vospace-api/#performance-optimization","title":"Performance Optimization","text":""},{"location":"user-guide/storage/vospace-api/#parallel-transfers","title":"Parallel Transfers","text":"<pre><code>import concurrent.futures\nimport threading\n\n\ndef parallel_upload(client, file_list, remote_dir, max_workers=4):\n    \"\"\"Upload multiple files in parallel\"\"\"\n\n    def upload_file(file_path):\n        remote_path = f\"{remote_dir}/{file_path.name}\"\n        try:\n            client.copy(str(file_path), remote_path)\n            return f\"\u2713 {file_path.name}\"\n        except Exception as e:\n            return f\"\u2717 {file_path.name}: {e}\"\n\n    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = [executor.submit(upload_file, f) for f in file_list]\n\n        for future in concurrent.futures.as_completed(futures):\n            result = future.result()\n            print(result)\n</code></pre>"},{"location":"user-guide/storage/vospace-api/#caching-strategy","title":"Caching Strategy","text":"<pre><code>import hashlib\nfrom pathlib import Path\n\n\ndef cached_download(client, vospace_path, local_path, force_refresh=False):\n    \"\"\"Download file only if it has changed\"\"\"\n\n    local_file = Path(local_path)\n    cache_file = Path(f\"{local_path}.cache_info\")\n\n    # Get remote file info\n    remote_info = client.get_info(vospace_path)\n    remote_hash = remote_info.get(\"MD5\", \"\")\n\n    # Check if we have cached info\n    if not force_refresh and local_file.exists() and cache_file.exists():\n        cached_hash = cache_file.read_text().strip()\n        if cached_hash == remote_hash:\n            print(f\"Using cached version of {local_file.name}\")\n            return local_path\n\n    # Download file\n    print(f\"Downloading {local_file.name}\")\n    client.copy(vospace_path, local_path)\n\n    # Save cache info\n    cache_file.write_text(remote_hash)\n\n    return local_path\n</code></pre>"},{"location":"user-guide/storage/vospace-api/#integration-examples","title":"Integration Examples","text":""},{"location":"user-guide/storage/vospace-api/#with-astropy","title":"With Astropy","text":"<pre><code>from astropy.io import fits\nfrom astropy.table import Table\n\n\ndef analyze_vospace_catalog(client, catalog_path):\n    \"\"\"Analyze a catalog stored in VOSpace\"\"\"\n\n    # Download catalog\n    local_path = \"./temp_catalog.fits\"\n    client.copy(catalog_path, local_path)\n\n    # Load and analyze\n    table = Table.read(local_path)\n\n    # Example analysis\n    bright_sources = table[table[\"magnitude\"] &lt; 15]\n    print(f\"Found {len(bright_sources)} bright sources\")\n\n    # Save filtered results\n    result_path = \"./bright_sources.fits\"\n    bright_sources.write(result_path, overwrite=True)\n\n    # Upload results\n    result_vospace = catalog_path.replace(\".fits\", \"_bright.fits\")\n    client.copy(result_path, result_vospace)\n\n    # Cleanup\n    os.remove(local_path)\n    os.remove(result_path)\n</code></pre>"},{"location":"user-guide/storage/vospace-api/#with-batch-jobs","title":"With Batch Jobs","text":"<pre><code>#!/bin/bash\n# Batch job script using VOSpace\n\n# Authenticate\ncadc-get-cert --cert ~/.ssl/cadcproxy.pem\n\n# Download input data\nvcp vos:CANFAR/project/input/data.fits ./input.fits\n\n# Process data\npython analysis_script.py input.fits output.fits\n\n# Upload results\nvcp output.fits vos:CANFAR/project/results/processed_$(date +%Y%m%d).fits\n\n# Cleanup\nrm input.fits output.fits\n</code></pre>"},{"location":"user-guide/storage/vospace-api/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/storage/vospace-api/#common-issues","title":"Common Issues","text":"<p>Authentication Problems: <pre><code># Refresh certificate\ncadc-get-cert --cert ~/.ssl/cadcproxy.pem\n\n# Check certificate validity\ncadc-get-cert --cert ~/.ssl/cadcproxy.pem --days-valid\n</code></pre></p> <p>Network Timeouts: <pre><code># Increase timeout for large files\nimport vos\n\nclient = vos.Client()\nclient.timeout = 300  # 5 minutes\n</code></pre></p> <p>Permission Errors: <pre><code># Check file permissions\nvls -l vos:CANFAR/your_username/file.fits\n\n# Check directory access\nvls vos:CANFAR/project_name/\n</code></pre></p>"},{"location":"user-guide/storage/vospace-api/#next-steps","title":"Next Steps","text":"<ul> <li>Storage Guide \u2192 - Basic storage concepts and web interface</li> <li>Batch Jobs \u2192 - Automate VOSpace workflows</li> <li>Containers \u2192 - Include VOSpace tools in custom containers</li> <li>Radio Astronomy \u2192 - Specialized data workflows</li> </ul>"}]}